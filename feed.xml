<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="/Content/RSS.xslt" type="text/xsl" media="screen"?>
<rss xmlns:dc="https://purl.org/dc/elements/1.1/" xmlns:atom="https://www.w3.org/2005/Atom" version="2.0">

    <channel>

        <title>Productive Rage</title>
        <link>https://www.productiverage.com/</link>
        <atom:link href="https://www.productiverage.com/feed" rel="self" type="application/rss+xml" />
        <description>Dan's techie ramblings</description>
        <language>en-gb</language>

        <lastBuildDate>Tue, 10 Aug 2021 08:01:00 GMT</lastBuildDate>
        <docs>https://blogs.law.harvard.edu/tech/rss</docs>

        <image>
            <title>Productive Rage</title>
            <url>https://www.productiverage.com/Content/Images/Grouch.jpg</url>
            <width>142</width>
            <height>142</height>
            <link>https://www.productiverage.com/</link>
        </image>

        <xhtml:meta xmlns:xhtml="https://www.w3.org/1999/xhtml" name="robots" content="noindex" />

            <item>
                <title>Parallelising (LINQ) work in C#</title>
                <link>https://www.productiverage.com/parallelising-linq-work-in-c-sharp</link>
                <guid>https://www.productiverage.com/parallelising-linq-work-in-c-sharp</guid>
                <description>&lt;h3&gt;TL;DR&lt;/h3&gt;&#xA;&lt;p&gt;For computationally-expensive work that can be split up into tasks for LINQ &amp;quot;Select&amp;quot; calls, .NET provides a convenient way to execute this code on multiple threads. This &amp;quot;parallelism&amp;quot; should not be confused with &amp;quot;concurrency&amp;quot;, which is what async / await is for.&lt;/p&gt;&#xA;&lt;h3&gt;A &amp;quot;parallelism vs concurrency&amp;quot; summary&lt;/h3&gt;&#xA;&lt;p&gt;Before getting started, I want to nip in the bud any confusion with the differences between code that runs &amp;quot;in parallel&amp;quot; and code that runs &amp;quot;concurrently&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;In short, recruiting a parallelisation strategy for code allows you to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;use multiple cores simultaneously to work on the same task&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;..while concurrency allows you to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;handle multiple tasks on the same core&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;A common example that I like to use is to refer to Node.js because it is a &lt;strong&gt;single-threaded&lt;/strong&gt; environment that supports concurrent execution of &lt;strong&gt;multiple&lt;/strong&gt; requests; each request will call out to external resources such as disk, out-of-process cache, a database, etc.. and it will be non-blocking when it does so, meaning that another request can be processed while it waits for that external resource to reply. So there is only a single thread but multiple overlapping requests can be handled because each time one pauses while it waits, another one can proceed until &lt;em&gt;it&lt;/em&gt; calls an external resource. &lt;strong&gt;One thread / multiple requests&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Parallelising a calculation is kind of the opposite - instead of one thread for multiple requests it tackles one request using multiple threads. This only makes sense when the work to be done is some sort of computation that consists of crunching away on data and &lt;em&gt;not&lt;/em&gt; just waiting for an external resource to reply.&lt;/p&gt;&#xA;&lt;p&gt;When talking about concurrency, it&#x27;s worth noting that in ASP.NET, if there is a lot of load then there might be multiple threads used to process work concurrently - each of the threads will be handling requests that spend most of their time waiting for some async work to complete. This is just like &amp;quot;one thread / multiple requests&amp;quot; but multiplied out to be &lt;strong&gt;&amp;quot;{x} threads / {y} requests&amp;quot; where {x} &amp;lt; {y}&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;For a web server, it is possible that it never makes sense to do work that benefits from being parallelised because that work, by its very nature, is very computationally-expensive and you wouldn&#x27;t want multiple requests to get bogged down in repeating the same costly work. You might require complicated synchronisation mechanisms (to avoid multiple requests doing the same work; instead, having one request do the work while other requests queue up and wait for the result to become available) and maybe you would be better moving that computationally-heavy work off into another service entirely (in which case your web server is back to making async requests as it asks a different server to do the work and send back the result).&lt;/p&gt;&#xA;&lt;h3&gt;A &amp;quot;parallelism vs concurrency&amp;quot; example&lt;/h3&gt;&#xA;&lt;p&gt;This is what concurrent (aka &amp;quot;async&amp;quot;) work looks likes - if we use &lt;strong&gt;Task.Delay&lt;/strong&gt; to imitate the delay that would be incurred by waiting on an external resource then we can create 50 requests and await the completion of them all like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = await Task.WhenAll(&#xA;    Enumerable&#xA;        .Range(0, 50)&#xA;        .Select(async i =&amp;gt;&#xA;        {&#xA;            LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;&#xA;            // Pause for 1, 2, 3, 4, 5 or 6 seconds depending upon the value of i&#xA;            await Task.Delay(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;            LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;            return i;&#xA;        })&#xA;);&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message}&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This work will all complete within about 6s because all it does is create 50 tasks (which it can do near-instantly) where the longest of those has a &lt;strong&gt;Task.Delay&lt;/strong&gt; call of 6s. Whenever one task is waiting, other work is free to continue. This means that all 50 of the tasks may be started using a single thread and that single thread may also be used to jump around receiving each of the results of those tasks.&lt;/p&gt;&#xA;&lt;p&gt;In this example, the &lt;strong&gt;Task.WhenAll&lt;/strong&gt; call creates a 50-element array where each element returns the value of &amp;quot;i&amp;quot; where i is 0-49. These 50 elements will be the 50 tasks&#x27; results, appearing in the array in the same order as they were created. This means that enumerating over the array - when &lt;strong&gt;Task.WhenAll&lt;/strong&gt; says that all of the tasks have completed - will reveal the task results to be in the same order in which they were specified.&lt;/p&gt;&#xA;&lt;p&gt;The 50 results, when the work is coordinated by &lt;strong&gt;Task.WhenAll&lt;/strong&gt;, will be:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In order&lt;/li&gt;&#xA;&lt;li&gt;Not available for enumeration until &lt;em&gt;all&lt;/em&gt; of them have completed (due to the &amp;quot;&lt;strong&gt;Task.WhenAll&lt;/strong&gt;&amp;quot; call) - all of the &amp;quot;Starting {i}&amp;quot; and &amp;quot;Finished {i}&amp;quot; messages will be displayed before any of the &amp;quot;Received item {item}&amp;quot; message&lt;/li&gt;&#xA;&lt;li&gt;Almost certainly handled by a single thread, across all 50 tasks (this isn&#x27;t guaranteed but it&#x27;s extremely likely to be true)&lt;/li&gt;&#xA;&lt;li&gt;The total running time will be about 6s since there is almost no work involved in starting the tasks, nor receiving the results of the tasks - all that we have to wait for is the time it takes for the longest tasks to complete (which is 6s)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Now, if this code is changed such that the &lt;strong&gt;Thread.Sleep&lt;/strong&gt; is used instead of of &lt;strong&gt;Task.Delay&lt;/strong&gt; then the thread will be blocked as each loop is iterated over. Whereas &lt;strong&gt;Task.Delay&lt;/strong&gt; was used to imitate a call to an external service that would do the work, &lt;strong&gt;Thread.Sleep&lt;/strong&gt; is used to imitate an expensive computation performed by the current thread.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;&#xA;        // Pause for 1, 2, 3, 4, 5 or 6 seconds depending upon the value of i&#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message}&amp;quot;);&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Because there is no &lt;strong&gt;Task.WhenAll&lt;/strong&gt; call that requires that &lt;em&gt;every&lt;/em&gt; iteration complete before enumeration can begin, the foreach loop will write out a line as soon as iteration finishes. The results will still be written to the console in the order in which they were defined.&lt;/p&gt;&#xA;&lt;p&gt;Note that this code is neither concurrent &lt;em&gt;not&lt;/em&gt; parallelised.&lt;/p&gt;&#xA;&lt;p&gt;Its behaviour, in comparison to the async example above, is that the results are returned:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In order&lt;/li&gt;&#xA;&lt;li&gt;Available for enumeration as soon as each iteration completes - so the console messages will always appear as &amp;quot;Starting 1&amp;quot;, &amp;quot;Finished 1&amp;quot;, &amp;quot;Receiving item 1&amp;quot;, &amp;quot;Starting 2&amp;quot;, &amp;quot;Finished 2&amp;quot;, &amp;quot;Receiving item 2&amp;quot;, etc..&lt;/li&gt;&#xA;&lt;li&gt;Handled by a single thread as there is merely the one thread that is processing the loop and blocking on each &lt;strong&gt;Thread.Sleep&lt;/strong&gt; call&lt;/li&gt;&#xA;&lt;li&gt;The total running time is the sum of every &lt;strong&gt;Thread.Sleep&lt;/strong&gt; delay, which is 171s (50 iterations where each sleep call is between 1 and 6s)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;With one simple change, we can alter this code such that the work &lt;em&gt;is&lt;/em&gt; parallelised -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel() // &amp;lt;- Paralellisation enabled here&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message}&amp;quot;);&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This changes the behaviour considerably (unless you happen to be running this code on a single core machine, which is pretty unusual these days!) because as AsParallel() call allows the 50 iterations to be distributed over multiple cores.&lt;/p&gt;&#xA;&lt;p&gt;My computer has 24 cores and so that means that up to 24 iterations can be run simultaneously - there will be up to 24 threads running and while each of those will be blocked as the &lt;strong&gt;Thread.Sleep&lt;/strong&gt; calls are hit (which, again, are intended to mimic an expensive computation that would tie up a thread), the work will be done much more quickly than when a &lt;em&gt;single&lt;/em&gt; thread had to do all the waiting.&lt;/p&gt;&#xA;&lt;p&gt;When this code is running, there will be many &amp;quot;Starting {i}&amp;quot; messages written out at once and then some &amp;quot;Finished {i}&amp;quot; messages will be written as soon as the first threads complete their current iterations and are ready to move onto another (until all 50 have been processed). It also means that &amp;quot;Received item {item}&amp;quot; messages will be interspersed throughout because enumeration of the list can commence as soon as any of the loops complete.&lt;/p&gt;&#xA;&lt;p&gt;It&#x27;s important to note that the scheduling of the threads should be considered undefined in this configuration and there is no guarantee that you will first see &amp;quot;Starting 1&amp;quot;, followed by &amp;quot;Starting 2&amp;quot;, followed by &amp;quot;Starting 3&amp;quot;. In fact, when I run it, the first messages are as follows:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;15:15:10.423 Starting 3&lt;br&gt;&#xA;15:15:10.423 Starting 9&lt;br&gt;&#xA;15:15:10.423 Starting 15&lt;br&gt;&#xA;15:15:10.423 Starting 16&lt;br&gt;&#xA;15:15:10.423 Starting 11&lt;br&gt;&#xA;15:15:10.423 Starting 20&lt;br&gt;&#xA;15:15:10.423 Starting 5&lt;br&gt;&#xA;15:15:10.423 Starting 19&lt;br&gt;&#xA;15:15:10.423 Starting 6&lt;br&gt;&#xA;15:15:10.423 Starting 0&lt;br&gt;&#xA;15:15:10.423 Starting 12&lt;br&gt;&#xA;15:15:10.423 Starting 17&lt;br&gt;&#xA;15:15:10.423 Starting 23&lt;br&gt;&#xA;15:15:10.423 Starting 1&lt;br&gt;&#xA;15:15:10.423 Starting 14&lt;br&gt;&#xA;15:15:10.423 Starting 2&lt;br&gt;&#xA;15:15:10.423 Starting 10&lt;br&gt;&#xA;15:15:10.423 Starting 22&lt;br&gt;&#xA;15:15:10.423 Starting 18&lt;br&gt;&#xA;15:15:10.423 Starting 4&lt;br&gt;&#xA;15:15:10.423 Starting 13&lt;br&gt;&#xA;15:15:10.423 Starting 21&lt;br&gt;&#xA;15:15:10.423 Starting 7&lt;br&gt;&#xA;15:15:10.423 Starting 8&lt;br&gt;&#xA;15:15:11.437 Finished 18&lt;br&gt;&#xA;15:15:11.437 Finished 0&lt;br&gt;&#xA;15:15:11.437 Finished 12&lt;br&gt;&#xA;15:15:11.437 Finished 6&lt;br&gt;&#xA;15:15:11.437 Starting 24&lt;br&gt;&#xA;15:15:11.437 Starting 25&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;While the starting order is not predictable, the iteration-completion order is somewhat more predictable &lt;em&gt;in this example code&lt;/em&gt; as loops 0, 6, 12, etc.. (ie. every multiple of 6) completes in 1s while every other value of i takes longer.&lt;/p&gt;&#xA;&lt;p&gt;As such, the first &amp;quot;Finished {i}&amp;quot; messages are 18, 0, 12, 6 in the output shown above.&lt;/p&gt;&#xA;&lt;p&gt;The &amp;quot;Received item {item}&amp;quot; messages will be interspersed between &amp;quot;Starting {i}&amp;quot; and &amp;quot;Finished {i}&amp;quot; messages because enumeration of the results &lt;em&gt;can&lt;/em&gt; commence as soon as soom of the loops have completed.. however, again, it&#x27;s important to note that the ordering of the results should not be considered to be defined as the scheduling of the threads depends upon how .NET decides to use its &lt;strong&gt;ThreadPool&lt;/strong&gt; to handle the work and how it will &amp;quot;join&amp;quot; the separate threads used for the loop iteration back to the primary thread that the program is running as.&lt;/p&gt;&#xA;&lt;p&gt;That may sound a little confusing, so if we change the code a little bit then maybe it can become clearer:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel() // &amp;lt;- Paralellisation enabled here&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Running this now has those first progress messages look like this:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;15:32:56.683 Starting 8 (Thread 19)&lt;br&gt;&#xA;15:32:56.688 Starting 14 (Thread 16)&lt;br&gt;&#xA;15:32:56.699 Starting 19 (Thread 18)&lt;br&gt;&#xA;15:32:56.692 Starting 17 (Thread 11)&lt;br&gt;&#xA;15:32:56.690 Starting 15 (Thread 14)&lt;br&gt;&#xA;15:32:56.687 Starting 11 (Thread 17)&lt;br&gt;&#xA;15:32:56.685 Starting 9 (Thread 12)&lt;br&gt;&#xA;15:32:56.695 Starting 18 (Thread 21)&lt;br&gt;&#xA;15:32:56.688 Starting 13 (Thread 26)&lt;br&gt;&#xA;15:32:56.703 Starting 21 (Thread 27)&lt;br&gt;&#xA;15:32:56.692 Starting 16 (Thread 25)&lt;br&gt;&#xA;15:32:56.700 Starting 20 (Thread 24)&lt;br&gt;&#xA;15:32:56.683 Starting 6 (Thread 4)&lt;br&gt;&#xA;15:32:56.683 Starting 0 (Thread 7)&lt;br&gt;&#xA;15:32:56.683 Starting 5 (Thread 13)&lt;br&gt;&#xA;15:32:56.683 Starting 1 (Thread 5)&lt;br&gt;&#xA;15:32:56.687 Starting 12 (Thread 10)&lt;br&gt;&#xA;15:32:56.683 Starting 2 (Thread 6)&lt;br&gt;&#xA;15:32:56.683 Starting 4 (Thread 9)&lt;br&gt;&#xA;15:32:56.685 Starting 10 (Thread 22)&lt;br&gt;&#xA;15:32:56.683 Starting 7 (Thread 15)&lt;br&gt;&#xA;15:32:56.706 Starting 22 (Thread 20)&lt;br&gt;&#xA;15:32:56.683 Starting 3 (Thread 8)&lt;br&gt;&#xA;15:32:56.706 Starting 23 (Thread 23)&lt;br&gt;&#xA;15:32:57.722 Finished 18 (Thread 21)&lt;br&gt;&#xA;15:32:57.722 Finished 6 (Thread 4)&lt;br&gt;&#xA;15:32:57.722 Finished 0 (Thread 7)&lt;br&gt;&#xA;15:32:57.722 Finished 12 (Thread 10)&lt;br&gt;&#xA;15:32:57.723 Starting 24 (Thread 21)&lt;br&gt;&#xA;15:32:57.723 Starting 25 (Thread 4)&lt;br&gt;&#xA;15:32:57.723 Starting 26 (Thread 7)&lt;br&gt;&#xA;15:32:57.723 Starting 27 (Thread 10)&lt;br&gt;&#xA;15:32:58.711 Finished 1 (Thread 5)&lt;br&gt;&#xA;15:32:58.711 Finished 7 (Thread 15)&lt;br&gt;&#xA;15:32:58.711 Finished 19 (Thread 18)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Firstly, note that the &amp;quot;Starting {i}&amp;quot; and &amp;quot;Finished {i}&amp;quot; messages are in a different order again - as I said, the order in which the tasks will be delegated to threads from the &lt;strong&gt;ThreadPool&lt;/strong&gt; should be considered undefined and so you can&#x27;t rely on having each loop started in the same order.&lt;/p&gt;&#xA;&lt;p&gt;Secondly, note that all of those first &amp;quot;Starting {i}&amp;quot; messages are being written from a different thread (19, 16, 18, 11, etc..). But when one of the loops is completed, the thread that processed it becomes free to work on a different iteration and so shortly after we see &amp;quot;Finished 18 (Thread 24)&amp;quot; we see &amp;quot;Starting 25 (Thread 24)&amp;quot; - meaning that one thread (the one with ManagedThreadId 24) finished with loop 18 and then became free to be assigned to start working on loop 25.&lt;/p&gt;&#xA;&lt;p&gt;Scrolling further down the output when I run it on my computer, I can see the first &amp;quot;Receiving item {item}&amp;quot; messages:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;15:33:01.732 Received item 9 (Thread 1)&lt;br&gt;&#xA;15:33:01.732 Received item 42 (Thread 1)&lt;br&gt;&#xA;15:33:01.734 Finished 32 (Thread 21)&lt;br&gt;&#xA;15:33:01.734 Received item 18 (Thread 1)&lt;br&gt;&#xA;15:33:01.742 Received item 24 (Thread 1)&lt;br&gt;&#xA;15:33:01.742 Received item 32 (Thread 1)&lt;br&gt;&#xA;15:33:01.734 Finished 37 (Thread 24)&lt;br&gt;&#xA;15:33:01.734 Finished 27 (Thread 10)&lt;br&gt;&#xA;15:33:01.744 Received item 20 (Thread 1)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Note that all of the &amp;quot;Received item {item}&amp;quot; messages are being logged by thread 1, which is the thread that the &amp;quot;Main&amp;quot; method of my program started on.&lt;/p&gt;&#xA;&lt;p&gt;Having &amp;quot;AsParallel()&amp;quot; join up its enumeration results such that the enumeration itself can happen on the &amp;quot;primary&amp;quot; thread can be useful because there are some environments that get unhappy if you try to do particular types of work on separate threads - for example, if you wrote an old-school WinForms app and had a separate thread do some work and then try to update a control on your form then you would get an error:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Cross-thread operation not valid. Control accessed from a thread other than the thread it was created on.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;(You may be wondering why the &amp;quot;Received item {i}&amp;quot; messages appeared a couple of seconds after the corresponding &amp;quot;Finished {i}&amp;quot; messages, rather than immediately after each loop completed - this is due to buffering of the results and I&#x27;ll touch on this later in this post)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;When &amp;quot;AsParallel()&amp;quot; is used in this way, the characteristics (as compared to the &lt;strong&gt;Task.WhenAll&lt;/strong&gt; async work and to the single-thread work) are that:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The results are not returned in order&lt;/li&gt;&#xA;&lt;li&gt;Enumeration starts before all of the processing has completed&lt;/li&gt;&#xA;&lt;li&gt;Multiple threads are used (by default, one thread per core in your computer - but, again, there are options for this that I&#x27;ll discuss further down)&lt;/li&gt;&#xA;&lt;li&gt;The total running time depends upon the number of cores you have - if you had 50 cores then every loop iteration would be running simultaneously and it would take about 6s for &lt;em&gt;everything&lt;/em&gt; to complete, as the longest iterations take 6s each (but they would be getting processed simultaneously). If you only had 1 core then you would see the same behaviour as the non-parallelised version above and it would take 171s. On my computer, with 24 cores, it takes around 11s because there are threads that get through the quick iterations until they hit the longer &lt;strong&gt;Thread.Sleep&lt;/strong&gt; calls but there will still be multiple of these slower iterations being processed at the same time.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;If ordering of the results is important then the code can easily be changed like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel() // &amp;lt;- Paralellisation enabled here&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    })&#xA;    .OrderBy(i =&amp;gt; i); // &amp;lt;- Ordering enforced here&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now the work will still be performed on multiple threads at once but enumeration will not be able to start until all of the iterations have completed.&lt;/p&gt;&#xA;&lt;p&gt;This means that the console messages will consist entirely of &amp;quot;Starting {i}&amp;quot; and &amp;quot;Finished {i}&amp;quot; messages until &lt;em&gt;all&lt;/em&gt; 50 iterations are completed, then all of the &amp;quot;Received item {item}&amp;quot; messages will be written out. This will still have the same running time (eg. 11s on my computer) because the work is being performed in the same way - the only difference is that the results are all buffered up until the work is completed, otherwise the &lt;strong&gt;OrderBy&lt;/strong&gt; call wouldn&#x27;t be able to do its job because it couldn&#x27;t know all of the values that were going to be produced.&lt;/p&gt;&#xA;&lt;h3&gt;Implementation details&lt;/h3&gt;&#xA;&lt;p&gt;There are a &lt;em&gt;lot&lt;/em&gt; of options and intricacies that you can find if you dig deep enough into how this works in the .NET library. I have no intention of trying to cover all of them but there are a few options and observations that I think are worth including in this post.&lt;/p&gt;&#xA;&lt;p&gt;The first thing to be aware of is that parallelisation of the work will not be enabled until after the &amp;quot;AsParallel()&amp;quot; call is made - for example, the following code will &lt;em&gt;not&lt;/em&gt; spread the the &lt;strong&gt;Thread.Sleep&lt;/strong&gt; calls across multiple cores:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    })&#xA;    .AsParallel(); // &amp;lt;- Too late!&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This may seem counterintuitive as the &lt;strong&gt;IEnumerable&lt;/strong&gt; returned from &amp;quot;Select&amp;quot; may be lazily evaluated and so you may expect the runtime to be able to distribute its work over multiple cores due to the &amp;quot;AsParallel()&amp;quot; call after it but this is not the case.&lt;/p&gt;&#xA;&lt;p&gt;To get an idea where parallelisation may occur, there are hints in the method return types - eg. where &amp;quot;Enumerable.Range&amp;quot; returns an &lt;strong&gt;IEnumerable&amp;lt;int&amp;gt;&lt;/strong&gt; and a &amp;quot;Select&amp;quot; call following it will also return an &lt;strong&gt;IEnumerable&amp;lt;int&amp;gt;&lt;/strong&gt;, when there is an &amp;quot;AsParallel&amp;quot; call after &amp;quot;Enumerable.Range&amp;quot; then the type is now a &lt;strong&gt;ParallelQuery&amp;lt;int&amp;gt;int&lt;/strong&gt; and there is a &amp;quot;Select&amp;quot; overload on that type that means that when &amp;quot;Select&amp;quot; is called on a &lt;strong&gt;ParallelQuery&lt;/strong&gt; then that too returns a &lt;strong&gt;ParallelQuery&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h4&gt;Limiting how many cores may be used&lt;/h4&gt;&#xA;&lt;p&gt;The default behaviour of &amp;quot;AsParallel()&amp;quot; is to spread the work over as many cores as your computer has available (obviously if there are only 10 work items to distribute and there are 24 cores then it won&#x27;t be able to use &lt;em&gt;all&lt;/em&gt; of your cores but if there are at least as many things to do as there are cores then it will use them all until it starts running out of things).&lt;/p&gt;&#xA;&lt;p&gt;Depending upon your scenario, this may or may not be a good thing. For example, in my previous post (&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts-part-2&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts - Part 2&lt;/a&gt;), I spoke about how I&#x27;ve started using the C# machine learning library &lt;a href=&quot;https://github.com/curiosity-ai/catalyst&quot;&gt;Catalyst&lt;/a&gt; (produced by a startup that I used to work at) to suggest &amp;quot;you may be also be interested in&amp;quot; links for the bottom of my posts - in this case, it&#x27;s a one-off task performed before I push an update to my blog live and so I want the computer to spend all of its resources calculating this as fast as possible.&lt;/p&gt;&#xA;&lt;p&gt;One of the applicable lines in the library is in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&quot;&gt;TFIDF&lt;/a&gt; implementation and looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;documents.AsParallel().ForAll(doc =&amp;gt; UpdateVocabulary(ExtractTokenHashes(doc)));&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;(As you can see in the source file &lt;a href=&quot;https://github.com/curiosity-ai/catalyst/blob/70df89be7b725f6c7786187bd75b2032f287141b/Catalyst/src/Models/Special/TF-IDF.cs#L110&quot;&gt;TF-IDF.cs&lt;/a&gt;; along with the rest of the implementation for if you&#x27;re curious)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;However, I could also imagine that there might be a web server that is serving requests from many people each day but &lt;em&gt;ocassionally&lt;/em&gt; there is a request that requires some more intense computation and it might take too long to calculate this while feeling responsive to the User if it tried to do the work on a single thread - &lt;em&gt;but&lt;/em&gt; if it used &lt;em&gt;every&lt;/em&gt; core available on the server then it would impact all of the other requests being handled. In this case it may be appropriate to say &amp;quot;parallelise this work but don&#x27;t allow more than four cores to be utilised&amp;quot;. There is a method &amp;quot;WithDegreeOfParallelism&amp;quot; available for just this purpose!&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel().WithDegreeOfParallelism(4)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;If the value passed to &amp;quot;WithDegreeOfParallelism&amp;quot; exceeds the number of cores then it will have no effect but if it is less then it will constrain that parallelised work such that it will not use more than that number of cores at any time.&lt;/p&gt;&#xA;&lt;h4&gt;Buffering options&lt;/h4&gt;&#xA;&lt;p&gt;I mentioned earlier that when work is spread over multiple cores using &amp;quot;AsParallel()&amp;quot; and then later enumerated that some buffering of the results occurs. There are three options for the buffering behaviour:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;AutoBuffering&lt;/li&gt;&#xA;&lt;li&gt;FullyBuffered&lt;/li&gt;&#xA;&lt;li&gt;NotBuffered&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The default is &amp;quot;AutoBuffering&amp;quot; and the behaviour of this is that results are not available for enumeration as soon as the work items are completed - instead, the runtime determines a batch size that it thinks makes sense to buffer the results up for before making them available for looping through.&lt;/p&gt;&#xA;&lt;p&gt;To be completely honest, I don&#x27;t know enough about how it decides on this number or the full extent of the benefits of doing so (though I will hint at a way to find out more in the &amp;quot;Partitioner&amp;quot; section further down); I presume that there are some performance benefits to reducing how often execution jumps from one thread to another - because, as we saw earlier, as soon as enumeration commences, execution returns to the &amp;quot;primary thread&amp;quot; and hopping between threads can be a &lt;em&gt;relatively&lt;/em&gt; expensive operation.&lt;/p&gt;&#xA;&lt;p&gt;The second option (&amp;quot;FullyBuffered&amp;quot;) is simple to understand - enumeration will not commence until &lt;em&gt;all&lt;/em&gt; of the work items are completed; they will &lt;em&gt;all&lt;/em&gt; be added to a buffer first. This not only has the disadvantage that enumeration can&#x27;t start until the final item is completed but it also means that all of those results must be held in memory, which could be avoided (if it&#x27;s a concern) by having the results &amp;quot;stream&amp;quot; out as they become ready in the other buffering scenarios. This has the advantage of minimising &amp;quot;thread hops&amp;quot; but, even though the results are all buffered, it does not preserve the order of the work items when it comes to enumeration - despite what I&#x27;ve read elsewhere (you can see this yourself by running the code a little further down).&lt;/p&gt;&#xA;&lt;p&gt;The final option is &amp;quot;NotBuffered&amp;quot; and that, as you can probably tell from the name, doesn&#x27;t buffer results at all and makes the available for enumeration as soon as they have been processed (the disadvantage being the additional cost of changing thread context more frequently - ie. more &amp;quot;thread hops&amp;quot;).&lt;/p&gt;&#xA;&lt;p&gt;To override the default (&amp;quot;AutoBuffering&amp;quot;) behaviour, you may use the &amp;quot;WithMergeOptions&amp;quot; function like this -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel().WithMergeOptions(ParallelMergeOptions.FullyBuffered)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;Cancellation&lt;/h4&gt;&#xA;&lt;p&gt;Say you have many work items distributed over multiple cores in order to calculate something very expensive and parallelisable. Part way through, you might decide that actually you don&#x27;t want the result any more - maybe some of the data that it relies on has changed and a &amp;quot;stale&amp;quot; result will not be of any use. In this case, you will want to cancel the parallised work.&lt;/p&gt;&#xA;&lt;p&gt;To enable this, there is a &amp;quot;WithCancellation&amp;quot; method that takes a &lt;strong&gt;CancellationToken&lt;/strong&gt; and will stop allocating work items to threads if the token is marked as cancelled - instead, it will throw an &lt;strong&gt;OperationCanceledException&lt;/strong&gt;. To imitate this, the code below has a token that will be set to be cancelled after 3s and the exception will be thrown during the enumeration:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var cts = new CancellationTokenSource();&#xA;cts.CancelAfter(TimeSpan.FromSeconds(3));&#xA;&#xA;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel().WithCancellation(cts.Token)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;It&#x27;s worth noting that &amp;quot;WithCancellation&amp;quot; can only cancel the &amp;quot;AsParallel&amp;quot; work of allocating items to threads, it doesn&#x27;t have any ability to cancel the individual work items themselves. If you want to do this - such that &lt;em&gt;all&lt;/em&gt; work is halted immediately as soon as the token is set to cancelled, then you would have to add cancelletion-checking code to the work performed in each step - ie.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var cts = new CancellationTokenSource();&#xA;cts.CancelAfter(TimeSpan.FromSeconds(3));&#xA;&#xA;var items = Enumerable&#xA;    .Range(0, 50)&#xA;    .AsParallel().WithCancellation(cts.Token)&#xA;    .Select(i =&amp;gt;&#xA;    {&#xA;        LogWithTime($&amp;quot;Starting {i}&amp;quot;);&#xA;                &#xA;        cts.Token.ThrowIfCancellationRequested();&#xA;        Thread.Sleep(TimeSpan.FromSeconds((i % 6) &#x2B; 1));&#xA;&#xA;        LogWithTime($&amp;quot;Finished {i}&amp;quot;);&#xA;        return i;&#xA;    });&#xA;&#xA;foreach (var item in items)&#xA;{&#xA;    LogWithTime($&amp;quot;Received item {item}&amp;quot;);&#xA;}&#xA;&#xA;static void LogWithTime(string message) =&amp;gt;&#xA;    Console.WriteLine($&amp;quot;{DateTime.Now:HH:mm:ss.fff} {message} &amp;quot; &#x2B; &#xA;                      $&amp;quot;(Thread {Thread.CurrentThread.ManagedThreadId})&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;(Granted, using &amp;quot;cts.Token.ThrowIfCancellationRequested&amp;quot; alongside &amp;quot;Thread.Sleep&amp;quot; isn&#x27;t a perfect example of how to deal with cancellation because you can&#x27;t cancel the &amp;quot;Thread.Sleep&amp;quot; call itself - but hopefully it demonstrates that if you want immediate cancellation of every work item then you need to incorporate cancellation support into each work item as well as calling &amp;quot;WithCancellation&amp;quot; on the &lt;strong&gt;ParallelQuery&lt;/strong&gt;)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;For more detailed information on &amp;quot;PLINQ (parallel LINQ) cancellation&amp;quot;, there is a great article by Reed Copsey Jr entitled &lt;a href=&quot;http://reedcopsey.com/2010/02/17/parallelism-in-net-part-10-cancellation-in-plinq-and-the-parallel-class/&quot;&gt;Parallelism in .NET &#x2013; Part 10, Cancellation in PLINQ and the Parallel class&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h4&gt;Partitioner&amp;lt;TSource&amp;gt;&lt;/h4&gt;&#xA;&lt;p&gt;When an &amp;quot;AsParallel&amp;quot; call decides how to split up the work, it uses something called a &amp;quot;Partitioner&amp;quot;. This determines how big the buffer will be when &amp;quot;AutoBuffering&amp;quot; is used and it may even perform other optimisations (up to this point, I&#x27;ve said that &amp;quot;AsParallel&amp;quot; will &lt;em&gt;always&lt;/em&gt; spread the work over multiple cores - so long as you have multiple cores at your disposal and &amp;quot;WithDegreeOfParallelism&amp;quot; doesn&#x27;t specify a value of 1) but, actually, the partitioner could look at the work load and decide that parallelising the work would probably incur more overhead than performing it one step at a time on a single thread and so it &lt;em&gt;won&#x27;t&lt;/em&gt; actually use multiple cores.&lt;/p&gt;&#xA;&lt;p&gt;The .NET library will use its own default Partitioner unless it is told to use a custom one. This is a complex subject matter that:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;I don&#x27;t have a lot of knowledge about about&lt;/li&gt;&#xA;&lt;li&gt;I don&#x27;t want to try to add to this article, lest it end up ginormous!&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;If you want to find out more, I recommend starting at the Microsoft documentation about it here: &lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/custom-partitioners-for-plinq-and-tpl&quot;&gt;Custom Partitioners for PLINQ and TPL&lt;/a&gt; and also checking out &lt;a href=&quot;https://weblogs.asp.net/dixin/parallel-linq-2-partitioning&quot;&gt;Parallel LINQ in Depth (2) Partitioning&lt;/a&gt; from Dixin&#x27;s Blog (whose blog I also referenced under the &amp;quot;Further reading&amp;quot; section of my &lt;a href=&quot;https://www.productiverage.com/i-didnt-understand-why-people-struggled-with-nets-async&quot;&gt;I didn&#x27;t understand why people struggled with (.NET&#x27;s) async&lt;/a&gt; post).&lt;/p&gt;&#xA;&lt;h3&gt;When to parallelise work (and when to not)&lt;/h3&gt;&#xA;&lt;p&gt;Much of the time, there is no need for you to try to spread individual tasks over multiple threads. A very common model in this day and age for processing is a web server that is dealing with requests from many Users and most of the time is spent waiting for external caches, file system accesses, database retrievals, etc.. This is not the sort of heavy computation that would lead you to want to try to utilise multiple cores on that web server for any single request.&lt;/p&gt;&#xA;&lt;p&gt;Also, some computational work, even if it&#x27;s expensive, doesn&#x27;t lend itself to parallelisation - if you can&#x27;t split the work into clearly delineated and independent work items then it&#x27;s going to be awkward (if not impossible) to make the work parallelisable. For example, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fibonacci_number&quot;&gt;Fibonacci Sequence&lt;/a&gt; starts with the numbers 0 and 1 and each subsequent number is the sum of the previous two; so the third number is (0 &#x2B; 1) = 1, the fourth number is (1 &#x2B; 1) = 2, the fifth number is (1 &#x2B; 2) = 3, etc.. In case you&#x27;re not familiar with it and that description is a little confusing, maybe it will help to know that the first ten numbers in the sequence are:&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;, &lt;strong&gt;1&lt;/strong&gt;, &lt;strong&gt;1&lt;/strong&gt; (=0&#x2B;1), &lt;strong&gt;2&lt;/strong&gt; (=1&#x2B;1), &lt;strong&gt;3&lt;/strong&gt; (=1&#x2B;2), &lt;strong&gt;5&lt;/strong&gt; (=2&#x2B;3), &lt;strong&gt;8&lt;/strong&gt; (=3&#x2B;5), &lt;strong&gt;13&lt;/strong&gt; (=5&#x2B;8), &lt;strong&gt;21&lt;/strong&gt; (=8&#x2B;13), &lt;strong&gt;34&lt;/strong&gt; (=13&#x2B;21)&lt;/p&gt;&#xA;&lt;p&gt;If you calculate the &lt;em&gt;nth&lt;/em&gt; number like this (based on the previous two) then it&#x27;s near impossible to split the work into big distinct chunks that you could run on different threads and so it wouldn&#x27;t be a good candidate for parallelisation*.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(If you search Google then you will find that there are people proposing ways to calculate Fibonacci numbers using multiple threads but it&#x27;s much more complicated than working them out the simple way described above, so let&#x27;s forget about that for now so that the Fibonacci sequence works as an easily-understood example of when not to parallelise!)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Another thing to bear in mind is that there &lt;em&gt;is&lt;/em&gt; some cost to having the runtime jump around multiple threads, to coordinate what work is done on which and to then join the results all back up on the original thread. For this reason, the ideal use cases are when the main task can be split into fairly large chunks so that the amount of time that each thread spends doing work makes the thread coordination time negligible in comparison.&lt;/p&gt;&#xA;&lt;p&gt;One example is the &lt;strong&gt;TF-IDF&lt;/strong&gt; class that I mentioned earlier where there are a list of documents (blog posts, in my use case) and there is analysis required on each one to look for &amp;quot;interesting&amp;quot; words:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;documents.AsParallel().ForAll(doc =&amp;gt; UpdateVocabulary(ExtractTokenHashes(doc)));&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Another example is something that I was tinkering with some months ago and which I&#x27;m hoping to write some blog posts about when I can motivate myself! A few years ago, I gave a tech talk to a local group that was recorded but the camera was out of focus for most of the video and so the slides are illegible. I&#x27;ve still got the slide deck that I prepared for the talk and so I can produce images of those in full resolution - which gave me the idea of analysing the frames of the original video and trying to determine which slide should be shown on which frame and then superimposing a clear version of the slide onto the blurry images (then creating a new version of the video with the original audio, the original blurry view of me but super-clear slide contents). Some of the steps involved in this are:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Load all of the original slide images and translate their pixel data into a form that will make comparisons easier for the code later on&lt;/li&gt;&#xA;&lt;li&gt;Look at every frame of the video and look for the brightest area on the image and hope that that is the projection of the slide (it will be a quadrilateral but not a rectangle, due to perspective of the wall onto which the slides were projected)&lt;/li&gt;&#xA;&lt;li&gt;Load every frame of the video, extract the content that is in the &amp;quot;brightest area&amp;quot; that appears most commonly throughout the slides (it varies a little from slide to slide, depending upon how out of focus the camera was at the time), stretch the area back into a simple rectangle (reversing the effect of perspective), translate the pixel data into the same format as the original slides were converted into earlier and then try to find the closest match&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Each of these steps lends itself to parallelisation because the work performed on each frame may be done in isolation and the work itself is sufficiently computationally expensive that the task of coordinating the work between threads can basically be considered to be zero in comparison.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(If you&#x27;re just absolutely desperate to know more about this still-slightly-rough-around-the-edges project, you can find it on my GitHub account under &lt;a href=&quot;https://github.com/ProductiveRage/NaivePerspectiveCorrection&quot;&gt;NaivePerspectiveCorrection&lt;/a&gt; - like I said, I hope to write some more posts about it in the coming months but, until then, you can see some sensible uses of &amp;quot;AsParallel()&amp;quot; in &lt;a href=&quot;https://github.com/ProductiveRage/NaivePerspectiveCorrection/blob/4cf5222282ea3c948d454af83eafcfdc274c155f/NaivePerspectiveCorrection/Program.cs&quot;&gt;Program.cs&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/how-are-barcodes-read-libraryless-image-processing-in-c-sharp&quot;&gt;How are barcodes read?? (Library-less image processing in C#)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/a-followup-to-implementing-f-sharp-inspired-with-updates-in-c-sharp&quot;&gt;A follow-up to &amp;quot;Implementing F#-inspired &amp;#x27;with&amp;#x27; updates in C#&amp;quot;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/implementing-f-sharp-inspired-with-updates-for-immutable-classes-in-c-sharp&quot;&gt;Implementing F#-inspired &amp;quot;with&amp;quot; updates for immutable classes in C#&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Tue, 10 Aug 2021 08:01:00 GMT</pubDate>
            </item>
            <item>
                <title>Automating &quot;suggested / related posts&quot; links for my blog posts - Part 2</title>
                <link>https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts-part-2</link>
                <guid>https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts-part-2</guid>
                <description>&lt;h3&gt;TL;DR&lt;/h3&gt;&#xA;&lt;p&gt;By training another type of model from the open source .NET library that I&#x27;ve been using and combining its results with the similarity model from last time (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts&lt;/a&gt;), I&#x27;m going to improve the automatically-generated &amp;quot;you may be interested in&amp;quot; links that I&#x27;m adding to my blog.&lt;/p&gt;&#xA;&lt;p&gt;Improvement, in fact, sufficient such that I&#x27;ll start displaying the machine-suggested links at the bottom of each post.&lt;/p&gt;&#xA;&lt;h3&gt;Where I left off last time&lt;/h3&gt;&#xA;&lt;p&gt;In my last post, I had trained a &lt;a href=&quot;https://en.wikipedia.org/wiki/FastText&quot;&gt;fastText&lt;/a&gt; model (as part of the &lt;a href=&quot;https://github.com/curiosity-ai/catalyst&quot;&gt;Catalyst .NET library&lt;/a&gt;) by having it read all of my blog posts so that it could predict which posts were most likely to be similar to which other posts.&lt;/p&gt;&#xA;&lt;p&gt;This came back with some excellent suggestions, like this:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Learning F# via some Machine Learning: The Single Layer Perceptron&lt;/strong&gt;&lt;br&gt;&#xA;How are barcodes read?? (Library-less image processing in C#)&lt;br&gt;&#xA;Writing F# to implement &#x27;The Single Layer Perceptron&#x27;&lt;br&gt;&#xA;Face or no face (finding faces in photos using C# and AccordNET)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. but it also produced some less good selections, like this:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Simple TypeScript type definitions for AMD modules&lt;/strong&gt;&lt;br&gt;&#xA;STA ApartmentState with ASP.Net MVC&lt;br&gt;&#xA;WCF with JSON (and nullable types)&lt;br&gt;&#xA;The joys of AutoMapper&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;I&#x27;m still not discounting the idea that I might be able to improve the results by tweaking hyperparameters on the training model (such as epoch, negative sampling rate and dimensions) or maybe even changing how it processes the blog posts - eg. it&#x27;s tackling the content as English language documents but there are large code segments in many of the posts and maybe that&#x27;s confusing it; maybe removing the code samples before processing would give better results?&lt;/p&gt;&#xA;&lt;p&gt;However, fiddling with those options and rebuilding over and over is a time-consuming process and there is no easy way to evaluate the &amp;quot;goodness&amp;quot; of the results - so I need to flick through them all myself and try to get a rough feel for whether I think the last run was an improvement or not.&lt;/p&gt;&#xA;&lt;h3&gt;Introducing a new model&lt;/h3&gt;&#xA;&lt;p&gt;The premise that I wil be experimenting with is to determine what words in my post titles are &amp;quot;interesting&amp;quot; and to then order the suggested-similar posts first by a score based upon how many interesting words they share &lt;em&gt;and then&lt;/em&gt; by the similarity score that I already have.&lt;/p&gt;&#xA;&lt;p&gt;The model that I&#x27;ll be training for this is called &amp;quot;TF-IDF&amp;quot; or &amp;quot;Term Frequency - Inverse Document Frequency&amp;quot; and it looks at every word in every blog post and considers how many times that word appears in the document (the more often, the more likely that the document relates to the word) and how many times it appears across multiple documents (the more often, the more common and less &amp;quot;specific&amp;quot; it&#x27;s likely to be).&lt;/p&gt;&#xA;&lt;p&gt;For each blog post that I&#x27;m looking for similar posts to, I&#x27;ll:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;take the words from its title&lt;/li&gt;&#xA;&lt;li&gt;take the words from another post&#x27;s title&lt;/li&gt;&#xA;&lt;li&gt;add together all of the TF-IDF scores for words that appear in both titles (the higher the score for each word, the greater the relevance)&lt;/li&gt;&#xA;&lt;li&gt;repeat until all other post titles have been compared&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Taking the example from above that didn&#x27;t have particularly good similar-post recommendations, the words in its title will have the following scores:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;Word&lt;/th&gt;&#xA;&lt;th&gt;Score&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Simple&lt;/td&gt;&#xA;&lt;td&gt;0.6618375&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;TypeScript&lt;/td&gt;&#xA;&lt;td&gt;4.39835453&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;type&lt;/td&gt;&#xA;&lt;td&gt;0.7873714&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;definitions&lt;/td&gt;&#xA;&lt;td&gt;2.60178781&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;for&lt;/td&gt;&#xA;&lt;td&gt;0&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;AMD&lt;/td&gt;&#xA;&lt;td&gt;3.81998682&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;modules&lt;/td&gt;&#xA;&lt;td&gt;3.96386051&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;.. so it should be clear that any other titles that contain the word &amp;quot;TypeScript&amp;quot; will be given a boost.&lt;/p&gt;&#xA;&lt;p&gt;This is by no means a perfect system as there will often be posts whose main topics are similar but whose titles are not. The example from earlier that fastText generated really good similar-post suggestions for is a great illustration of this:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Learning F# via some Machine Learning: The Single Layer Perceptron&lt;/strong&gt;&lt;br&gt;&#xA;How are barcodes read?? (Library-less image processing in C#)&lt;br&gt;&#xA;Writing F# to implement &#x27;The Single Layer Perceptron&#x27;&lt;br&gt;&#xA;Face or no face (finding faces in photos using C# and AccordNET)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;All of them are investigations into some form of machine learning or computer vision but the titles share very little in common. It&#x27;s likely that the prediction quality of this one will actually suffer a little with the change I&#x27;m introducing but I&#x27;m looking for an overall improvement, across the entire blog. I&#x27;m also not looking for a perfect general solution, I&#x27;m trying to find something that works well for &lt;em&gt;my&lt;/em&gt; data (again, bearing in mind that there is a relatively small quantity of it as there are only around 120 posts, which doesn&#x27;t give the computer a huge amount of data to work from).&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(It&#x27;s also worth noting that the way I implement this in my blog is that I maintain two lists - the manually-curated list that I had before that had links for about a dozen posts and a machine-generated list; if there are manual links present then they will be displayed and the auto-generated ones will be hidden - so if I find that I have a particuarly awkward post where the machine can&#x27;t find nice matches then I can always tidy it up myself by manually creating the related-post links for that post)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Implementation&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;Last time&lt;/a&gt;, I had code that was reading and parsing my blog posts into a &amp;quot;postsWithDocuments&amp;quot; list.&lt;/p&gt;&#xA;&lt;p&gt;After training the fastText model, I&#x27;ll train a TF-IDF model on all of the documents. I&#x27;ll then go back round each document again, have this new model &amp;quot;Process&amp;quot; them and retrieve Frequency values for each word. These values allow for a score to be generated - since the scores depend upon how often a word appears in a given document, the scores will vary from one blog post to another and so I&#x27;m taking an average score for each distinct word.&lt;/p&gt;&#xA;&lt;p&gt;(Confession: I&#x27;m not 100% sure that this averaging is the ideal approach here but it seems to be doing a good enough job and I&#x27;m only fiddling around with things, so &lt;em&gt;good enough&lt;/em&gt; should be all that I need)&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Console.WriteLine(&amp;quot;Training TF-IDF model..&amp;quot;);&#xA;var tfidf = new TFIDF(pipeline.Language, version: 0, tag: &amp;quot;&amp;quot;);&#xA;await tfidf.Train(postsWithDocuments.Select(postWithDocument =&amp;gt; postWithDocument.Document));&#xA;&#xA;Console.WriteLine(&amp;quot;Getting average TF-IDF weights per word..&amp;quot;);&#xA;var tokenValueTFIDF = new Dictionary&amp;lt;string, List&amp;lt;float&amp;gt;&amp;gt;(StringComparer.OrdinalIgnoreCase);&#xA;foreach (var doc in postsWithDocuments.Select(postWithDocument =&amp;gt; postWithDocument.Document))&#xA;{&#xA;    // Calling &amp;quot;Process&amp;quot; on the document updates data on the tokens within the document&#xA;    // (specifically, the token.Frequency value)&#xA;    tfidf.Process(doc);&#xA;    foreach (var sentence in doc)&#xA;    {&#xA;        foreach (var token in sentence)&#xA;        {&#xA;            if (!tokenValueTFIDF.TryGetValue(token.Value, out var freqs))&#xA;            {&#xA;                freqs = new();&#xA;                tokenValueTFIDF.Add(token.Value, freqs);&#xA;            }&#xA;            freqs.Add(token.Frequency);&#xA;        }&#xA;    }&#xA;}&#xA;var averagedTokenValueTFIDF = tokenValueTFIDF.ToDictionary(&#xA;    entry =&amp;gt; entry.Key,&#xA;    entry =&amp;gt; entry.Value.Average(), StringComparer.OrdinalIgnoreCase&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now, with a couple of helper methods:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static float GetProximityByTitleTFIDF(&#xA;    string similarPostTitle,&#xA;    HashSet&amp;lt;string&amp;gt; tokenValuesInInitialPostTitle,&#xA;    Dictionary&amp;lt;string, float&amp;gt; averagedTokenValueTFIDF,&#xA;    Pipeline pipeline)&#xA;{&#xA;    return GetAllTokensForText(similarPostTitle, pipeline)&#xA;        .Where(token =&amp;gt; tokenValuesInInitialPostTitle.Contains(token.Value))&#xA;        .Sum(token =&amp;gt;&#xA;        {&#xA;            var tfidfValue = averagedTokenValueTFIDF.TryGetValue(token.Value, out var score)&#xA;                ? score&#xA;                : 0;&#xA;            if (tfidfValue &amp;lt;= 0)&#xA;            {&#xA;                // Ignore any tokens that report a negative impact (eg. punctuation or&#xA;                // really common words like &amp;quot;in&amp;quot;)&#xA;                return 0;&#xA;            }&#xA;            return tfidfValue;&#xA;        });&#xA;}&#xA;&#xA;private static IEnumerable&amp;lt;IToken&amp;gt; GetAllTokensForText(string text, Pipeline pipeline)&#xA;{&#xA;    var doc = new Document(text, pipeline.Language);&#xA;    pipeline.ProcessSingle(doc);&#xA;    return doc.SelectMany(sentence =&amp;gt; sentence);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. it&#x27;s possible, for any given post, to sort the titles of the other posts according to how many &amp;quot;interesting&amp;quot; words (and &lt;em&gt;how&lt;/em&gt; &amp;quot;interesting&amp;quot; they are) they have in common like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// Post 82 on my blog is &amp;quot;Simple TypeScript type definitions for AMD modules&amp;quot;&#xA;var post82 = postsWithDocuments.Select(p =&amp;gt; p.Post).FirstOrDefault(p =&amp;gt; p.ID == 82);&#xA;var title = post82.Title;&#xA;&#xA;var tokenValuesInTitle =&#xA;    GetAllTokensForText(NormaliseSomeCommonTerms(title), pipeline)&#xA;        .Select(token =&amp;gt; token.Value)&#xA;        .ToHashSet(StringComparer.OrdinalIgnoreCase);&#xA;&#x9;&#x9;&#xA;var others = postsWithDocuments&#xA;    .Select(p =&amp;gt; p.Post)&#xA;    .Where(p =&amp;gt; p.ID != post82.ID)&#xA;    .Select(p =&amp;gt; new&#xA;    {&#xA;        Post = p,&#xA;        ProximityByTitleTFIDF = GetProximityByTitleTFIDF(&#xA;            NormaliseSomeCommonTerms(p.Title),&#xA;            tokenValuesInTitle,&#xA;            averagedTokenValueTFIDF,&#xA;            pipeline&#xA;        )&#xA;    })&#xA;    .OrderByDescending(similarResult =&amp;gt; similarResult.ProximityByTitleTFIDF);&#xA;&#x9;&#xA;foreach (var result in others)&#xA;    Console.WriteLine($&amp;quot;{result.ProximityByTitleTFIDF:0.000} {result.Post.Title}&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The top 11 scores (after which, everything has a TF-IDF proximity score of zero) are these:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;7.183 Parsing TypeScript definitions (functional-ly.. ish)&lt;br&gt;&#xA;4.544 TypeScript State Machines&lt;br&gt;&#xA;4.544 Writing React components in TypeScript&lt;br&gt;&#xA;4.544 TypeScript classes for (React) Flux actions&lt;br&gt;&#xA;4.544 TypeScript / ES6 classes for React components - without the hacks!&lt;br&gt;&#xA;4.544 Writing a Brackets extension in TypeScript, in Brackets&lt;br&gt;&#xA;0.796 A static type system is a wonderful message to the present and future&lt;br&gt;&#xA;0.796 A static type system is a wonderful message to the present and future - Supplementary&lt;br&gt;&#xA;0.796 Type aliases in Bridge.NET (C#)&lt;br&gt;&#xA;0.796 Hassle-free immutable type updates in C#&lt;br&gt;&#xA;0.000 I love Immutable Data&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;So the idea is to then use the fastText similarity score when deciding which of these matches is best.&lt;/p&gt;&#xA;&lt;p&gt;There are all sorts of ways that these two scoring mechanisms could be combined - eg. I could take the 20 titles with the greatest TF-IDF proximity scores and then order them by similarity (ie. which results the fastText model thinks are best) or I could reverse it and take the 20 titles that fastText thought were best and &lt;em&gt;then&lt;/em&gt; take the three with the greatest TF-IDF proximity scores from within those. For now, I&#x27;m using the simplest approach and ordering by the TF-IDF scores first and then by the fastText similarity model. So, from the above list, the 7.183-scoring post will be taken first and then 2 out of the 5 posts that have a TF-IDF score of 4.544 will be taken, according to which ones the fastText model thought were more similar.&lt;/p&gt;&#xA;&lt;p&gt;Again, there are lots of things that could be tweaked and fiddled with - and I imagine that I will experiment with them at some point. The main problem is that I have enough data across my posts that it&#x27;s tedious looking through the output to try to decide if I&#x27;ve improved things each time I make change but there &lt;em&gt;isn&#x27;t&lt;/em&gt; enough data that the algorithms have a huge pile of information to work on. Coupled with the fact that training takes a few minutes to run and I have recipe for frustration if I obsess too much about it. Right now, I&#x27;m happy enough with the suggestions and any that I want to manually override, I can do so easily.&lt;/p&gt;&#xA;&lt;h3&gt;Trying the code yourself&lt;/h3&gt;&#xA;&lt;p&gt;If you want to try out the code, you can find a complete sample in the &amp;quot;SimilarityWithTitleTFIDF&amp;quot; project in the solution of this repo: &lt;a href=&quot;https://github.com/ProductiveRage/BlogPostSimilarity&quot;&gt;BlogPostSimilarity&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3&gt;Has it helped?&lt;/h3&gt;&#xA;&lt;p&gt;Let&#x27;s return to those examples that I started with.&lt;/p&gt;&#xA;&lt;p&gt;Good suggestions from last time:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Learning F# via some Machine Learning: The Single Layer Perceptron&lt;/strong&gt;&lt;br&gt;&#xA;How are barcodes read?? (Library-less image processing in C#)&lt;br&gt;&#xA;Writing F# to implement &#x27;The Single Layer Perceptron&#x27;&lt;br&gt;&#xA;Face or no face (finding faces in photos using C# and AccordNET)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;Less&lt;/em&gt; good suggestions:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Simple TypeScript type definitions for AMD modules&lt;/strong&gt;&lt;br&gt;&#xA;STA ApartmentState with ASP.Net MVC&lt;br&gt;&#xA;WCF with JSON (and nullable types)&lt;br&gt;&#xA;The joys of AutoMapper&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Now, the not-very-good one has improved and has these offered:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Simple TypeScript type definitions for AMD modules&lt;/strong&gt;&lt;br&gt;&#xA;Parsing TypeScript definitions (functional-ly.. ish)&lt;br&gt;&#xA;TypeScript State Machines&lt;br&gt;&#xA;Writing a Brackets extension in TypeScript, in Brackets&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. but, as I said before, the good suggestions are now not &lt;em&gt;as&lt;/em&gt; good as they were:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;How are barcodes read?? (Library-less image processing in C#)&lt;/strong&gt;&lt;br&gt;&#xA;Face or no face (finding faces in photos using C# and Accord.NET)&lt;br&gt;&#xA;Implementing F#-inspired &amp;quot;with&amp;quot; updates for immutable classes in C#&lt;br&gt;&#xA;A follow-up to &amp;quot;Implementing F#-inspired &#x27;with&#x27; updates in C#&amp;quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;There are lots of suggestions that &lt;em&gt;are&lt;/em&gt; still very good - eg.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Creating a C# (&amp;quot;Roslyn&amp;quot;) Analyser - For beginners by a beginner&lt;/strong&gt;&lt;br&gt;&#xA;Using Roslyn to identify unused and undeclared variables in VBScript WSC components&lt;br&gt;&#xA;Locating TODO comments with Roslyn&lt;br&gt;&#xA;Using Roslyn code fixes to make the &amp;quot;Friction-less immutable objects in Bridge&amp;quot; even easier&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Migrating my Full Text Indexer to .NET Core (supporting multi-target NuGet packages)&lt;/strong&gt;&lt;br&gt;&#xA;Revisiting .NET Core tooling (Visual Studio 2017)&lt;br&gt;&#xA;The Full Text Indexer Post Round-up&lt;br&gt;&#xA;The NeoCities Challenge! aka The Full Text Indexer goes client-side!&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Dependency Injection with a WCF Service&lt;/strong&gt;&lt;br&gt;&#xA;Ramping up WCF Web Service Request Handling.. on IIS 6 with .Net 4.0&lt;br&gt;&#xA;Consuming a WCF Web Service from PHP&lt;br&gt;&#xA;WCF with JSON (and nullable types)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translating VBScript into C#&lt;/strong&gt;&lt;br&gt;&#xA;VBScript is DIM&lt;br&gt;&#xA;Using Roslyn to identify unused and undeclared variables in VBScript WSC components&lt;br&gt;&#xA;If you can keep your head when all about you are losing theirs and blaming it on VBScript&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. but still some less-good suggestions, like:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Auto-releasing Event Listeners&lt;/strong&gt;&lt;br&gt;&#xA;Writing React apps using Bridge.NET - The Dan Way (Part Three)&lt;br&gt;&#xA;Persistent Immutable Lists - Extended&lt;br&gt;&#xA;Extendable LINQ-compilable Mappers&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Problems in Immutability-land&lt;/strong&gt;&lt;br&gt;&#xA;Language detection and words-in-sentence classification in C#&lt;br&gt;&#xA;Using Roslyn to identify unused and undeclared variables in VBScript WSC components&lt;br&gt;&#xA;Writing a Brackets extension in TypeScript, in Brackets&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;However, having just looked through the matches to try to find any really awful suggestions, there aren&#x27;t many that jump out at me. And, informal as that may be as a measure of success, I&#x27;m fairly happy with that!&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/the-full-text-indexer-automating-index-generation&quot;&gt;The Full Text Indexer - Automating Index Generation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/dynamically-applying-interfaces-to-objects-part-2&quot;&gt;Dynamically applying interfaces to objects - Part 2&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Wed, 28 Apr 2021 21:56:00 GMT</pubDate>
            </item>
            <item>
                <title>Automating &quot;suggested / related posts&quot; links for my blog posts</title>
                <link>https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts</link>
                <guid>https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts</guid>
                <description>&lt;h3&gt;TL;DR&lt;/h3&gt;&#xA;&lt;p&gt;Using the same open source .NET library as I did in my last post (&lt;a href=&quot;https://www.productiverage.com/language-detection-and-wordsinsentence-classification-in-c-sharp&quot;&gt;Language detection and words-in-sentence classification in C#&lt;/a&gt;), I use some of its other machine learning capabilities to automatically generate &amp;quot;you may also be interested in&amp;quot; links to similar posts for any given post on this blog.&lt;/p&gt;&#xA;&lt;h3&gt;The current &amp;quot;You may also be interested in&amp;quot; functionality&lt;/h3&gt;&#xA;&lt;p&gt;This site has always had a way for me to link related posts together - for example, if you scroll to the bottom of &amp;quot;&lt;a href=&quot;https://www.productiverage.com/learning-f-sharp-via-some-machine-learning-the-single-layer-percepton&quot;&gt;Learning F# via some Machine Learning: The Single Layer Perceptron&lt;/a&gt;&amp;quot; then it suggests a link to &amp;quot;&lt;a href=&quot;https://www.productiverage.com/face-or-no-face-finding-faces-in-photos-using-c-sharp-and-accordnet&quot;&gt;Face or no face (finding faces in photos using C# and Accord.NET)&lt;/a&gt;&amp;quot; on the basis that you might be super-excited into my fiddlings with computers being trained how to make decisions on their own. But there aren&#x27;t many of these links because they&#x27;re something that I have to maintain manually. Firstly, that means that I have to remember / consider every previous post and decide whether it might be worth linking to the new post that I&#x27;ve just finished writing and, secondly, I often just forget.&lt;/p&gt;&#xA;&lt;p&gt;There are models in the &lt;a href=&quot;https://github.com/curiosity-ai/catalyst&quot;&gt;Catalyst&lt;/a&gt; library* that make this possible and so I thought that I would see whether I could train it with my blog post data and then incorporate the suggestions into the final content.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(Again, see my &lt;a href=&quot;https://www.productiverage.com/language-detection-and-wordsinsentence-classification-in-c-sharp&quot;&gt;last post&lt;/a&gt; for more details on this library and a little blurb about my previous employers who are doing exciting things in the Enterprise Search space)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Specifically, I&#x27;ll be using the &lt;a href=&quot;https://en.wikipedia.org/wiki/FastText&quot;&gt;fastText&lt;/a&gt; model that was published by &lt;a href=&quot;https://github.com/facebookresearch/fastText&quot;&gt;Facebook&#x27;s AI Research lab&lt;/a&gt; in 2015 and then &lt;a href=&quot;https://github.com/curiosity-ai/catalyst/tree/master/Catalyst/src/Models/Embeddings/FastText&quot;&gt;rewritten in C#&lt;/a&gt; as part of the Catalyst library.&lt;/p&gt;&#xA;&lt;h3&gt;Getting my blog post articles&lt;/h3&gt;&#xA;&lt;p&gt;When I first launched my blog (just over a decade ago), I initially hosted it somewhere as an ASP.NET MVC application. Largely because I wanted to try my hand at writing an MVC app from scratch and fiddling with various settings, I think.. and partly because it felt like the &amp;quot;natural&amp;quot; thing to do, seeing as I was employed as a .NET Developer at the time!&lt;/p&gt;&#xA;&lt;p&gt;To keep things simple, I had a single text file for each blog post and the filenames were of a particular format containing a unique post ID, date and time of publishing, whether it should appear in the &amp;quot;Highlights&amp;quot; column and any tags that should be associated with it. Like this:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;1,2011,3,14,20,14,2,0,Immutability.txt&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;That&#x27;s the very first post (it has ID 1), it was published on 2011-03-14 at 20:14:02 and it is not shown in the Highlights column (hence the final zero). It has a single tag of &amp;quot;Immutability&amp;quot;. Although it has a &amp;quot;.txt&amp;quot; extension, it&#x27;s actually markdown content, so &amp;quot;.md&amp;quot; would have been more logical (the reason why I chose &amp;quot;.txt&amp;quot; over &amp;quot;.md&amp;quot; will likely remain forever lost in the mists of time!)&lt;/p&gt;&#xA;&lt;p&gt;A couple of years later, I came across the project &lt;a href=&quot;https://neocities.org/&quot;&gt;neocities.org&lt;/a&gt; and thought that it was a cool idea and did some (perhaps slightly hacky) work to make things work as a static site (including pushing the search logic entirely to the client) as described in &lt;a href=&quot;https://www.productiverage.com/the-neocities-challenge-aka-the-full-text-indexer-goes-clientside&quot;&gt;The NeoCities Challenge!&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Some &lt;em&gt;more&lt;/em&gt; years later, GitHub Pages started supporting custom domains over HTTPS (in May 2018 according to &lt;a href=&quot;https://github.blog/2018-05-01-github-pages-custom-domains-https/&quot;&gt;this&lt;/a&gt;) and so, having already moved web hosts once due to wildly inconsistent performance from the first provider, I decided to use this to-static-site logic and start publishing via GitHub Pages.&lt;/p&gt;&#xA;&lt;p&gt;This is a long-winded way of saying that, although I publish my content these days as a static site, I write new content by running the original blog app locally and then turning it into static content later. Meaning that the original individual post files are available in the ASP.NET MVC Blog GitHub repo here:&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&quot;https://github.com/ProductiveRage/Blog/tree/master/Blog/App_Data/Posts&quot;&gt;github.com/ProductiveRage/Blog/tree/master/Blog/App_Data/Posts&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Therefore, if you were sufficiently curious and wanted to play along at home, you can also access the original markdown files for my blog posts and see if you can reproduce my results.&lt;/p&gt;&#xA;&lt;p&gt;Following shortly is some code to do just that. GitHub has an API that allows you to query folder contents and so we can get a list of blog post files without having to do anything arduous like clone the entire repo or trying to scrape the information from the site or even creating an authenticated API access application because GitHub allows us rate-limited non-authenticated access for free! Once we have the list of files, each will have a &amp;quot;download_url&amp;quot; that we can retrieve the raw content from.&lt;/p&gt;&#xA;&lt;p&gt;To get the list of blog post files, you would call:&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts?ref=master&quot;&gt;api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts?ref=master&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;.. and get results that look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;[&#xA;  {&#xA;    &amp;quot;name&amp;quot;: &amp;quot;1,2011,3,14,20,14,2,0,Immutability.txt&amp;quot;,&#xA;    &amp;quot;path&amp;quot;: &amp;quot;Blog/App_Data/Posts/1,2011,3,14,20,14,2,0,Immutability.txt&amp;quot;,&#xA;    &amp;quot;sha&amp;quot;: &amp;quot;b243ea15c891f73550485af27fa06dd1ccb8bf45&amp;quot;,&#xA;    &amp;quot;size&amp;quot;: 18965,&#xA;    &amp;quot;url&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts/1,2011,3,14,20,14,2,0,Immutability.txt?ref=master&amp;quot;,&#xA;    &amp;quot;html_url&amp;quot;: &amp;quot;https://github.com/ProductiveRage/Blog/blob/master/Blog/App_Data/Posts/1,2011,3,14,20,14,2,0,Immutability.txt&amp;quot;,&#xA;    &amp;quot;git_url&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/git/blobs/b243ea15c891f73550485af27fa06dd1ccb8bf45&amp;quot;,&#xA;    &amp;quot;download_url&amp;quot;: &amp;quot;https://raw.githubusercontent.com/ProductiveRage/Blog/master/Blog/App_Data/Posts/1%2C2011%2C3%2C14%2C20%2C14%2C2%2C0%2CImmutability.txt&amp;quot;,&#xA;    &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,&#xA;    &amp;quot;_links&amp;quot;: {&#xA;      &amp;quot;self&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts/1,2011,3,14,20,14,2,0,Immutability.txt?ref=master&amp;quot;,&#xA;      &amp;quot;git&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/git/blobs/b243ea15c891f73550485af27fa06dd1ccb8bf45&amp;quot;,&#xA;      &amp;quot;html&amp;quot;: &amp;quot;https://github.com/ProductiveRage/Blog/blob/master/Blog/App_Data/Posts/1,2011,3,14,20,14,2,0,Immutability.txt&amp;quot;&#xA;    }&#xA;  },&#xA;  {&#xA;    &amp;quot;name&amp;quot;: &amp;quot;10,2011,8,30,19,06,0,0,Mercurial.txt&amp;quot;,&#xA;    &amp;quot;path&amp;quot;: &amp;quot;Blog/App_Data/Posts/10,2011,8,30,19,06,0,0,Mercurial.txt&amp;quot;,&#xA;    &amp;quot;sha&amp;quot;: &amp;quot;ab6cf2fc360948212e29c64d9c886b3dbfe0d6fc&amp;quot;,&#xA;    &amp;quot;size&amp;quot;: 3600,&#xA;    &amp;quot;url&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts/10,2011,8,30,19,06,0,0,Mercurial.txt?ref=master&amp;quot;,&#xA;    &amp;quot;html_url&amp;quot;: &amp;quot;https://github.com/ProductiveRage/Blog/blob/master/Blog/App_Data/Posts/10,2011,8,30,19,06,0,0,Mercurial.txt&amp;quot;,&#xA;    &amp;quot;git_url&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/git/blobs/ab6cf2fc360948212e29c64d9c886b3dbfe0d6fc&amp;quot;,&#xA;    &amp;quot;download_url&amp;quot;: &amp;quot;https://raw.githubusercontent.com/ProductiveRage/Blog/master/Blog/App_Data/Posts/10%2C2011%2C8%2C30%2C19%2C06%2C0%2C0%2CMercurial.txt&amp;quot;,&#xA;    &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,&#xA;    &amp;quot;_links&amp;quot;: {&#xA;      &amp;quot;self&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts/10,2011,8,30,19,06,0,0,Mercurial.txt?ref=master&amp;quot;,&#xA;      &amp;quot;git&amp;quot;: &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/git/blobs/ab6cf2fc360948212e29c64d9c886b3dbfe0d6fc&amp;quot;,&#xA;      &amp;quot;html&amp;quot;: &amp;quot;https://github.com/ProductiveRage/Blog/blob/master/Blog/App_Data/Posts/10,2011,8,30,19,06,0,0,Mercurial.txt&amp;quot;&#xA;    }&#xA;  },&#xA;  ..&#xA;  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;While the API is rate-limited, retrieving content via the &amp;quot;download_url&amp;quot; locations is not - so we can make a single API call for the list and then download all of the individual files that we want.&lt;/p&gt;&#xA;&lt;p&gt;Note that there are a couple of files in that folders that are NOT blog posts (such as the &amp;quot;RelatedPosts.txt&amp;quot; file, which is the way that I manually associate &amp;quot;You may also be interested in&amp;quot; post) and so each filename will have to be checked to ensure that it matches the format shown above.&lt;/p&gt;&#xA;&lt;p&gt;The title of the blog post is not in the file name, it is always the first line of the content in the file (to obtain it, we&#x27;ll need to process the file as markdown content, convert it to plain text and then look at that first line).&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static async Task&amp;lt;IEnumerable&amp;lt;BlogPost&amp;gt;&amp;gt; GetBlogPosts()&#xA;{&#xA;    // Note: The GitHub API is rate limited quite severely for non-authenticated apps, so we just&#xA;    // call it once for the list of files and then retrieve them all further down via the Download&#xA;    // URLs (which don&#x27;t count as API calls). Still, if you run this code repeatedly and start&#xA;    // getting 403 &amp;quot;rate limited&amp;quot; responses then you might have to hold off for a while.&#xA;    string namesAndUrlsJson;&#xA;    using (var client = new WebClient())&#xA;    {&#xA;        // The API refuses requests without a User Agent, so set one before calling (see&#xA;        // https://docs.github.com/en/rest/overview/resources-in-the-rest-api#user-agent-required)&#xA;        client.Headers.Add(HttpRequestHeader.UserAgent, &amp;quot;ProductiveRage Blog Post Example&amp;quot;);&#xA;        namesAndUrlsJson = await client.DownloadStringTaskAsync(new Uri(&#xA;            &amp;quot;https://api.github.com/repos/ProductiveRage/Blog/contents/Blog/App_Data/Posts?ref=master&amp;quot;&#xA;        ));&#xA;    }&#xA;&#xA;    // Deserialise the response into an array of entries that have Name and Download_Url properties&#xA;    var namesAndUrls = JsonConvert.DeserializeAnonymousType(&#xA;        namesAndUrlsJson,&#xA;        new[] { new { Name = &amp;quot;&amp;quot;, Download_Url = (Uri)null } }&#xA;    );&#xA;&#xA;    return await Task.WhenAll(namesAndUrls&#xA;        .Select(entry =&amp;gt;&#xA;        {&#xA;            var fileNameSegments = Path.GetFileNameWithoutExtension(entry.Name).Split(&amp;quot;,&amp;quot;);&#xA;            if (fileNameSegments.Length &amp;lt; 8)&#xA;                return default;&#xA;            if (!int.TryParse(fileNameSegments[0], out var id))&#xA;                return default;&#xA;            var dateContent = string.Join(&amp;quot;,&amp;quot;, fileNameSegments.Skip(1).Take(6));&#xA;            if (!DateTime.TryParseExact(dateContent, &amp;quot;yyyy,M,d,H,m,s&amp;quot;, default, default, out var date))&#xA;                return default;&#xA;            return (PostID: id, PublishedAt: date, entry.Download_Url);&#xA;        })&#xA;        .Where(entry =&amp;gt; entry != default)&#xA;        .Select(async entry =&amp;gt;&#xA;        {&#xA;            // Read the file content as markdown and parse into plain text (the first line of which&#xA;            // will be the title of the post)&#xA;            string markdown;&#xA;            using (var client = new WebClient())&#xA;            {&#xA;                markdown = await client.DownloadStringTaskAsync(entry.Download_Url);&#xA;            }&#xA;            var plainText = Markdown.ToPlainText(markdown);&#xA;            var title = plainText.Replace(&amp;quot;\r\n&amp;quot;, &amp;quot;\n&amp;quot;).Replace(&#x27;\r&#x27;, &#x27;\n&#x27;).Split(&#x27;\n&#x27;).First();&#xA;            return new BlogPost(entry.PostID, title, plainText, entry.PublishedAt);&#xA;        })&#xA;    );&#xA;}&#xA;&#xA;private sealed class BlogPost&#xA;{&#xA;    public BlogPost(int id, string title, string plainTextContent, DateTime publishedAt)&#xA;    {&#xA;        ID = id;&#xA;        Title = !string.IsNullOrWhiteSpace(title)&#xA;            ? title&#xA;            : throw new ArgumentException(&amp;quot;may not be null, blank or whitespace-only&amp;quot;);&#xA;        PlainTextContent = !string.IsNullOrWhiteSpace(plainTextContent)&#xA;            ? plainTextContent&#xA;            : throw new ArgumentException(&amp;quot;may not be null, blank or whitespace-only&amp;quot;);&#xA;        PublishedAt = publishedAt;&#xA;    }&#xA;&#xA;    public int ID{ get; }&#xA;    public string Title { get; }&#xA;    public string PlainTextContent { get; }&#xA;    public DateTime PublishedAt { get; }&#xA;}    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;(Note: I use the &lt;a href=&quot;https://github.com/xoofx/markdig&quot;&gt;Markdig&lt;/a&gt; library to process markdown)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Training a FastText model&lt;/h3&gt;&#xA;&lt;p&gt;This raw blog post content needs to transformed into Catalyst &amp;quot;documents&amp;quot;, then tokenised (split into individual sentences and words), then fed into a FastText model trainer.&lt;/p&gt;&#xA;&lt;p&gt;Before getting to the code, I want to discuss a couple of oddities coming up. Firstly, Catalyst documents are required to train the FastText model and each document instance must be uniquely identified by a &lt;strong&gt;UID128&lt;/strong&gt; value, which is fine because we can generate them from the Title text of each blog post using the &amp;quot;Hash128()&amp;quot; extension method in Catalyst. However, (as we&#x27;ll see a bit further down), when you ask for vectors* from the FastText model for the processed documents, each vector comes with a &amp;quot;Token&amp;quot; string that is the ID of the source document - so that has to be parsed &lt;em&gt;back&lt;/em&gt; into a &lt;strong&gt;UID128&lt;/strong&gt;. I&#x27;m not quite sure why the &amp;quot;Token&amp;quot; value isn&#x27;t also a &lt;strong&gt;UID128&lt;/strong&gt; but it&#x27;s no massive deal.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(Vectors are just 1D arrays of floating point values - the FastText algorithm does magic to produce vectors that represent the text of the documents such that the distance between them can be compared; the length of these arrays is determined by the &amp;quot;Dimensions&amp;quot; option shown below and shorter distances between vectors suggest more similar content)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Next, there are the FastText settings that I&#x27;ve used. The &lt;a href=&quot;https://github.com/curiosity-ai/catalyst&quot;&gt;Catalyst README&lt;/a&gt; has some code near the bottom for training a FastText embedding model but I didn&#x27;t have much luck with the default options. Firstly, when I used the &amp;quot;FastText.ModelType.CBow&amp;quot; option then I didn&#x27;t get any vectors generated and so I tried changing it to &amp;quot;FastText.ModelType.PVDM&amp;quot; and things started looked promising. Then I fiddled with some of the other settings. Some of which I have a rough idea what they mean and some, erm.. not so much.&lt;/p&gt;&#xA;&lt;p&gt;The settings that I ended up using are these:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var fastText = new FastText(language, version: 0, tag: &amp;quot;&amp;quot;);&#xA;fastText.Data.Type = FastText.ModelType.PVDM;&#xA;fastText.Data.Loss = FastText.LossType.NegativeSampling;&#xA;fastText.Data.IgnoreCase = true;&#xA;fastText.Data.Epoch = 50;&#xA;fastText.Data.Dimensions = 512;&#xA;fastText.Data.MinimumCount = 1;&#xA;fastText.Data.ContextWindow = 10;&#xA;fastText.Data.NegativeSamplingCount = 20;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;I already mentioned changing the Data.Type / ModelType and the LossType (&amp;quot;NegativeSampling&amp;quot;) is the value shown in the README. Then I felt like an obvious one to change was IgnoreCase, since that defaults to false and I think that I want it to be true - I don&#x27;t care about the casing in any words when it&#x27;s parsing my posts&#x27; content.&lt;/p&gt;&#xA;&lt;p&gt;Now the others.. well, this library is built to work with systems with 10s or 100s of 1,000s of documents and that is a LOT more data than I have (currently around 120 blog posts) and so I made a few tweaks based on that. The &amp;quot;Epoch&amp;quot; count is the number of iterations that the training process will go through when constructing its model - by default, this is only 5 but I have limited data (meaning there&#x27;s less for it to learn from but also that it&#x27;s faster to complete each iteration) and so I bumped that up to 50. Then &amp;quot;Dimensions&amp;quot; is the size of the vectors generated - again, I figured that with limited data I would want a higher value and so I picked 512 (a nice round number if you&#x27;re geeky enough) over the default 200. The &amp;quot;MinimumCount&amp;quot;, I believe, relates to how often a word may appear and it defaults to 5 so I pulled it down to 1. The &amp;quot;ContextWindow&amp;quot; is (again, I &lt;em&gt;think&lt;/em&gt;) how far to either side of any word that the process will look at in order to determine context - the larger the value, the more expensive the calculation; I bumped this from the default 5 up to 10. Then there&#x27;s the &amp;quot;NegativeSamplingCount&amp;quot; value.. I have to just put my hands up and say that I have no idea what that actually does, only that I seemed to be getting better results with a value of 20 than I was with the default of 10.&lt;/p&gt;&#xA;&lt;p&gt;With machine learning, there is almost always going to be some value to tweaking options (the &amp;quot;hyperparameters&amp;quot;, if we&#x27;re being all fancy) like this when building a model. Depending upon the model and the library, the defaults can be good for the general case but my tiny data set is not really what this library was intended for. Of course, machine learning &lt;em&gt;experts&lt;/em&gt; have more idea &lt;em&gt;what&lt;/em&gt; they&#x27;re tweaking and (sometimes, at least) hopefully what results they&#x27;ll get.. but I&#x27;m happy enough with where I&#x27;ve ended up with these.&lt;/p&gt;&#xA;&lt;p&gt;This talk about what those machine learning experts do brings me on to the final thing that I wanted to talk about before showing the code; a little pre-processing / data-massaging. The better the data is that goes in, generally the better the results that come out will be. So another less glamorous part of the life of a Data Scientist is cleaning up data for training models.&lt;/p&gt;&#xA;&lt;p&gt;In my case, that only extended to noticing that a few terms didn&#x27;t seem to be getting recognised as essentially being the same thing and so I wanted to give it a little hand - for example, a fair number of my posts are about my &amp;quot;Full Text Indexer&amp;quot; project and so it probably makes sense to replace any instances of that string with a single concatenated word &amp;quot;FullTextIndexer&amp;quot;. And I have a range of posts about React but I didn&#x27;t want it to get confused with the verb &amp;quot;react&amp;quot; and so I replaced any &amp;quot;React&amp;quot; occurrence with &amp;quot;ReactJS&amp;quot; (now, this probably means that some &amp;quot;React&amp;quot; verb occurrences were incorrectly changed but I made the replacements of this word in a case-sensitive manner and felt like I would have likely used it as the noun more often than a verb with a captial letter due to the nature of my posts).&lt;/p&gt;&#xA;&lt;p&gt;So I have a method to tidy up the plain text content a little:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static string NormaliseSomeCommonTerms(string text) =&amp;gt; text&#xA;    .Replace(&amp;quot;.NET&amp;quot;, &amp;quot;NET&amp;quot;, StringComparison.OrdinalIgnoreCase)&#xA;    .Replace(&amp;quot;Full Text Indexer&amp;quot;, &amp;quot;FullTextIndexer&amp;quot;, StringComparison.OrdinalIgnoreCase)&#xA;    .Replace(&amp;quot;Bridge.net&amp;quot;, &amp;quot;BridgeNET&amp;quot;, StringComparison.OrdinalIgnoreCase)&#xA;    .Replace(&amp;quot;React&amp;quot;, &amp;quot;ReactJS&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now let&#x27;s get training!&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Console.WriteLine(&amp;quot;Reading posts from GitHub repo..&amp;quot;);&#xA;var posts = await GetBlogPosts();&#xA;&#xA;Console.WriteLine(&amp;quot;Parsing documents..&amp;quot;);&#xA;Storage.Current = new OnlineRepositoryStorage(new DiskStorage(&amp;quot;catalyst-models&amp;quot;));&#xA;var language = Language.English;&#xA;var pipeline = Pipeline.For(language);&#xA;var postsWithDocuments = posts&#xA;    .Select(post =&amp;gt;&#xA;    {&#xA;        var document = new Document(NormaliseSomeCommonTerms(post.PlainTextContent), language)&#xA;        {&#xA;            UID = post.Title.Hash128()&#xA;        };&#xA;        pipeline.ProcessSingle(document);&#xA;        return (Post: post, Document: document);&#xA;    })&#xA;    .ToArray(); // Call ToArray to force evaluation of the document processing now&#xA;&#xA;Console.WriteLine(&amp;quot;Training FastText model..&amp;quot;);&#xA;var fastText = new FastText(language, version: 0, tag: &amp;quot;&amp;quot;);&#xA;fastText.Data.Type = FastText.ModelType.PVDM;&#xA;fastText.Data.Loss = FastText.LossType.NegativeSampling;&#xA;fastText.Data.IgnoreCase = true;&#xA;fastText.Data.Epoch = 50;&#xA;fastText.Data.Dimensions = 512;&#xA;fastText.Data.MinimumCount = 1;&#xA;fastText.Data.ContextWindow = 10;&#xA;fastText.Data.NegativeSamplingCount = 20;&#xA;fastText.Train(&#xA;    postsWithDocuments.Select(postWithDocument =&amp;gt; postWithDocument.Document),&#xA;    trainingStatus: update =&amp;gt; Console.WriteLine($&amp;quot; Progress: {update.Progress}, Epoch: {update.Epoch}&amp;quot;)&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;Identifying similar documents using the model&lt;/h3&gt;&#xA;&lt;p&gt;Now that a model has been built that can represent all of my blog posts as vectors, we need to go through those post / vector combinations and identify others that are similar to it.&lt;/p&gt;&#xA;&lt;p&gt;This will be achieved by using the &lt;a href=&quot;https://github.com/curiosity-ai/hnsw-sharp&quot;&gt;HNSW.NET&lt;/a&gt; NuGet package that enables K-Nearest Neighbour (k-NN) searches over &amp;quot;high-dimensional space&amp;quot;*.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(This just means that the vectors are relatively large; 512 in this case - two dimensions would be a point on a flat plane, three dimensions would be a physical point in space, anything with more dimensions that that is in &amp;quot;higher-dimensional space&amp;quot;.. though that&#x27;s not to say that any more than three dimensions is definitely a bad fit for a regular k-NN search but 512 dimensions IS going to be a bad fit and the HNSW approach will be much more efficient)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;There are useful examples on the &lt;a href=&quot;https://github.com/curiosity-ai/hnsw-sharp#how-to-build-a-graph&quot;&gt;README&lt;/a&gt; about &amp;quot;&lt;strong&gt;How to build a graph?&lt;/strong&gt;&amp;quot; and &amp;quot;&lt;strong&gt;How to run k-NN search?&lt;/strong&gt;&amp;quot; and tweaking those for the data that I have so far leads to this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Console.WriteLine(&amp;quot;Building recommendations..&amp;quot;);&#xA;&#xA;// Combine the blog post data with the FastText-generated vectors&#xA;var results = fastText&#xA;    .GetDocumentVectors()&#xA;    .Select(result =&amp;gt;&#xA;    {&#xA;        // Each document vector instance will include a &amp;quot;token&amp;quot; string that may be mapped back to the&#xA;        // UID of the document for each blog post. If there were a large number of posts to deal with&#xA;        // then a dictionary to match UIDs to blog posts would be sensible for performance but I only&#xA;        // have a 100&#x2B; and so a LINQ &amp;quot;First&amp;quot; scan over the list will suffice.&#xA;        var uid = UID128.Parse(result.Token);&#xA;        var postForResult = postsWithDocuments.First(&#xA;            postWithDocument =&amp;gt; postWithDocument.Document.UID == uid&#xA;        );&#xA;        return (UID: uid, result.Vector, postForResult.Post);&#xA;    })&#xA;    .ToArray(); // ToArray since we enumerate multiple times below&#xA;&#xA;// Construct a graph to search over, as described at&#xA;// https://github.com/curiosity-ai/hnsw-sharp#how-to-build-a-graph&#xA;var graph = new SmallWorld&amp;lt;(UID128 UID, float[] Vector, BlogPost Post), float&amp;gt;(&#xA;    distance: (to, from) =&amp;gt; CosineDistance.NonOptimized(from.Vector, to.Vector),&#xA;    DefaultRandomGenerator.Instance,&#xA;    new() { M = 15, LevelLambda = 1 / Math.Log(15) }&#xA;);&#xA;graph.AddItems(results);&#xA;&#xA;// For every post, use the &amp;quot;KNNSearch&amp;quot; method on the graph to find the three most similar posts&#xA;const int maximumNumberOfResultsToReturn = 3;&#xA;var postsWithSimilarResults = results&#xA;    .Select(result =&amp;gt;&#xA;    {&#xA;        // Request one result too many from the KNNSearch call because it&#x27;s expected that the original&#xA;        // post will come back as the best match and we&#x27;ll want to exclude that&#xA;        var similarResults = graph&#xA;            .KNNSearch(result, maximumNumberOfResultsToReturn &#x2B; 1)&#xA;            .Where(similarResult =&amp;gt; similarResult.Item.UID != result.UID)&#xA;            .Take(maximumNumberOfResultsToReturn); // Just in case the original post wasn&#x27;t included&#xA;&#xA;        return new&#xA;        {&#xA;            result.Post,&#xA;            Similar = similarResults&#xA;                .Select(similarResult =&amp;gt; new&#xA;                {&#xA;                    similarResult.Id,&#xA;                    similarResult.Item.Post,&#xA;                    similarResult.Distance&#xA;                })&#xA;                .ToArray()&#xA;        };&#xA;    })&#xA;    .OrderBy(result =&amp;gt; result.Post.Title, StringComparer.OrdinalIgnoreCase)&#xA;    .ToArray();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;And with that, there is a list of every post from my blog and a list of the three blog posts most similar to it!&lt;/p&gt;&#xA;&lt;p&gt;Well, &amp;quot;most similar&amp;quot; according to the model that we trained and the hyperparameters that we used to do so. As with many machine learning algorithms, it will have started from a random state and tweaked and tweaked until it&#x27;s time for it to stop (based upon the &amp;quot;Epoch&amp;quot; value in this FastText case) and so the results each time may be a little different.&lt;/p&gt;&#xA;&lt;p&gt;However, if we inspect the results like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;foreach (var postWithSimilarResults in postsWithSimilarResults)&#xA;{&#xA;    Console.WriteLine();&#xA;    Console.WriteLine(postWithSimilarResults.Post.Title);&#xA;    foreach (var similarResult in postWithSimilarResults.Similar.OrderBy(other =&amp;gt; other.Distance))&#xA;        Console.WriteLine($&amp;quot;{similarResult.Distance:0.000} {similarResult.Post.Title}&amp;quot;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. then there are some good results to be found! Like these:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Learning F# via some Machine Learning: The Single Layer Perceptron&lt;/strong&gt;&lt;br&gt;&#xA;0.229 How are barcodes read?? (Library-less image processing in C#)&lt;br&gt;&#xA;0.236 Writing F# to implement &#x27;The Single Layer Perceptron&#x27;&lt;br&gt;&#xA;0.299 Face or no face (finding faces in photos using C# and AccordNET)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translating VBScript into C#&lt;/strong&gt;&lt;br&gt;&#xA;0.257 VBScript is DIM&lt;br&gt;&#xA;0.371 If you can keep your head when all about you are losing theirs and blaming it on VBScript&lt;br&gt;&#xA;0.384 Using Roslyn to identify unused and undeclared variables in VBScript WSC components&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Writing React components in TypeScript&lt;/strong&gt;&lt;br&gt;&#xA;0.376 TypeScript classes for (React) Flux actions&lt;br&gt;&#xA;0.378 React and Flux with DuoCode&lt;br&gt;&#xA;0.410 React (and Flux) with Bridge.net&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;However, there are also some &lt;em&gt;less&lt;/em&gt; good ones - like these:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;A static type system is a wonderful message to the present and future&lt;/strong&gt;&lt;br&gt;&#xA;0.271 STA ApartmentState with ASP.Net MVC&lt;br&gt;&#xA;0.291 CSS Minification Regular Expressions&lt;br&gt;&#xA;0.303 Publishing RSS&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Simple TypeScript type definitions for AMD modules&lt;/strong&gt;&lt;br&gt;&#xA;0.162 STA ApartmentState with ASP.Net MVC&lt;br&gt;&#xA;0.189 WCF with JSON (and nullable types)&lt;br&gt;&#xA;0.191 The joys of AutoMapper&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Supporting IDispatch through the COMInteraction wrapper&lt;/strong&gt;&lt;br&gt;&#xA;0.394 A static type system is a wonderful message to the present and future&lt;br&gt;&#xA;0.411 TypeScript State Machines&lt;br&gt;&#xA;0.414 Simple TypeScript type definitions for AMD modules&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3&gt;Improving the results&lt;/h3&gt;&#xA;&lt;p&gt;I&#x27;d like to get this good enough that I can include auto-generated recommendations on my blog and I don&#x27;t feel like the consistency in quality is there yet. If they were all like the good examples then I&#x27;d be ploughing ahead right now with enabling it! But there are mediocre examples as well as those poorer ones above.&lt;/p&gt;&#xA;&lt;p&gt;It&#x27;s quite possible that I could get closer by experimenting with the hyperparameters more but that does tend to get tedious when you have to analyse the output of each run manually - looking through all the 120-ish post titles and deciding whether the supposed best matches are good or not. It would be lovely if I could concoct some sort of metric of &amp;quot;goodness&amp;quot; and then have the computer try lots of variations of parameters but one of the downsides of having relatively little data is that that is difficult*.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(On the flip side, if I had &lt;strong&gt;1,000s&lt;/strong&gt; of blog posts as source data then the difficult part would be manually labelling enough of them as &amp;quot;quite similar&amp;quot; in numbers sufficient for the computer to know if it&#x27;s done better or done worse with each experiment)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Fortunately, I have another trick up my sleeve - but I&#x27;m going to leave that for next time! This post is already more than long enough, I think. The plan is to combine results from &lt;em&gt;another&lt;/em&gt; model in the Catalyst with the FastText results and see if I can encourage things to look a bit neater.&lt;/p&gt;&#xA;&lt;h3&gt;Trying the code if you&#x27;re lazy&lt;/h3&gt;&#xA;&lt;p&gt;If you want to try fiddling with this code but don&#x27;t want to copy-paste the sections above into a new project, you can find the complete sample in the &amp;quot;Similarity&amp;quot; project in the solution of this repo: &lt;a href=&quot;https://github.com/ProductiveRage/BlogPostSimilarity&quot;&gt;BlogPostSimilarity&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts-part-2&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts - Part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/private-local-c-sharp-analysers-without-nuget&quot;&gt;Private / local C# analysers (without NuGet)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/the-full-text-indexer-automating-index-generation&quot;&gt;The Full Text Indexer - Automating Index Generation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Wed, 07 Apr 2021 22:21:00 GMT</pubDate>
            </item>
            <item>
                <title>Language detection and words-in-sentence classification in C#</title>
                <link>https://www.productiverage.com/language-detection-and-wordsinsentence-classification-in-c-sharp</link>
                <guid>https://www.productiverage.com/language-detection-and-wordsinsentence-classification-in-c-sharp</guid>
                <description>&lt;h3&gt;TL;(BG)DR&lt;/h3&gt;&#xA;&lt;p&gt;Using an open source .NET library, it&#x27;s easy to determine what language a sentence / paragraph / document is written in and to then classify the words in each sentence into verbs, nouns, etc..&lt;/p&gt;&#xA;&lt;h3&gt;What library?&lt;/h3&gt;&#xA;&lt;p&gt;I recently parted ways on very good terms with my last employers (and friends!) at &lt;a href=&quot;https://curiosity.ai/&quot;&gt;Curiosity AI&lt;/a&gt; but that doesn&#x27;t mean that I&#x27;m not still excited by their technology, some really useful aspects of which they have released as open source*.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(For the full service, ask yourself if your team or your company have ever struggled to find some information that you know exists somewhere but that might be in one of your network drives containing 10s of 1,000s of files &lt;strong&gt;or&lt;/strong&gt; in your emails &lt;strong&gt;or&lt;/strong&gt; in Sharepoint &lt;strong&gt;or&lt;/strong&gt; GDrive somewhere - with Curiosity, you can set up a system that will index all that data so that it&#x27;s searchable in one place, as well as learning synonyms and abbreviations in case you can&#x27;t conjure up the precise terms to search for. It can even find similar documents for those case where have one document to hand and just know that there&#x27;s another related to it but are struggling to find it - plus it has an ingrained permissions model so that your team could all index their emails and GDrive files and be secure in the knowledge that only they and people that they&#x27;ve shared the files with can see them; they don&#x27;t get pulled in in such a way that your private, intimate, confidential emails are now visible to everyone!)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;I have a little time off between jobs and so I wanted to write a little bit about some of the open-sourced projects that they released that I think are cool.&lt;/p&gt;&#xA;&lt;p&gt;This first one is a really simple example but I think that it demonstrates how easily you can access capabilities that are pretty impressive.&lt;/p&gt;&#xA;&lt;p&gt;This is my cat Cass:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&quot;https://www.productiverage.com/Content/Images/Posts/Cass.jpg&quot; alt=&quot;Cute little girl&quot;&gt;&lt;/p&gt;&#xA;&lt;p&gt;She looks so cute that you&#x27;d think butter wouldn&#x27;t melt. But, of my three cats, she is the prime suspect for the pigeon carcus that was recently dragged through the cat flap one night, up a flight of stairs and deposited outside my home office - and, perhaps not coincidentally, a mere six feet away from where she&#x27;d recently made herself a cosy bed in a duvet cover that I&#x27;d left out to remind myself to wash.&lt;/p&gt;&#xA;&lt;p&gt;I think that it&#x27;s a fair conclusion to draw that:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;My cat Cass is a lovely fluffy little pigeon-killer!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Now you and I can easily see that that is a sentence written in English. But if you wanted a computer to work it out, how would you go about it?&lt;/p&gt;&#xA;&lt;p&gt;Well, one way would be to install the &lt;a href=&quot;https://github.com/curiosity-ai/catalyst&quot;&gt;Catalyst&lt;/a&gt; &lt;a href=&quot;https://www.nuget.org/packages/Catalyst&quot;&gt;NuGet package&lt;/a&gt; and write the following code:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;using System;&#xA;using System.IO;&#xA;using System.Threading.Tasks;&#xA;using Catalyst;&#xA;using Catalyst.Models;&#xA;using Mosaik.Core;&#xA;using Version = Mosaik.Core.Version;&#xA;&#xA;namespace CatalystExamples&#xA;{&#xA;    internal static class Program&#xA;    {&#xA;        private static async Task Main()&#xA;        {&#xA;            const string text = &amp;quot;My cat Cass is a lovely fluffy little pigeon-killer!&amp;quot;;&#xA;&#xA;            Console.WriteLine(&amp;quot;Downloading/reading language detection models..&amp;quot;);&#xA;            const string modelFolderName = &amp;quot;catalyst-models&amp;quot;;&#xA;            if (!new DirectoryInfo(modelFolderName).Exists)&#xA;                Console.WriteLine(&amp;quot;- Downloading for the first time, so this may take a little while&amp;quot;);&#xA;            &#xA;            Storage.Current = new OnlineRepositoryStorage(new DiskStorage(modelFolderName));&#xA;            var languageDetector = await FastTextLanguageDetector.FromStoreAsync(&#xA;                Language.Any,&#xA;                Version.Latest,&#xA;                &amp;quot;&amp;quot;&#xA;            );&#xA;            Console.WriteLine();&#xA;&#xA;            var doc = new Document(text);&#xA;            languageDetector.Process(doc);&#xA;&#xA;            Console.WriteLine(text);&#xA;            Console.WriteLine($&amp;quot;Detected language: {doc.Language}&amp;quot;);&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Running this code will print the following to the console:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Downloading/reading language detection models..&#xA;- Downloading for the first time, so this may take a little while&#xA;&#xA;My cat Cass is a lovely fluffy little pigeon-killer!&#xA;Detected language: English&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Just to prove that it doesn&#x27;t &lt;em&gt;only&lt;/em&gt; detect English, I ran the sentence through Google Translate to get a German version (unfortunately, the languages I&#x27;m fluent in are only English and a few computer languages and so Google Translate was very much needed!) - thus changing the &amp;quot;text&amp;quot; definition to:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;const string text = &amp;quot;Meine Katze Cass ist eine sch&#xF6;ne flauschige kleine Taubenm&#xF6;rderin!&amp;quot;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Running the altered program results in the following console output:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Downloading/reading language detection models..&#xA;&#xA;Meine Katze Cass ist eine wundersch&#xF6;ne, flauschige kleine Taubenm&#xF6;rderin!&#xA;Detected language: German&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Great success!&lt;/p&gt;&#xA;&lt;p&gt;The next thing that we can do is analyse the grammatical constructs of the sentence. I&#x27;m going to return to the English version for this because it will be easier for me to be confident that the word classifications are correct.&lt;/p&gt;&#xA;&lt;p&gt;Add the following code immediately after the Console.WriteLine calls in the Main method from earlier:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Console.WriteLine();&#xA;Console.WriteLine($&amp;quot;Downloading/reading part-of-speech model for {doc.Language}..&amp;quot;);&#xA;var pipeline = await Pipeline.ForAsync(doc.Language);&#xA;pipeline.ProcessSingle(doc);&#xA;foreach (var sentence in doc)&#xA;{&#xA;    foreach (var token in sentence)&#xA;        Console.WriteLine($&amp;quot;{token.Value}{new string(&#x27; &#x27;, 20 - token.Value.Length)}{token.POS}&amp;quot;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The program will now write the following to the console:&lt;/p&gt;&#xA;&lt;p&gt;Downloading/reading language detection models..&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;My cat Cass is a lovely fluffy little pigeon-killer!&#xA;Detected language: English&#xA;&#xA;Downloading/reading part-of-speech model for English..&#xA;My                  PRON&#xA;cat                 NOUN&#xA;Cass                PROPN&#xA;is                  AUX&#xA;a                   DET&#xA;lovely              ADJ&#xA;fluffy              ADJ&#xA;little              ADJ&#xA;pigeon-killer       NOUN&#xA;!                   PUNCT&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The &amp;quot;Part of Speech&amp;quot; (PoS) categories shown above are (as quoted from &lt;a href=&quot;https://universaldependencies.org/u/pos/all.html&quot;&gt;universaldependencies.org/u/pos/all.html&lt;/a&gt;) -&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;Word(s)&lt;/th&gt;&#xA;&lt;th&gt;Code&lt;/th&gt;&#xA;&lt;th&gt;Name&lt;/th&gt;&#xA;&lt;th&gt;Description&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;My&lt;/td&gt;&#xA;&lt;td&gt;PRON&lt;/td&gt;&#xA;&lt;td&gt;Pronoun&lt;/td&gt;&#xA;&lt;td&gt;words that substitute for nouns or noun phrases, whose meaning is recoverable from the linguistic or extralinguistic context&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;cat, pigeon-killer&lt;/td&gt;&#xA;&lt;td&gt;NOUN&lt;/td&gt;&#xA;&lt;td&gt;Noun&lt;/td&gt;&#xA;&lt;td&gt;a part of speech typically denoting a person, place, thing, animal or idea&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Cass&lt;/td&gt;&#xA;&lt;td&gt;PNOUN&lt;/td&gt;&#xA;&lt;td&gt;Proper Noun&lt;/td&gt;&#xA;&lt;td&gt;a noun (or nominal content word) that is the name (or part of the name) of a specific individual, place, or object&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;is&lt;/td&gt;&#xA;&lt;td&gt;AUX&lt;/td&gt;&#xA;&lt;td&gt;Auxiullary Verb&lt;/td&gt;&#xA;&lt;td&gt;a function word that accompanies the lexical verb of a verb phrase and expresses grammatical distinctions not carried by the lexical verb, such as person, number, tense, mood, aspect, voice or evidentiality&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;a&lt;/td&gt;&#xA;&lt;td&gt;DET&lt;/td&gt;&#xA;&lt;td&gt;Determiner&lt;/td&gt;&#xA;&lt;td&gt;words that modify nouns or noun phrases and express the reference of the noun phrase in context&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lovely, fluffy, little&lt;/td&gt;&#xA;&lt;td&gt;ADJ&lt;/td&gt;&#xA;&lt;td&gt;Adjective&lt;/td&gt;&#xA;&lt;td&gt;words that typically modify nouns and specify their properties or attributes&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;!&lt;/td&gt;&#xA;&lt;td&gt;PUNCT&lt;/td&gt;&#xA;&lt;td&gt;Punctuation&lt;/td&gt;&#xA;&lt;td&gt;non-alphabetical characters and character groups used in many languages to delimit linguistic units in printed text&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;How easy was that?! There are a myriad of uses for this sort of analysis (one of the things that the full Curiosity system uses it for is identifying nouns throughout documents and creating tags that any documents sharing a given noun are linked via; so if you found one document about &amp;quot;Flux Capacitors&amp;quot; then you could easily identify all of the other documents / emails / memos that mentioned it - though that really is just the tip of the iceberg).&lt;/p&gt;&#xA;&lt;h3&gt;Very minor caveats&lt;/h3&gt;&#xA;&lt;p&gt;I have only a couple of warnings before signing off this post. I&#x27;ve seen the sentence detector get confused if it has very little data to work with (a tiny segment fragment, for example) or if there is a document that has different sections written in multiple languages - but I don&#x27;t think that either case is unreasonable, the library is very clever but it can&#x27;t perform magic!&lt;/p&gt;&#xA;&lt;h3&gt;Coming soon&lt;/h3&gt;&#xA;&lt;p&gt;I&#x27;ve got another post relating to their open-sourced libraries in the pipeline, hopefully I&#x27;ll get that out this week! Let&#x27;s just say that I&#x27;m hoping that my days of having to manually maintain the &amp;quot;you may also be interested&amp;quot; links between my posts will soon be behind me!&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/how-are-barcodes-read-libraryless-image-processing-in-c-sharp&quot;&gt;How are barcodes read?? (Library-less image processing in C#)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/a-followup-to-implementing-f-sharp-inspired-with-updates-in-c-sharp&quot;&gt;A follow-up to &amp;quot;Implementing F#-inspired &amp;#x27;with&amp;#x27; updates in C#&amp;quot;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/implementing-f-sharp-inspired-with-updates-for-immutable-classes-in-c-sharp&quot;&gt;Implementing F#-inspired &amp;quot;with&amp;quot; updates for immutable classes in C#&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Tue, 09 Mar 2021 19:52:00 GMT</pubDate>
            </item>
            <item>
                <title>Monitoring my garden&#x27;s limited sunlight time period with an Arduino (and some tupperware)</title>
                <link>https://www.productiverage.com/monitoring-my-gardens-limited-sunlight-time-period-with-an-arduino-and-some-tupperware</link>
                <guid>https://www.productiverage.com/monitoring-my-gardens-limited-sunlight-time-period-with-an-arduino-and-some-tupperware</guid>
                <description>&lt;p&gt;My house has a lovely little garden out front. The house and garden itself are elevated one storey above the street (and so my basement is really more of a bizarre ground floor because it has natural light windows but is full of dust and my life-accumulated rubbish is in one room of it while my covid-times &amp;quot;trying to stay fit, not fat&amp;quot; home gym is in the other) and there was no fence around it when I moved in. Meaning that that the &lt;em&gt;interesting characters&lt;/em&gt; that amble past (suffice to say that I went for a nicer house in a slightly on-the-cusp between classy and rougher neighbourhoods as opposed to a less nice house in a posh place) could see in and converse between sips on their 9am double-strength lager. Once fenced off, kitted out with a cute little table and chairs that my friendly neighbours found at a tip and with some lovely raised flower beds installed, it is a &lt;em&gt;delight&lt;/em&gt; in Summer.. only problem is that my house faces the wrong way and so only gets direct sunlight at certain hours of the day. And this time period varies greatly depending upon the time of year - in March, it might not get the light until almost 5pm whilst in July and August it&#x27;s getting warm and light and beautiful (well, on the days that English weather allows) more in time for a late lunch.&lt;/p&gt;&#xA;&lt;p&gt;The problem is that, even after four years here, I still don&#x27;t really have any idea when it&#x27;s going to be sunny there for a given time of year and I want to be able to plan opportunities around it - late evening drinks outside with friends, lunch time warm weather meals for myself, just any general chance top up my vitamin D!&lt;/p&gt;&#xA;&lt;img alt=&quot;Rare English sun in my garden (plus cats)&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/SunnyGardenAndCats.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;I guess that one way to sort this out would be to just keep an eye out on sunny days and take the opportunity whenever it strikes. A more organised plan would be to start a little diary and mark down every fortnight or so through the year when the sun hits the garden and when it leaves.&lt;/p&gt;&#xA;&lt;p&gt;But I work in technology, damnnit, and so I expect to be able to solve this using that electronics and magic! (Cue comments about everything looking like a nail when you&#x27;re holding a hammer).&lt;/p&gt;&#xA;&lt;p&gt;To be &lt;em&gt;really&lt;/em&gt; honest, maybe I&#x27;m describing this situation back to front. My friend gave me an &lt;a href=&quot;https://store.arduino.cc/arduino-uno-rev3&quot;&gt;Arduino UNO r3&lt;/a&gt; because he had a kit spare from the coding club that he runs for kids locally and I&#x27;d been looking for a use for it.. and this seemed like it!&lt;/p&gt;&#xA;&lt;h3&gt;What I needed&lt;/h3&gt;&#xA;&lt;p&gt;Being a total Arduino noob (and, since my Electronics GCSE was over 20 years ago now, I&#x27;m basically a total hardware noob.. you should have seen the trouble that I had trying to build a custom PC a few years ago; I swear it was easier when I was 14!) I wanted something nice and simple to begin with.&lt;/p&gt;&#xA;&lt;p&gt;So I had the starter kit, which included the Arduino board and some jumper cables, a prototyping breadboard and some common components (including, essentially, a photoresistor) and so I figured that all I&#x27;d then need is a way to record the light levels periodically, a power source and some sort of container for when it rains (again; England).&lt;/p&gt;&#xA;&lt;p&gt;I considered having some sort of fancy wifi server in it that would record the values somehow and let me either poll it from somewhere else or have it push those results to the cloud somewhere but eventually decided to go for what seemed like a simpler, more robust and (presumably) more power efficient mechanism of storing the light values throughout the day - using an SD card. Because I&#x27;d got the kit for free (on the agreement that I would try to do something useful with it), I was looking for something cheap to write to an SD card that I&#x27;d had lying around since.. well, I guess since whenever SD cards were useful. Could it have been a digital camera? The very concept seems absurd these days, with the quality of camera that even phones from three or four generations ago have.&lt;/p&gt;&#xA;&lt;p&gt;I came across something called a &amp;quot;&lt;strong&gt;Deek Robot SD/RTC datalogging shield&lt;/strong&gt;&amp;quot; that would not only write to an SD card but would also keep time due to a small battery mounted on it.&lt;/p&gt;&#xA;&lt;p&gt;These are cheap (mine was less than &#xA3;5 delivered, new from eBay) but documentation is somewhat.. spotty. There is a lot of documentation for the &amp;quot;Adafruit Assembled Data Logging shield&amp;quot; but they cost more like &#xA3;13&#x2B; and I was looking for the cheap option. Considering how much time I spent trying to make it work and find good information, it probably would have made more sense to buy a better supported shield than a knock-off from somewhere.. but I &lt;em&gt;did&lt;/em&gt; get it working eventually, so I&#x27;ll share all the code throughout this post!&lt;/p&gt;&#xA;&lt;img alt=&quot;The Arduino UNO r3 with a Deek Robot SD/RTC shield installed&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoAndShield.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: I found a warning that when using this particular shield, &amp;quot;If you have a UNO with a USB type B connector this shield may NOT WORK because the male pins are NOT LONG ENOUGH&amp;quot; on a &lt;a href=&quot;https://forum.arduino.cc/index.php?topic=649395.0&quot;&gt;forum page&lt;/a&gt; - my UNO r3 does have the USB B connector but I&#x27;ve not had this problem.. though if you do encounter this problem then maybe some sort of pin extenders or raisers would fix it.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Step 1: Writing to the SD card&lt;/h3&gt;&#xA;&lt;p&gt;After reading around, I settled on a library called &lt;a href=&quot;https://github.com/greiman/SdFat&quot;&gt;SdFat&lt;/a&gt; that should handle the disk access for me. I downloaded it from the Github repo and followed the &amp;quot;Importing a .zip Library&amp;quot; instructions on the &lt;a href=&quot;https://www.arduino.cc/en/guide/libraries&quot;&gt;Installing Additional Arduino Libraries&lt;/a&gt; page.&lt;/p&gt;&#xA;&lt;p&gt;This allowed me to stack the data logging shield on top of the UNO, put an SD card into the shield, connect the UNO to my PC via a USB lead and upload the following code -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;SdFat.h&amp;gt; // https://github.com/greiman/SdFat&#xA;&#xA;// chipSelect = 10 according to &amp;quot;Item description&amp;quot; section of&#xA;// https://www.play-zone.ch/de/dk-data-logging-shield-v1-0.html&#xA;#define SD_CHIP_SELECT 10&#xA;&#xA;void setup() {&#xA;  Serial.begin(9600);&#xA;&#xA;  // See &amp;quot;Note 1&amp;quot; further down about SPI_HALF_SPEED&#xA;  SdFat sd;&#xA;  if (!sd.begin(SD_CHIP_SELECT, SPI_HALF_SPEED)) {&#xA;    Serial.println(&amp;quot;ERROR: sd.begin() failed&amp;quot;);&#xA;  }&#xA;  else {&#xA;    SdFile file;&#xA;    if (!file.open(&amp;quot;TestData.txt&amp;quot;, O_WRITE | O_APPEND | O_CREAT)) {&#xA;      Serial.println(&amp;quot;ERROR: file.open() failed - unable to write&amp;quot;);&#xA;    }&#xA;    else {&#xA;      file.println(&amp;quot;Hi!&amp;quot;);&#xA;      file.close();&#xA;      Serial.println(&amp;quot;Successfully wrote to file!&amp;quot;);&#xA;    }&#xA;  }&#xA;}&#xA;&#xA;void loop() { }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The Arduino IDE has an option to view the serial output (the messages written to &amp;quot;Serial.println&amp;quot;) by going to Tools / Serial Monitor. Ensure that the baud rate shown near the bottom right of the window is set to 9600 to match the setting in the code above.&lt;/p&gt;&#xA;&lt;p&gt;This happily showed&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Successfully wrote to file!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;in the Serial Monitor&#x27;s output and when I yanked the card out and put it into my laptop to see if it had worked, it did indeed have a file on it called &amp;quot;TestData.txt&amp;quot; with a single line saying &amp;quot;Hi!&amp;quot; - an excellent start!&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note 1: In the &amp;quot;sd.begin&amp;quot; call, I specify &lt;strong&gt;SPI_HALF_SPEED&lt;/strong&gt; primarily because that&#x27;s what most of the examples that I&#x27;ve found use - there is an option &lt;strong&gt;SPI_FULL_SPEED&lt;/strong&gt; but I read in &lt;a href=&quot;https://community.particle.io/t/has-anyone-had-success-hooking-up-an-sd-card-to-the-photon-and-writing-reading-data/24026/41&quot;&gt;an Arduino forum thread&lt;/a&gt; that: &amp;quot;You should be able to use &lt;strong&gt;SPI_FULL_SPEED&lt;/strong&gt; instead, but if that produces communication errors you can use SD_SCK_HZ(4 * MHZ) instead of &lt;strong&gt;SPI_HALF_SPEED&lt;/strong&gt;&amp;quot; and I&#x27;m not sure what might be the limiting factor with said communication errors; whether it&#x27;s the card or the shield or something else and I&#x27;m only going to be writing small amounts of data at relatively infrequent intervals and so I thought that I would err on the safe side and stick with &lt;strong&gt;SPI_HALF_SPEED&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note 2: In a lot of code samples, in the &amp;quot;setup&amp;quot; method you will see code after the &amp;quot;Serial.begin(..)&amp;quot; call that looks like this:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;while (!Serial) {&#xA;  // wait for serial port to connect - needed for native USB&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;^ This is only needed for particular variants of the Arduino - the &amp;quot;Leonardo&amp;quot;, I believe - and is not required for the UNO and so I haven&#x27;t included it in my code.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha One:&lt;/strong&gt; Initially, I had formatted my SD card (branded as &amp;quot;Elgetec&amp;quot;, who I can&#x27;t remember ever hearing of other than on this card) on my Windows laptop - doing a full format, to make absolutely sure that it was as ready for action as possible. However, not only did that full format take a long time, I found that when I left my Arduino shield writing files over a period of a few hours then it would often get reported as being corrupted when I tried to read it. I&#x27;ve found that if the &lt;a href=&quot;https://github.com/greiman/SdFat/blob/master/examples/SdFormatter/SdFormatter.ino&quot;&gt;SdFormatter.ino&lt;/a&gt; (from the examples folder of the SdFat GitHub repo) is used then these corruption problems have stopped occurring (and the formatting is much faster!).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Two:&lt;/strong&gt; While I was fiddling around with writing to the SD card, particularly when connected to a battery instead of the USB port (where I could use the Serial Monitor to see what was happening), I tried setting the LED_BUILTIN to be on while writing and then go off again when the file was closed. This didn&#x27;t work. And it &lt;em&gt;can&#x27;t&lt;/em&gt; work, though it took me a lot of reading to find out why. It turns out that the SPI (the &lt;a href=&quot;https://www.arduino.cc/en/reference/SPI&quot;&gt;Serial Peripheral Library&lt;/a&gt;) connection from the Arduino to the Deek Robot shield will use IO pins 10, 11, 12 and 13 for its own communications. 13 happens to be the output used to set the LED_BUILTIN state and so you lose access to setting that built-in LED while this shield is connected. Specifically, &amp;quot;&lt;a href=&quot;https://forum.arduino.cc/index.php?topic=533606.msg3637549#msg3637549&quot;&gt;pin 13 is the SPI clock. Pin 13 is also the built-in led and hence you have a conflict&lt;/a&gt;&amp;quot;.&lt;/p&gt;&#xA;&lt;h3&gt;Step 2: Keeping time&lt;/h3&gt;&#xA;&lt;p&gt;Since I want to record light levels throughout the day, it&#x27;s important to know at what time the recording is being made. The shield that I&#x27;m using also includes an &amp;quot;RTC&amp;quot; (a real-time clock) and so I needed to work out how to set that once and then read from it each time I took a light level reading.&lt;/p&gt;&#xA;&lt;p&gt;The UNO board itself can do some basic form of time keeping, such as telling you how long it&#x27;s been since the board started / was last reset (via the &lt;a href=&quot;https://www.arduino.cc/reference/en/language/functions/time/millis/&quot;&gt;millis()&lt;/a&gt; function) but there are a few limitations with this. You can bake into the compiled code the time at which it was compiled and you &lt;em&gt;could&lt;/em&gt; then use that, in combination with &amp;quot;millis()&amp;quot;, to work out the current time but you will hit problems if power is temporarily lost or if the board is reset (because &amp;quot;millis()&amp;quot; will start from zero again and timing will start again from that baked-in &amp;quot;compiled at&amp;quot; time).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Three:&lt;/strong&gt; I didn&#x27;t realise when I was first fiddling with this that any time you connected the USB lead, it would reset the board and the program (the &amp;quot;sketch&amp;quot;, in Arduino-speak) would start all over again. (This will only make a difference if you&#x27;re using an external power source because otherwise the program would &lt;em&gt;stop&lt;/em&gt; whenever you disconnected the USB lead and there would be nothing running to reset when plugging the USB lead back in! I&#x27;ll be talking about external power supplies further down).&lt;/p&gt;&#xA;&lt;p&gt;So the next step was using the clock on the shield that I had bought, instead of relying on the clock on the Arduino board itself. To do this, I&#x27;d inserted a CR1220 battery and then tested with the following code:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Wire.h&amp;gt;&#xA;#include &amp;lt;RTClib.h&amp;gt; // https://github.com/adafruit/RTClib&#xA;&#xA;RTC_DS1307 rtc;&#xA;&#xA;void setup() {&#xA;  // The clock won&#x27;t work with this (thanks https://arduino.stackexchange.com/a/44305!)&#xA;  Wire.begin();&#xA;&#xA;  bool rtcWasAlreadyConfigured;&#xA;  if (rtc.isrunning()) {&#xA;    rtcWasAlreadyConfigured = true;&#xA;  }&#xA;  else {&#xA;    rtc.adjust(DateTime(__DATE__, __TIME__));&#xA;    rtcWasAlreadyConfigured = false;&#xA;  }&#xA;&#xA;  Serial.begin(9600);&#xA;&#xA;  if (rtcWasAlreadyConfigured) {&#xA;    Serial.println(&amp;quot;setup: RTC is already running&amp;quot;);&#xA;  }&#xA;  else {&#xA;    Serial.println(&amp;quot;setup: RTC was not running, so it was set to the time of compilation&amp;quot;);&#xA;  }&#xA;}&#xA;&#xA;void loop() {&#xA;  DateTime now = rtc.now();&#xA;  Serial.print(&amp;quot;Year: &amp;quot;);&#xA;  Serial.print(now.year());&#xA;  Serial.print(&amp;quot; Month: &amp;quot;);&#xA;  Serial.print(now.month());&#xA;  Serial.print(&amp;quot; Day: &amp;quot;);&#xA;  Serial.print(now.day());&#xA;  Serial.print(&amp;quot; Hour: &amp;quot;);&#xA;  Serial.print(now.hour());&#xA;  Serial.print(&amp;quot; Minutes: &amp;quot;);&#xA;  Serial.print(now.minute());&#xA;  Serial.print(&amp;quot; Seconds: &amp;quot;);&#xA;  Serial.print(now.second());&#xA;  Serial.println();&#xA;&#xA;  delay(1000);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The first time you run this, you&#x27;ll see the first line say:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;setup: RTC was not running, so it was set to the time of compilation&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. and then you&#x27;ll see the date and time shown every second.&lt;/p&gt;&#xA;&lt;p&gt;If you remove the USB cable and then re-insert it then you&#x27;ll see the message:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;setup: RTC is already running&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. and then the date and time will continue to show every second &lt;em&gt;and it will be the correct date and time&lt;/em&gt; (it won&#x27;t have reset each time that the USB cable is connected and the &amp;quot;setup&amp;quot; function is run again).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Four:&lt;/strong&gt; When disconnecting and reconnecting the USB lead, sometimes (if not always) I need to close the Serial Monitor and then re-open it otherwise it won&#x27;t update and it will say that the COM port is busy if I try to upload a sketch to the board.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Five:&lt;/strong&gt; I&#x27;ve seen a lot of examples use &amp;quot;RTC_Millis&amp;quot; instead of &amp;quot;RTC_DS1307&amp;quot; in timing code samples. This is &lt;em&gt;not&lt;/em&gt; what we want! That is a timer that is simulated by the board and it just uses the &amp;quot;millis()&amp;quot; function to track time which, as I explained earlier, is no good for persisting time across resets. We want to use &amp;quot;RTC_DS1307&amp;quot; because that uses the RTC on the shield, which &lt;em&gt;will&lt;/em&gt; maintain the time between power cycles due to the battery on the board.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Six:&lt;/strong&gt; If you don&#x27;t include &amp;quot;Wire.h&amp;quot; and call &amp;quot;Wire.begin();&amp;quot; at the start of setup then the RTC won&#x27;t work properly and you will always get the same weird date displayed when you read it:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Year: 2165 Month: 165 Day: 165 Hour: 165 Minutes: 165 Seconds: 85&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3&gt;Step 3: An external power source&lt;/h3&gt;&#xA;&lt;p&gt;So far, the board has only been powered up when connected to the USB lead but this is not the only option. There are a few approaches that you can take; a regulated 5V input, the barrel-shaped power jack and the option of applying power to the vin and gnd pins on the board.&lt;/p&gt;&#xA;&lt;p&gt;The power jack makes most sense when you are connecting to some sort of wall wart but I want a &amp;quot;disconnected&amp;quot; power supply for outside. I did a bunch of reading on this and some people are just connecting a simple 9V battery to the vin/gnd pins but apparently that&#x27;s not very efficient - the amount of power stored in a standard MN1604 9V battery (the common kind that you might use in a smoke alarm) is comparatively low and the vin/gnd pins will be happy with something in the 6V-12V range and there is said to be more loss in regulating 9V to the internal 5V than there would be from a 6V supply.&lt;/p&gt;&#xA;&lt;p&gt;So I settled on a rechargable 6V sealed lead acid battery, which I believe is often used in big torches or in remote control cars. I got one for &#xA3;8 delivered from ebay that is stated to have 4.5Ah (which is a measure, essentially, of how much energy it stores) - for reference, a 9V battery will commonly have about 0.5Ah and so will run out much more quickly. Whatever battery you select, there are ways to eke out more life from them, which I&#x27;ll cover shortly.&lt;/p&gt;&#xA;&lt;p&gt;It&#x27;s completely safe to connect the battery to the vin/gnd ports at the same time as the USB lead is inserted, so you don&#x27;t have to worry about only providing power by the battery &lt;em&gt;or&lt;/em&gt; the USB lead and you can safely connect and disconnect the USB lead while the battery is connected as often as you like.&lt;/p&gt;&#xA;&lt;h3&gt;Step 4: Capturing light levels&lt;/h3&gt;&#xA;&lt;p&gt;The starter kit that I&#x27;ve got conveniently included an LDR (a &amp;quot;Light Dependent Resistor&amp;quot; aka a &amp;quot;photo-resistor&amp;quot;) and so I just had to work out how to connect that. I knew that the Arduino has a range of digital input/output pins and that it has some analog input pins but I had to remind myself of some basic electronics to put it all together.&lt;/p&gt;&#xA;&lt;p&gt;What you &lt;em&gt;can&#x27;t&lt;/em&gt; do is just put 5V into one pin of the LDR and connect the other end of the LDR straight into an analog pin. I&#x27;m going to try to make a stab at a simple explanation here and then refer you to someone who can explain it better!&lt;/p&gt;&#xA;&lt;p&gt;The analog pin will read a voltage value from between 0 and 5V and allow this to be read in code as a numeric value between 0 and 1023 (inclusive). When we talk about the 5V output pin, this only makes sense in the context of the ground of the board - so the concept of a 5V output with no gnd pin connection makes no sense, there is nothing for that 5V to be measured relative to. So what we need to do is use the varying resistance of the LDR and somehow translate that into a varying voltage to provide to an analog pin (I chose A0 in my build).&lt;/p&gt;&#xA;&lt;p&gt;The way to do this is with a &amp;quot;voltage divider&amp;quot;, which is essentially a circuit that looks a bit like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;gnd &amp;lt;--&amp;gt; resistor &amp;lt;--&amp;gt; connection-to-analog-input &amp;lt;--&amp;gt; LDR &amp;lt;--&amp;gt; 5V&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;If the resistance of the LDR happens to precisely match that resistance of the fixed resistor then precisely 2.5V will be delivered to the analog input. But if the LDR resistance is higher or lower than the fixed resistor&#x27;s value then a higher or lower voltage will be delivered to analog pin.&lt;/p&gt;&#xA;&lt;p&gt;There is a &lt;a href=&quot;https://learn.adafruit.com/photocells/using-a-photocell&quot;&gt;tutorial on learn.adafruit.com&lt;/a&gt; that does a much better job of explaining it! It also suggests what fixed resistor values that you might use for different environments (eg. are you more interested in granular light level readings at low light levels but don&#x27;t mind saturation at high levels or are you more interested in more granular readings at high levels and less granular at lower?) - at the moment, I&#x27;m still experimenting with a few different fixed resistor values to see which ones work for my particular climate.&lt;/p&gt;&#xA;&lt;p&gt;The shield that I&#x27;m using solder pads for mounting components onto but I wasn&#x27;t brave enough for that, so I&#x27;ve been using the pass-through pins and connecting them to the bread board that came with my starter kit.&lt;/p&gt;&#xA;&lt;p&gt;When it&#x27;s not connected to a power supply, it looks a bit like this:&lt;/p&gt;&#xA;&lt;img alt=&quot;The Arduino-plus-shield connected to an LDR on a breadboard&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoWithBreadboardAlongside.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;The code to read the light level value looks like this (while running this code, try slowly moving your hand closer and further from covering the sensor to see the value change when it&#x27;s read each second) -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;void setup() {&#xA;  Serial.begin(9600);&#xA;}&#xA;&#xA;void loop() {&#xA;  Serial.print(&amp;quot;Light level reading: &amp;quot;);&#xA;  Serial.print(analogRead(0));&#xA;  Serial.println();&#xA;&#xA;  delay(1000);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In an effort to start putting all of this together into a more robust package, I picked up a pack of self-adhesive felt pads from the supermarket and stuck them to appropriate points under the breadboard -&lt;/p&gt;&#xA;&lt;img alt=&quot;Felt pads to more easily align the breadboard on top of the Arduino and shield&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoBreadboardFeltPads.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;img alt=&quot;Felt pads attached to the underside of the breadboard&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoBreadboardWithFeltPadsAttached.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. and then I secured it all together with an elastic band:&lt;/p&gt;&#xA;&lt;img alt=&quot;Arduino plus shield plus breadboard secured in a tower&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoTower.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;h3&gt;Step 5: Sleeping when not busy&lt;/h3&gt;&#xA;&lt;p&gt;In my ideal dream world, I would be able to leave my light level monitoring box outside for a few months. As I explained earlier, due to the direction that my garden faces, the hours at which the sun hits it fully varies by several hours depending upon the time of year. However, NO battery is going to last forever and even with this 4.5Ah battery that is at a 6V output (which is only a small jump down to regulate to 5V), the time that it can keep things running is limited.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: Recharging via a solar panel sounds interesting but it&#x27;s definitely a future iteration possibility at this point!&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;There are, however, some things that can be done to eke out the duration of the battery by reducing the power usage of the board. There are ways to put the board into a &amp;quot;power down&amp;quot; state where it will do less - its timers will stop and its CPU can have a rest. There are tutorials out there about how to put it into this mode and have it only wake up on an &amp;quot;interrupt&amp;quot;, which can be an external circuit setting an input pin (maybe somehow using the RTC on the shield I&#x27;m using) &lt;em&gt;or&lt;/em&gt; using something called the &amp;quot;&lt;a href=&quot;https://create.arduino.cc/projecthub/rafitc/what-is-watchdog-timer-fffe20&quot;&gt;Watchdog Timer&lt;/a&gt;&amp;quot; that stays running on the Arduino even when it&#x27;s in power down mode.&lt;/p&gt;&#xA;&lt;p&gt;I read &lt;em&gt;a lot&lt;/em&gt; of posts and tutorials on this and I really struggled to get it to work. Until, finally, I came across this one: &lt;a href=&quot;https://circuitdigest.com/microcontroller-projects/arduino-sleep-modes-and-how-to-use-them-to-reduce-power-consumption&quot;&gt;Arduino Sleep Modes and How to use them to Save the Power&lt;/a&gt;. It explains in a clear table the difference between the different power-reduced modes (idle, power-save, power-down, etc..) &lt;em&gt;and&lt;/em&gt; it recommends a library called &amp;quot;&lt;a href=&quot;https://github.com/rocketscream/Low-Power&quot;&gt;Low-Power&lt;/a&gt;&amp;quot; that takes all of the hard work out of it.&lt;/p&gt;&#xA;&lt;p&gt;Whereas other tutorials talked about calling &amp;quot;sleep_enable()&amp;quot; and &amp;quot;set_sleep_mode(..)&amp;quot; functions and then using &amp;quot;attachInterrupt(..)&amp;quot; and adding some magic method to then undo all of those things, this library allows you to write a one-liner as follows:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This willl cause the board to go into its most power-saving mode for eight seconds (which is the longest that&#x27;s possible when relying upon its internal Watchdog Timer to wake it up).&lt;/p&gt;&#xA;&lt;p&gt;No muss, no fuss.&lt;/p&gt;&#xA;&lt;p&gt;I haven&#x27;t measured yet how long that my complete device can sit outside in its waterproof box on a single charge of a battery but I&#x27;m confident that it&#x27;s definitely measured in days, not hours - and that was &lt;em&gt;before&lt;/em&gt; introducing this &amp;quot;LowPower.powerDown(..)&amp;quot; call.&lt;/p&gt;&#xA;&lt;p&gt;Since I only want a reading every 30-60s, I call &amp;quot;LowPower.powerDown(..)&amp;quot; in a loop so that there are several 8s power down delays. While I haven&#x27;t confirmed this yet, I would be astonished if it didn&#x27;t last &lt;em&gt;at least&lt;/em&gt; a week out there on one charge. And if I have to bring it in some nights (when it&#x27;s dark and I don&#x27;t care about light measurements) to charge it, then that&#x27;s fine by me (though I&#x27;d like to be as infrequently as possible).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Seven:&lt;/strong&gt; When entering power-down mode, if you are connected to the USB port in order to use the Serial Monitor to watch what&#x27;s going on, ensure that you call &amp;quot;Serial.flush()&amp;quot; before entering power-down, otherwise the message might get buffered up and not fully sent through the serial connection before the board takes a nap.&lt;/p&gt;&#xA;&lt;h3&gt;Step 6: Preparing for the outdoors (in the British weather!)&lt;/h3&gt;&#xA;&lt;p&gt;I always associate the brand &amp;quot;&lt;a href=&quot;https://www.independent.co.uk/life-style/food-and-drink/how-tupperware-s-fate-was-sealed-a7899771.html&quot;&gt;Tupperware&lt;/a&gt;&amp;quot; as being a very British thing - it&#x27;s what we get packed lunches put into and what we get takeaway curries in. At least, I &lt;em&gt;think&lt;/em&gt; that it is - maybe it&#x27;s like &amp;quot;hoover&amp;quot;, where everyone uses the phrase &amp;quot;hoover&amp;quot; when they mean their generic vacuum cleaner. Regardless the origin, this seemed like the simplest way to make my device waterproof. The containers are not completely transparent but they shouldn&#x27;t make a significant impact on the light levels being recorded by the photo-resistor because they&#x27;re also far from opaque. And these containers are sealable, waterproof and come in all shapes and sizes!&lt;/p&gt;&#xA;&lt;p&gt;I took my elastic-band-wrapped &amp;quot;stack&amp;quot; of Arduino-plus-shield-plus-breadboard and connected it to the battery -&lt;/p&gt;&#xA;&lt;img alt=&quot;The Arduino &#x27;stack&#x27; connected to a battery&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoStackWithBattery.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. and put in a plastic box. By turning the battery so that it was length-side-up, it was quite a snug fit and meant that the battery wouldn&#x27;t slide around inside the box. There wasn&#x27;t a lot of space for the stack to move around and so it seemed like quite a secure arrangement:&lt;/p&gt;&#xA;&lt;img alt=&quot;The Arduino &#x27;stack&#x27; and battery in its waterproof container&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/ArduinoInBox.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;h3&gt;Step 7: The final code&lt;/h3&gt;&#xA;&lt;p&gt;So far, each code sample has demonstrated &lt;em&gt;aspects&lt;/em&gt; of what I want to do but now it&#x27;s time to bring it all fully together.&lt;/p&gt;&#xA;&lt;p&gt;In trying to write the following code, I was reminded how much I&#x27;ve taken for granted in C# (and other higher level languages) with their string handling! I tried a little C and C&#x2B;&#x2B; &lt;em&gt;maaaaany&lt;/em&gt; years ago and so writing Arduino code was a bit of a throwback for me - at first, I was trying to make a char array for a filename and I set the length of the array to be the number of characters that were required for the filename.. silly me, I had forgotten that C strings need to be null-terminated and so you need an extra zero character at the end in order for things to work properly! Failing to do so would not result in a compile or run time error, it would just mean that the files weren&#x27;t written properly. Oh, how I&#x27;ve been spoilt! But, on the other hand, it also feels kinda good being this close to the &amp;quot;bare metal&amp;quot; :)&lt;/p&gt;&#xA;&lt;p&gt;The following sketch will record the light level about twice a minute to a file on the SD card where the filename is based upon the current date (as maintained by the RTC module and its CR1220 battery) -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;Wire.h&amp;gt;&#xA;#include &amp;lt;SdFat.h&amp;gt;    // https://github.com/greiman/SdFat&#xA;#include &amp;lt;RTClib.h&amp;gt;   // https://github.com/adafruit/RTClib&#xA;#include &amp;lt;LowPower.h&amp;gt; // https://github.com/rocketscream/Low-Power&#xA;&#xA;// chipSelect = 10 according to &amp;quot;Item description&amp;quot; section of&#xA;// https://www.play-zone.ch/de/dk-data-logging-shield-v1-0.html&#xA;#define SD_CHIP_SELECT 10&#xA;&#xA;RTC_DS1307 rtc;&#xA;&#xA;void setup() {&#xA;  // The clock won&#x27;t work with this (thanks https://arduino.stackexchange.com/a/44305!)&#xA;  Wire.begin();&#xA;&#xA;  bool rtcWasAlreadyConfigured;&#xA;  if (rtc.isrunning()) {&#xA;    rtcWasAlreadyConfigured = true;&#xA;  }&#xA;  else {&#xA;    rtc.adjust(DateTime(__DATE__, __TIME__));&#xA;    rtcWasAlreadyConfigured = false;&#xA;  }&#xA;&#xA;  Serial.begin(9600);&#xA;&#xA;  if (rtcWasAlreadyConfigured) {&#xA;    Serial.println(&amp;quot;setup: RTC is already running&amp;quot;);&#xA;  }&#xA;  else {&#xA;    Serial.println(&amp;quot;setup: RTC was not running, so it was set to the time of compilation&amp;quot;);&#xA;  }&#xA;}&#xA;&#xA;void loop() {&#xA;  // Character arrays need to be long enough to store the number of &amp;quot;real&amp;quot; characters plus the&#xA;  // null terminator&#xA;  char filename[13]; // yyyyMMdd.txt = 12 chars &#x2B; 1 null&#xA;  char timestamp[9]; // 00:00:00     =  8 chars &#x2B; 1 null&#xA;  DateTime now = rtc.now();&#xA;  snprintf(filename, sizeof(filename), &amp;quot;%04u%02u%02u.txt&amp;quot;, now.year(), now.month(), now.day());&#xA;  snprintf(timestamp, sizeof(timestamp), &amp;quot;%02u:%02u:%02u&amp;quot;, now.hour(), now.minute(), now.second());&#xA;&#xA;  int sensorValue = analogRead(0);&#xA;&#xA;  Serial.print(filename);&#xA;  Serial.print(&amp;quot; &amp;quot;);&#xA;  Serial.print(timestamp);&#xA;  Serial.print(&amp;quot; &amp;quot;);&#xA;  Serial.println(sensorValue);&#xA;&#xA;  SdFat sd;&#xA;  if (!sd.begin(SD_CHIP_SELECT, SPI_HALF_SPEED)) {&#xA;    Serial.println(&amp;quot;ERROR: sd.begin() failed&amp;quot;);&#xA;  }&#xA;  else {&#xA;    SdFile file;&#xA;    if (!file.open(filename, O_WRITE | O_APPEND | O_CREAT)) {&#xA;      Serial.println(&amp;quot;ERROR: file.open() failed - unable to write&amp;quot;);&#xA;    }&#xA;    else {&#xA;      file.print(timestamp);&#xA;      file.print(&amp;quot; Sensor value: &amp;quot;);&#xA;      file.println(sensorValue);&#xA;      file.close();&#xA;    }&#xA;  }&#xA;&#xA;  Serial.flush(); // Ensure we finish sending serial messages before going to sleep&#xA;&#xA;  // 4x 8s is close enough to a reading every 30s, which gives me plenty of data&#xA;  // - Using this instead of &amp;quot;delay&amp;quot; should mean that the battery will power the device for longer&#xA;  for (int i = 0; i &amp;lt; 3; i&#x2B;&#x2B;) {&#xA;    LowPower.powerDown(SLEEP_8S, ADC_OFF, BOD_OFF);&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;At the moment, I&#x27;m bringing the box inside each night and then disconnecting the battery, pulling out the card and looking at the values recorded in the file to see if it&#x27;s clear when the sun was fully hitting the table that I had placed the box on.&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;ve only started doing this in the last couple of days and each day has been rather grey and so there haven&#x27;t been any sunny periods so that I can confirm that the readings clearly distinguish between &amp;quot;regular daylight&amp;quot; and &amp;quot;sun directly on the table&amp;quot;. Once I get some sun again, I&#x27;ll be able to get a better idea - and if I &lt;em&gt;can&#x27;t&lt;/em&gt; distinguish well enough then I&#x27;ll adjust the pull-down resistor that splits the voltage with the LDR and keep experimenting!&lt;/p&gt;&#xA;&lt;p&gt;When I&#x27;m happy with the configuration, &lt;em&gt;then&lt;/em&gt; I&#x27;ll start experimenting with leaving the box outside for longer to see how long this battery can last in conjunction with the &amp;quot;LowPower.powerDown(..)&amp;quot; calls. One obvious optimisation for my use case would be to continue keeping it in power-down mode between the hours of 10pm and 8am - partly because I know that it will definitely be dark after 10pm and partly because I am &lt;em&gt;not&lt;/em&gt; a morning person and so would not want to be outside before 8am, even if it &lt;em&gt;was&lt;/em&gt; streaming with light (which it wouldn&#x27;t be due to when my yard actually gets direct sunlight).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Gotcha Eight:&lt;/strong&gt; The RTC has no awareness of daylight savings time and so I&#x27;ll need to take this into account when the clocks change in the UK. I&#x27;ll worry about this another day!&lt;/p&gt;&#xA;&lt;h3&gt;Step 8: Draw some graphs (one day)&lt;/h3&gt;&#xA;&lt;p&gt;As you can tell from the above, I&#x27;m still very much in the early phases of gathering data. But, at some point, I&#x27;m going to have to &lt;em&gt;use&lt;/em&gt; this data to predict when the yard will get sun for future dates - once I&#x27;ve got a few months of data for different times of year, hopefully I&#x27;ll be able to do so!&lt;/p&gt;&#xA;&lt;p&gt;I foresee a little bit of data-reading and Excel-graph-drawing in my future! There&#x27;s just something about seeing &lt;a href=&quot;https://www.productiverage.com/when-a-disk-cache-performs-better-than-an-inmemory-cache-befriending-the-net-gc&quot;&gt;results on a graph&lt;/a&gt; that make everything feel so much more real. As much as I&#x27;d like to be able to stare at 1000s of numbers and read them like the Matrix, seeing trends and curves plotted out just feels so much more satisfying and definitive. Maybe there will be a follow-up post with the results, though I feel that they would be much more personal and less useful to the general populace than even &lt;em&gt;my&lt;/em&gt; standard level of esoteric and niche blog posts! Maybe there are some graphs in my Twitter stream&#x27;s future!&lt;/p&gt;&#xA;&lt;p&gt;On the other hand.. if I learn any more power-saving techniques or have any follow-up information about how long these rechargeable torch-or-remote-control batteries last then maybe &lt;em&gt;that&lt;/em&gt; will be grounds for a follow-up!&lt;/p&gt;&#xA;&lt;p&gt;In the meantime, I hope you&#x27;ve enjoyed this little journey - and if you&#x27;ve tried to do anything similar with these cheap Deek Robot boards, then maybe the code samples here have been of use to you. I hope so! (Because, goodness knows, feeling like a beginner again and getting onto those new forums has been &lt;em&gt;quite&lt;/em&gt; an experience!)&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts-part-2&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts - Part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;Automating &amp;quot;suggested / related posts&amp;quot; links for my blog posts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/javascript-compression-putting-my-json-search-indexes-on-a-diet&quot;&gt;JavaScript Compression (Putting my JSON Search Indexes on a diet)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Sat, 22 Aug 2020 21:34:00 GMT</pubDate>
            </item>
            <item>
                <title>How are barcodes read?? (Library-less image processing in C#)</title>
                <link>https://www.productiverage.com/how-are-barcodes-read-libraryless-image-processing-in-c-sharp</link>
                <guid>https://www.productiverage.com/how-are-barcodes-read-libraryless-image-processing-in-c-sharp</guid>
                <description>&lt;p&gt;I&#x27;ve been using MyFitnessPal and it has the facility to load nutrition information by scanning the barcode on the product. I can guess how the retrieval works once the barcode number is obtained (a big database somewhere) but it struck me that I had no idea how the reading of the barcode &lt;em&gt;itself&lt;/em&gt; worked and.. well, I&#x27;m curious and enjoy the opportunity to learn something new to me by writing the code to do it. I do enjoy being able to look up (almost) anything on the internet to find out how it works!&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(For anyone who wants to either play along but not copy-paste the code themselves or for anyone who wants to jump to the end result, I&#x27;ve put the code - along with the example image I&#x27;ve used in this post - up on a &lt;a href=&quot;https://github.com/ProductiveRage/BarcodeReader&quot;&gt;GitHub repo&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;The plan of attack&lt;/h3&gt;&#xA;&lt;p&gt;There are two steps required here:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Read image and try to identify areas that look like barcodes&lt;/li&gt;&#xA;&lt;li&gt;Try to extract numbers from the looks-like-a-barcode regions&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;As with anything, these steps may be broken down into smaller tasks. The first step can be done like this:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Barcodes are black and white regions that have content that has steep &amp;quot;gradients&amp;quot; in image intensity horizontally (where there is a change from a black bar to a white space) and little change in intensity vertically (as each bar is a vertical line), so first we greyscale the image and then generate horizontal and vertical intensity gradients values for each point in the image and combine the values by subtracting vertical gradient from horizontal gradient&lt;/li&gt;&#xA;&lt;li&gt;These values are normalised so that they are all on the scale zero to one - this data could be portrayed as another greyscale image where the brightest parts are most likely to be within barcodes&lt;/li&gt;&#xA;&lt;li&gt;These values are then &amp;quot;spread out&amp;quot; or &amp;quot;blurred&amp;quot; and then a threshold value is applied where every value about it is changed into a 1 and every value below it a 0&lt;/li&gt;&#xA;&lt;li&gt;This &amp;quot;mask&amp;quot; (where every value is a 0 or 1) should have identified many of the pixels within the barcodes and we want to group these pixels into distinct objects&lt;/li&gt;&#xA;&lt;li&gt;There is a chance, though, that there could be gaps between bars that mean that a single barcode is spread across multiple masked-out objects and we need to try to piece them back together into one area (since the bars are tall and narrow, this may be done by considering a square area over every object and then combining objects whose squared areas overlap into one)&lt;/li&gt;&#xA;&lt;li&gt;This process will result in a list of areas that may be barcodes - any that are taller than they are wide are ignored (because barcode regions are always wider than they are tall)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The second step can be broken down into:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Take the maybe-barcode region of the image, greyscale it and then turn into a mask by setting any pixel with an intensity less than a particular threshold to zero and otherwise to one&lt;/li&gt;&#xA;&lt;li&gt;Take a horizontal slice across the image region - all of the pixels on the first row of the image - and change the zero-or-one raw data into a list of line lengths where a new line starts at any transition from zero-to-one or one-to-zero (so &amp;quot;01001000110&amp;quot; becomes &amp;quot;1,1,2,1,3,2,1&amp;quot; because there is 1x zero and then 1x one and then 2x zero and then 1x one, etc..)&lt;/li&gt;&#xA;&lt;li&gt;These line lengths should correspond to bar sizes (and space-between-bar sizes) if we&#x27;ve found a barcode - so run the values through the magic barcode bar-size-reading algorithm (see section 2.1 in &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859730/&quot;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859730/&lt;/a&gt;) and if we get a number (and the checksum is correct) then we&#x27;re done, hurrah!&lt;/li&gt;&#xA;&lt;li&gt;If we couldn&#x27;t get a number from this horizontal slice then move one pixel down and go back around&lt;/li&gt;&#xA;&lt;li&gt;If it was not possible to extract a number from any of the slices through the image region then it&#x27;s either not a barcode or it&#x27;s somehow so distorted in the image that we can&#x27;t read it&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This approach is fairly resilient to changes in lighting and orientation because the barcode regions are still likely to have the highest horizontal intensity gradient whether the image is dark or light (and even if &lt;em&gt;part&lt;/em&gt; of the image is light and part of it is dark) and the barcode-reading algorithm works on ratios of bar/space-between-bar widths and these remain constant if the image is rotated.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(Some of the techniques are similar to things that I did in my &lt;a href=&quot;https://www.productiverage.com/face-or-no-face-finding-faces-in-photos-using-c-sharp-and-accordnet&quot;&gt;Face or no face (finding faces in photos using C# and Accord.NET)&lt;/a&gt; and so I&#x27;ll be using some of the same code shortly that I described then)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Identifying maybe-barcode images&lt;/h3&gt;&#xA;&lt;p&gt;Let&#x27;s this image as an example to work with (peanut butter.. I &lt;em&gt;do&lt;/em&gt; love peanut butter) -&lt;/p&gt;&#xA;&lt;img alt=&quot;Delicious peanut butter&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;Before looking at any code, let&#x27;s visualise the process.&lt;/p&gt;&#xA;&lt;p&gt;We&#x27;re going to consider horizontal and vertical gradient intensity maps - at every point in the image we either look to the pixels to the left and to the right (for the horizontal gradient) or we look at the pixels above and below (for the vertical gradient) and the larger the change, the brighter the pixel in the gradient intensity map&lt;/p&gt;&#xA;&lt;img alt=&quot;Horizontal gradient intensity&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-HorizontalAndVerticalGradients.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;And when they&#x27;re combined by subtracting the vertical gradient at each point from the horizontal gradient, it looks lke this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Combined gradient intensity&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-CombinedGradients.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;If this image is blurred then we get this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Blurred combined gradient intensity&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-Blurred.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. and if we create a binary mask by saying &amp;quot;normalise the intensity values so that their range goes from zero (for the darkest pixel) to one (for the brightest) and then set any pixels that are in the bottom third in terms of intensity to 0 and set the rest to 1&amp;quot; then we get this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Mask of possibly-part-of-a-barcode areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-Mask.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;If each distinct area (where an &amp;quot;area&amp;quot; means &amp;quot;a group of pixels that are connected&amp;quot;) is identified and squares overlaid and centered around the areas then we see this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Mask of possibly-part-of-a-barcode areas, extended into squared areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskSquares.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. and if the areas whose bounding squares overlap are combined and then cropped around the white pixels then we end up with this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Combined possibly-a-barcode areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskSquaresCombined.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;This has identified the area around the barcode and also two tiny other areas - when we come to trying to read barcode numbers out of these, the tiny regions will result in no value while the area around the genuine barcode content &lt;em&gt;should&lt;/em&gt; result in a number successfully being read. But I&#x27;m getting ahead of myself.. let&#x27;s look at the code required to perform the above transformations.&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;m going to start with a &lt;strong&gt;DataRectangle&lt;/strong&gt; for performing transformations -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public static class DataRectangle&#xA;{&#xA;    public static DataRectangle&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(T[,] values) =&amp;gt; new DataRectangle&amp;lt;T&amp;gt;(values);&#xA;}&#xA;&#xA;public sealed class DataRectangle&amp;lt;T&amp;gt;&#xA;{&#xA;    private readonly T[,] _protectedValues;&#xA;    public DataRectangle(T[,] values) : this(values, isolationCopyMayBeBypassed: false) { }&#xA;    private DataRectangle(T[,] values, bool isolationCopyMayBeBypassed)&#xA;    {&#xA;        if ((values.GetLowerBound(0) != 0) || (values.GetLowerBound(1) != 0))&#xA;            throw new ArgumentException(&amp;quot;Both dimensions must have lower bound zero&amp;quot;);&#xA;        var arrayWidth = values.GetUpperBound(0) &#x2B; 1;&#xA;        var arrayHeight = values.GetUpperBound(1) &#x2B; 1;&#xA;        if ((arrayWidth == 0) || (arrayHeight == 0))&#xA;            throw new ArgumentException(&amp;quot;zero element arrays are not supported&amp;quot;);&#xA;&#xA;        Width = arrayWidth;&#xA;        Height = arrayHeight;&#xA;&#xA;        if (isolationCopyMayBeBypassed)&#xA;            _protectedValues = values;&#xA;        else&#xA;        {&#xA;            _protectedValues = new T[Width, Height];&#xA;            Array.Copy(values, _protectedValues, Width * Height);&#xA;        }&#xA;    }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will always be greater than zero&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public int Width { get; }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will always be greater than zero&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public int Height { get; }&#xA;&#xA;    public T this[int x, int y]&#xA;    {&#xA;        get&#xA;        {&#xA;            if ((x &amp;lt; 0) || (x &amp;gt;= Width))&#xA;                throw new ArgumentOutOfRangeException(nameof(x));&#xA;            if ((y &amp;lt; 0) || (y &amp;gt;= Height))&#xA;                throw new ArgumentOutOfRangeException(nameof(y));&#xA;            return _protectedValues[x, y];&#xA;        }&#xA;    }&#xA;&#xA;    public IEnumerable&amp;lt;Tuple&amp;lt;Point, T&amp;gt;&amp;gt; Enumerate(Func&amp;lt;Point, T, bool&amp;gt;? optionalFilter = null)&#xA;    {&#xA;        for (var x = 0; x &amp;lt; Width; x&#x2B;&#x2B;)&#xA;        {&#xA;            for (var y = 0; y &amp;lt; Height; y&#x2B;&#x2B;)&#xA;            {&#xA;                var value = _protectedValues[x, y];&#xA;                var point = new Point(x, y);&#xA;                if (optionalFilter?.Invoke(point, value) ?? true)&#xA;                    yield return Tuple.Create(point, value);&#xA;            }&#xA;        }&#xA;    }&#xA;&#xA;    public DataRectangle&amp;lt;TResult&amp;gt; Transform&amp;lt;TResult&amp;gt;(Func&amp;lt;T, TResult&amp;gt; transformer)&#xA;    {&#xA;        return Transform((value, coordinates) =&amp;gt; transformer(value));&#xA;    }&#xA;&#xA;    public DataRectangle&amp;lt;TResult&amp;gt; Transform&amp;lt;TResult&amp;gt;(Func&amp;lt;T, Point, TResult&amp;gt; transformer)&#xA;    {&#xA;        var transformed = new TResult[Width, Height];&#xA;        for (var x = 0; x &amp;lt; Width; x&#x2B;&#x2B;)&#xA;        {&#xA;            for (var y = 0; y &amp;lt; Height; y&#x2B;&#x2B;)&#xA;                transformed[x, y] = transformer(_protectedValues[x, y], new Point(x, y));&#xA;        }&#xA;        return new DataRectangle&amp;lt;TResult&amp;gt;(transformed, isolationCopyMayBeBypassed: true);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;And then I&#x27;m going to add a way to load image data into this structure -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public static class BitmapExtensions&#xA;{&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will return values in the range 0-255 (inclusive)&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    // Based on http://stackoverflow.com/a/4748383/3813189&#xA;    public static DataRectangle&amp;lt;double&amp;gt; GetGreyscale(this Bitmap image)&#xA;    {&#xA;        var values = new double[image.Width, image.Height];&#xA;        var data = image.LockBits(&#xA;            new Rectangle(0, 0, image.Width, image.Height),&#xA;            ImageLockMode.ReadOnly,&#xA;            PixelFormat.Format24bppRgb&#xA;        );&#xA;        try&#xA;        {&#xA;            var pixelData = new Byte[data.Stride];&#xA;            for (var lineIndex = 0; lineIndex &amp;lt; data.Height; lineIndex&#x2B;&#x2B;)&#xA;            {&#xA;                Marshal.Copy(&#xA;                    source: data.Scan0 &#x2B; (lineIndex * data.Stride),&#xA;                    destination: pixelData,&#xA;                    startIndex: 0,&#xA;                    length: data.Stride&#xA;                );&#xA;                for (var pixelOffset = 0; pixelOffset &amp;lt; data.Width; pixelOffset&#x2B;&#x2B;)&#xA;                {&#xA;                    // Note: PixelFormat.Format24bppRgb means the data is stored in memory as BGR&#xA;                    const int PixelWidth = 3;&#xA;                    var r = pixelData[pixelOffset * PixelWidth &#x2B; 2];&#xA;                    var g = pixelData[pixelOffset * PixelWidth &#x2B; 1];&#xA;                    var b = pixelData[pixelOffset * PixelWidth];&#xA;                    values[pixelOffset, lineIndex] = (0.2989 * r) &#x2B; (0.5870 * g) &#x2B; (0.1140 * b);&#xA;                }&#xA;            }&#xA;        }&#xA;        finally&#xA;        {&#xA;            image.UnlockBits(data);&#xA;        }&#xA;        return DataRectangle.For(values);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;With these classes, we can load an image and calculate the combined horizontal-gradient-minus-vertical-gradient value like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static IEnumerable&amp;lt;Rectangle&amp;gt; GetPossibleBarcodeAreasForBitmap(Bitmap image)&#xA;{&#xA;    var greyScaleImageData = image.GetGreyscale();&#xA;    var combinedGradients = greyScaleImageData.Transform((intensity, pos) =&amp;gt;&#xA;    {&#xA;        // Consider gradients to be zero at the edges of the image because there aren&#x27;t pixels&#xA;        // both left/right or above/below and so it&#x27;s not possible to calculate a real value&#xA;        var horizontalChange = (pos.X == 0) || (pos.X == greyScaleImageData.Width - 1)&#xA;            ? 0&#xA;            : greyScaleImageData[pos.X &#x2B; 1, pos.Y] - greyScaleImageData[pos.X - 1, pos.Y];&#xA;        var verticalChange = (pos.Y == 0) || (pos.Y == greyScaleImageData.Height - 1)&#xA;            ? 0&#xA;            : greyScaleImageData[pos.X, pos.Y &#x2B; 1] - greyScaleImageData[pos.X, pos.Y - 1];&#xA;        return Math.Max(0, Math.Abs(horizontalChange) - Math.Abs(verticalChange));&#xA;    });&#xA;&#xA;    // .. more will go here soon&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Before jumping straight into the image analysis, though, it&#x27;s worth resizing the source image if it&#x27;s large. Since this stage of the processing is looking for areas that look approximately like barcodes, we don&#x27;t require a lot of granularity - I&#x27;m envisaging (as with the MyFitnessPal use case) source images where the barcode takes up a significant space in the image and is roughly aligned with the view port* and so resizing the image such that the largest side is 300px should work well. If you wanted to scan an image where there were many barcodes to process (or even where there was only one but it was very small) then you might want to allow larger inputs than this - the more data that there is, though, the more work that must be done and the slower that the processing will be!&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(The barcode has to be roughly aligned with the viewport because the approaching of looking for areas with large horizontal variance in intensity with minor vertical variance would not work - as we&#x27;ll see later, though, there is considerable margin for error in this approach and perfect alignment is not required)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;A naive approach to this would be force the image so that its largest side is 300px, regardless of what it was originally. However, this is unnecessary if the largest side is already less than 300px (scaling it up will actually give us more work to do) and if the largest side is not much more than 300px then it&#x27;s probably not worth doing either - scaling it down may make any barcodes areas fuzzy and risk reducing the effectiveness of the processing while not actually reducing the required work. So I&#x27;m going to say that if the largest side of the image is 450px or larger than resize it so that its largest side is 300px and do nothing otherwise. To achieve that, we need a method like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static DataRectangle&amp;lt;double&amp;gt; GetGreyscaleData(&#xA;    Bitmap image,&#xA;    int resizeIfLargestSideGreaterThan,&#xA;    int resizeTo)&#xA;{&#xA;    var largestSide = Math.Max(image.Width, image.Height);&#xA;    if (largestSide &amp;lt;= resizeIfLargestSideGreaterThan)&#xA;        return image.GetGreyscale();&#xA;&#xA;    int width, height;&#xA;    if (image.Width &amp;gt; image.Height)&#xA;    {&#xA;        width = resizeTo;&#xA;        height = (int)(((double)image.Height / image.Width) * width);&#xA;    }&#xA;    else&#xA;    {&#xA;        height = resizeTo;&#xA;        width = (int)(((double)image.Width / image.Height) * height);&#xA;    }&#xA;    using var resizedImage = new Bitmap(image, width, height);&#xA;    return resizedImage.GetGreyscale();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The next steps are to &amp;quot;normalise&amp;quot; the combined intensity variance values so that they fit the range zero-to-one, to &amp;quot;blur&amp;quot; this data and to then create a binary mask where the brighter pixels get set to one and the darker pixels get set to zero. In other words, to extend the code earlier (that calculated the intensity variance values) like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static IEnumerable&amp;lt;Rectangle&amp;gt; GetPossibleBarcodeAreasForBitmap(Bitmap image)&#xA;{&#xA;    var greyScaleImageData = GetGreyscaleData(&#xA;        image,&#xA;        resizeIfLargestSideGreaterThan: 450,&#xA;        resizeTo: 300&#xA;    );&#xA;    var combinedGradients = greyScaleImageData.Transform((intensity, pos) =&amp;gt;&#xA;    {&#xA;        // Consider gradients to be zero at the edges of the image because there aren&#x27;t pixels&#xA;        // both left/right or above/below and so it&#x27;s not possible to calculate a real value&#xA;        var horizontalChange = (pos.X == 0) || (pos.X == greyScaleImageData.Width - 1)&#xA;            ? 0&#xA;            : greyScaleImageData[pos.X &#x2B; 1, pos.Y] - greyScaleImageData[pos.X - 1, pos.Y];&#xA;        var verticalChange = (pos.Y == 0) || (pos.Y == greyScaleImageData.Height - 1)&#xA;            ? 0&#xA;            : greyScaleImageData[pos.X, pos.Y &#x2B; 1] - greyScaleImageData[pos.X, pos.Y - 1];&#xA;        return Math.Max(0, Math.Abs(horizontalChange) - Math.Abs(verticalChange));&#xA;    });&#xA;&#xA;    const int maxRadiusForGradientBlurring = 2;&#xA;    const double thresholdForMaskingGradients = 1d / 3;&#xA;&#xA;    var mask = Blur(Normalise(combinedGradients), maxRadiusForGradientBlurring)&#xA;        .Transform(value =&amp;gt; (value &amp;gt;= thresholdForMaskingGradients));&#xA;&#xA;    // .. more will go here soon&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;To do that we, need a &amp;quot;Normalise&amp;quot; method - which is simple:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static DataRectangle&amp;lt;double&amp;gt; Normalise(DataRectangle&amp;lt;double&amp;gt; values)&#xA;{&#xA;    var max = values.Enumerate().Max(pointAndValue =&amp;gt; pointAndValue.Item2);&#xA;    return (max == 0)&#xA;        ? values&#xA;        : values.Transform(value =&amp;gt; (value / max));&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and a &amp;quot;Blur&amp;quot; method - which is a little less simple but hopefully still easy enough to follow &lt;em&gt;(for every point, look at the points around it and take an average of all of them; it just looks for a square area, which is fine for small &amp;quot;maxRadius&amp;quot; values but which might be better implemented as a circular area if large &amp;quot;maxRadius&amp;quot; values might be needed, which they aren&#x27;t in this code):&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static DataRectangle&amp;lt;double&amp;gt; Blur(DataRectangle&amp;lt;double&amp;gt; values, int maxRadius)&#xA;{&#xA;    return values.Transform((value, point) =&amp;gt;&#xA;    {&#xA;        var valuesInArea = new List&amp;lt;double&amp;gt;();&#xA;        for (var x = -maxRadius; x &amp;lt;= maxRadius; x&#x2B;&#x2B;)&#xA;        {&#xA;            for (var y = -maxRadius; y &amp;lt;= maxRadius; y&#x2B;&#x2B;)&#xA;            {&#xA;                var newPoint = new Point(point.X &#x2B; x, point.Y &#x2B; y);&#xA;                if ((newPoint.X &amp;lt; 0) || (newPoint.Y &amp;lt; 0)&#xA;                || (newPoint.X &amp;gt;= values.Width) || (newPoint.Y &amp;gt;= values.Height))&#xA;                    continue;&#xA;                valuesInArea.Add(values[newPoint.X, newPoint.Y]);&#xA;            }&#xA;        }&#xA;        return valuesInArea.Average();&#xA;    });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This gets us to this point:&lt;/p&gt;&#xA;&lt;img alt=&quot;Mask of possibly-part-of-a-barcode areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-Mask.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. which feels like good progress!&lt;/p&gt;&#xA;&lt;p&gt;Now we need to try to identify distinct &amp;quot;islands&amp;quot; of pixels where each &amp;quot;island&amp;quot; or &amp;quot;object&amp;quot; is a set of points that are within a single connected area. A straightforward way to do that is to look at every point in the mask that is set to 1 and either:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Perform a pixel-style &amp;quot;flood fill&amp;quot; starting at this point in order to find other points in an object&lt;/li&gt;&#xA;&lt;li&gt;If this pixel has already been included in such a fill operation, do nothing (because it&#x27;s already been accounted for)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This was made easier for me by reading the article &lt;a href=&quot;https://simpledevcode.wordpress.com/2015/12/29/flood-fill-algorithm-using-c-net/&quot;&gt;Flood Fill algorithm (using C#.Net)&lt;/a&gt;..&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static IEnumerable&amp;lt;IEnumerable&amp;lt;Point&amp;gt;&amp;gt; GetDistinctObjects(DataRectangle&amp;lt;bool&amp;gt; mask)&#xA;{&#xA;    // Flood fill areas in the looks-like-bar-code mask to create distinct areas&#xA;    var allPoints = new HashSet&amp;lt;Point&amp;gt;(&#xA;        mask.Enumerate(optionalFilter: (point, isMasked) =&amp;gt; isMasked).Select(point =&amp;gt; point.Item1)&#xA;    );&#xA;    while (allPoints.Any())&#xA;    {&#xA;        var currentPoint = allPoints.First();&#xA;        var pointsInObject = GetPointsInObject(currentPoint).ToArray();&#xA;        foreach (var point in pointsInObject)&#xA;            allPoints.Remove(point);&#xA;        yield return pointsInObject;&#xA;    }&#xA;&#xA;    // Inspired by code at&#xA;    // https://simpledevcode.wordpress.com/2015/12/29/flood-fill-algorithm-using-c-net/&#xA;    IEnumerable&amp;lt;Point&amp;gt; GetPointsInObject(Point startAt)&#xA;    {&#xA;        var pixels = new Stack&amp;lt;Point&amp;gt;();&#xA;        pixels.Push(startAt);&#xA;&#xA;        var valueAtOriginPoint = mask[startAt.X, startAt.Y];&#xA;        var filledPixels = new HashSet&amp;lt;Point&amp;gt;();&#xA;        while (pixels.Count &amp;gt; 0)&#xA;        {&#xA;            var currentPoint = pixels.Pop();&#xA;            if ((currentPoint.X &amp;lt; 0) || (currentPoint.X &amp;gt;= mask.Width)&#xA;            || (currentPoint.Y &amp;lt; 0) || (currentPoint.Y &amp;gt;= mask.Height))&#xA;                continue;&#xA;&#xA;            if ((mask[currentPoint.X, currentPoint.Y] == valueAtOriginPoint)&#xA;            &amp;amp;&amp;amp; !filledPixels.Contains(currentPoint))&#xA;            {&#xA;                filledPixels.Add(new Point(currentPoint.X, currentPoint.Y));&#xA;                pixels.Push(new Point(currentPoint.X - 1, currentPoint.Y));&#xA;                pixels.Push(new Point(currentPoint.X &#x2B; 1, currentPoint.Y));&#xA;                pixels.Push(new Point(currentPoint.X, currentPoint.Y - 1));&#xA;                pixels.Push(new Point(currentPoint.X, currentPoint.Y &#x2B; 1));&#xA;            }&#xA;        }&#xA;        return filledPixels;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The problem is that, even with the blurring we performed, there will likely be some groups of distinct objects that are actually part of a single barcode. These areas need to be joined together. It&#x27;s quite possible for there to be relatively large gaps in the middle of barcodes (there is in the example that we&#x27;ve been looking at) and so we might not easily be able to just take the distinct objects that we&#x27;ve got and join together areas that seem &amp;quot;close enough&amp;quot;.&lt;/p&gt;&#xA;&lt;img alt=&quot;Areas that are possibly part of a barcode&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskObjects.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;On the basis that individual bars in a barcode are tall compared to the largest possible width that any of them can be (which I&#x27;ll go into more detail about later on), it seems like a reasonable idea to take any areas that are taller than they are wide and expand their width until they become square. That would give us this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Mask of possibly-part-of-a-barcode areas, extended into squared areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskSquares.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;We&#x27;d then work out which of these &amp;quot;squared off&amp;quot; rectangles overlap (if any) and replace overlapping rectangles with rectangles that cover their combined areas, which would look like this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Overlapping squared-off areas that have been combined&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskSquaresCombinedPreTrimmed.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;The only problem with this is that the combined rectangles extend too far to the left and right of the areas, so we need to trim them down. The will be fairly straightforward because we have the information about what distinct objects there are and each object is just a list of points - so we work out which objects have points within each of the combined bounding areas and then we work out which out of all of the objects for each combined area has the smallest &amp;quot;x&amp;quot; value and smallest &amp;quot;y&amp;quot; value and which have the largest values. That way, we can change the combined bounding areas to only cover actual barcode pixels. Which would leave us with this:&lt;/p&gt;&#xA;&lt;img alt=&quot;Combined possibly-a-barcode areas&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-MaskSquaresCombined.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;That might sound like a lot of complicated work but if we take a bit of a brute force* approach to it then it can be expressed like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static IEnumerable&amp;lt;Rectangle&amp;gt; GetOverlappingObjectBounds(&#xA;    IEnumerable&amp;lt;IEnumerable&amp;lt;Point&amp;gt;&amp;gt; objects)&#xA;{&#xA;    // Translate each &amp;quot;object&amp;quot; (a list of connected points) into a bounding box (squared off if&#xA;    // it was taller than it was wide)&#xA;    var squaredOffBoundedObjects = new HashSet&amp;lt;Rectangle&amp;gt;(&#xA;        objects.Select((points, index) =&amp;gt;&#xA;        {&#xA;            var bounds = Rectangle.FromLTRB(&#xA;                points.Min(p =&amp;gt; p.X),&#xA;                points.Min(p =&amp;gt; p.Y),&#xA;                points.Max(p =&amp;gt; p.X) &#x2B; 1,&#xA;                points.Max(p =&amp;gt; p.Y) &#x2B; 1&#xA;            );&#xA;            if (bounds.Height &amp;gt; bounds.Width)&#xA;                bounds.Inflate((bounds.Height - bounds.Width) / 2, 0);&#xA;            return bounds;&#xA;        })&#xA;    );&#xA;&#xA;    // Loop over the boundedObjects and reduce the collection by merging any two rectangles&#xA;    // that overlap and then starting again until there are no more bounds merges to perform&#xA;    while (true)&#xA;    {&#xA;        var combinedOverlappingAreas = false;&#xA;        foreach (var bounds in squaredOffBoundedObjects)&#xA;        {&#xA;            foreach (var otherBounds in squaredOffBoundedObjects)&#xA;            {&#xA;                if (otherBounds == bounds)&#xA;                    continue;&#xA;&#xA;                if (bounds.IntersectsWith(otherBounds))&#xA;                {&#xA;                    squaredOffBoundedObjects.Remove(bounds);&#xA;                    squaredOffBoundedObjects.Remove(otherBounds);&#xA;                    squaredOffBoundedObjects.Add(Rectangle.FromLTRB(&#xA;                        Math.Min(bounds.Left, otherBounds.Left),&#xA;                        Math.Min(bounds.Top, otherBounds.Top),&#xA;                        Math.Max(bounds.Right, otherBounds.Right),&#xA;                        Math.Max(bounds.Bottom, otherBounds.Bottom)&#xA;                    ));&#xA;                    combinedOverlappingAreas = true;&#xA;                    break;&#xA;                }&#xA;            }&#xA;            if (combinedOverlappingAreas)&#xA;                break;&#xA;        }&#xA;        if (!combinedOverlappingAreas)&#xA;            break;&#xA;    }&#xA;&#xA;    return squaredOffBoundedObjects.Select(bounds =&amp;gt;&#xA;    {&#xA;        var allPointsWithinBounds = objects&#xA;            .Where(points =&amp;gt; points.Any(point =&amp;gt; bounds.Contains(point)))&#xA;            .SelectMany(points =&amp;gt; points)&#xA;            .ToArray(); // Don&#x27;t re-evaluate in the four accesses below&#xA;        return Rectangle.FromLTRB(&#xA;            left: allPointsWithinBounds.Min(p =&amp;gt; p.X),&#xA;            right: allPointsWithinBounds.Max(p =&amp;gt; p.X) &#x2B; 1,&#xA;            top: allPointsWithinBounds.Min(p =&amp;gt; p.Y),&#xA;            bottom: allPointsWithinBounds.Max(p =&amp;gt; p.Y) &#x2B; 1&#xA;        );&#xA;    });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;* &lt;em&gt;(There are definitely more efficient ways that this could be done but since we&#x27;re only looking at 300px images then we&#x27;re not likely to end up with huge amounts of data to deal with)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;To complete the process, we need to do three more things:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Since barcodes are wider than they are tall, we can discard any regions that don&#x27;t fit this shape (of which there are two in the example image)&lt;/li&gt;&#xA;&lt;li&gt;The remaining regions are expanded a little across so that they more clearly surround the barcode region, rather than being butted right up to it (this will make the barcode reading process a little easier)&lt;/li&gt;&#xA;&lt;li&gt;As the regions that have been identified may well be on a resized version of the source image, they may need to scaled up so that they correctly apply to the source&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;To do that, we&#x27;ll start from this code that we saw earlier:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var mask = Blur(Normalise(combinedGradients), maxRadiusForGradientBlurring)&#xA;    .Transform(value =&amp;gt; (value &amp;gt;= thresholdForMaskingGradients));&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and expand it like so (removing the &amp;quot;// .. more will go here soon&amp;quot; comment), using the methods above:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// Determine how much the image was scaled down (if it had to be scaled down at all)&#xA;// by comparing the width of the potentially-scaled-down data to the source image&#xA;var reducedImageSideBy = (double)image.Width / greyScaleImageData.Width;&#xA;&#xA;var mask = Blur(Normalise(combinedGradients), maxRadiusForGradientBlurring)&#xA;    .Transform(value =&amp;gt; (value &amp;gt;= thresholdForMaskingGradients));&#xA;&#xA;return GetOverlappingObjectBounds(GetDistinctObjects(mask))&#xA;    .Where(boundedObject =&amp;gt; boundedObject.Width &amp;gt; boundedObject.Height)&#xA;    .Select(boundedObject =&amp;gt;&#xA;    {&#xA;        var expandedBounds = boundedObject;&#xA;        expandedBounds.Inflate(width: expandedBounds.Width / 10, height: 0);&#xA;        expandedBounds.Intersect(&#xA;            Rectangle.FromLTRB(0, 0, greyScaleImageData.Width, greyScaleImageData.Height)&#xA;        );&#xA;        return new Rectangle(&#xA;            x: (int)(expandedBounds.X * reducedImageSideBy),&#xA;            y: (int)(expandedBounds.Y * reducedImageSideBy),&#xA;            width: (int)(expandedBounds.Width * reducedImageSideBy),&#xA;            height: (int)(expandedBounds.Height * reducedImageSideBy)&#xA;        );&#xA;    });&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The final result is that the barcode has been successfully located on the image - hurrah!&lt;/p&gt;&#xA;&lt;img alt=&quot;Barcode located!&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-Identified.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;With this information, we should be able to extract regions or &amp;quot;sub images&amp;quot; from the source image and attempt to decipher the barcode value in it (presuming that there IS a bar code in it and we haven&#x27;t got a false positive match).&lt;/p&gt;&#xA;&lt;p&gt;As we&#x27;ll see in a moment, the barcode doesn&#x27;t have to be perfectly lined up - some rotation is acceptable (depending upon the image, up to around 20 or 30 degrees should be fine). The MyFitnessPal app has a couple of fallbacks that I&#x27;ve noticed, such as being able to read barcodes that are upside down or even back to front (which can happen if a barcode is scanned from the wrong side of a transparent wrapper). While I won&#x27;t be writing code here for either of those approaches, I&#x27;m sure that you could envisage how it could be done - the source image data could be processed as described here and then, if no barcode is read, rotated 180 degrees and re-processed and reversed and re-processed, etc..&lt;/p&gt;&#xA;&lt;h3&gt;How to read a bar code&lt;/h3&gt;&#xA;&lt;p&gt;A barcode is comprised of both black and white bars - so it&#x27;s not just the black parts that are significant, it is the spaces between them as well.&lt;/p&gt;&#xA;&lt;p&gt;The format of a barcode is as follows:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Three single-width bars (a black one, a white one and another black one) that are used to gauge what is considered to be a &amp;quot;single width&amp;quot;&lt;/li&gt;&#xA;&lt;li&gt;Information for six numbers then appears, where each number is encoded by a sequence of four bars (white, black, white, black) - particular combinations of bar widths relate to particular digits (see below)&lt;/li&gt;&#xA;&lt;li&gt;Another guard section appears with five single width bars (white, black, white, black, white)&lt;/li&gt;&#xA;&lt;li&gt;Six more numbers appear (using the same bar-width-combinations encoding as before but the groups of four bars are now black, white, black, white)&lt;/li&gt;&#xA;&lt;li&gt;A final guard section of three single width bards (black, white, black)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The numbers are encoded using the following system:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt; Digit      Bar widths&#xA;&#xA;   0        3, 2, 1, 1&#xA;   1        2, 2, 2, 1&#xA;   2        2, 1, 2, 2&#xA;   3        1, 4, 1, 1&#xA;   4        1, 1, 3, 2&#xA;   5        1, 2, 3, 1&#xA;   6        1, 1, 1, 4&#xA;   7        1, 3, 1, 2&#xA;   8        1, 2, 1, 3&#xA;   9        3, 1, 1, 2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;(Note that every combination of values totals 7 when they added up - this is very helpful later!)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;To see what that looks like in the real world, here&#x27;s a slice of that barcode from the jar of peanut butter with each section and each numberic value identified:&lt;/p&gt;&#xA;&lt;img alt=&quot;Barcode numbers interpreted&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-AnnotatedValues.png&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;&lt;em&gt;(I should point out that the article &lt;a href=&quot;https://habr.com/en/post/439768/&quot;&gt;How does a barcode work?&lt;/a&gt; was extremely helpful in the research I did for this post and I&#x27;m very grateful to the author for having written it in such an approachable manner!)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Any combination of bar widths that is not found in the table is considered to be invalid. On the one hand, you might think that this a potential loss; the format could support more combinations of bar widths to encode more values and then more data could be packed into the same space. There is an advantage, however, to having relatively few valid combinations of bar widths - it makes easier to tell whether the information being read appears to be correct. If a combination is encountered that seems incorrect then the read attempt should be aborted and retried. The format has existed for decades and it would make sense, bearing that in mind, to prioritise making it easier for the hardware to read rather prioritising trying to cram as much data in there as possible. There is &lt;em&gt;also&lt;/em&gt; a checksum included in the numerical data to try to catch any &amp;quot;misreads&amp;quot; but when working with low resolutions or hardware with little computing power, the easier that it is to bail out of a scan and to retry the better.&lt;/p&gt;&#xA;&lt;p&gt;The way to tackle the reading is to:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Convert the sub image to greyscale&lt;/li&gt;&#xA;&lt;li&gt;Create a binary mask so that the darker pixels become 0 and the lighter ones become 1&lt;/li&gt;&#xA;&lt;li&gt;Take a single line across the area&lt;/li&gt;&#xA;&lt;li&gt;Change the individual 1s and 0s into lengths of continuous &amp;quot;runs&amp;quot; of values&#xA;&lt;ul&gt;&#xA;&lt;li&gt;eg. 0001100 would become 3, 2, 2 because there are three 0s then two 1s and then two 0s&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;These runs of values will represent the different sized (black and white) bars that were encountered&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For a larger image, each run length will be longer than for a small image but that won&#x27;t matter because when we encounter runs of four bar length values that we think should be interpreted as a single digit, we&#x27;ll do some dividing to try to guess the average size of a single width bar&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Take these runs of values, skip through the expected guard regions and try to interpret each set of four bars that is thought to represent a digit of the bar code as that digit&lt;/li&gt;&#xA;&lt;li&gt;If successful then perform a checksum calculation on the output and return the value ass a success if it meets expectations&lt;/li&gt;&#xA;&lt;li&gt;If the line couldn&#x27;t be interpreted as a barcode or the checksum calculation fails then take the next line down and go back to step 4&lt;/li&gt;&#xA;&lt;li&gt;If there are no more lines to attempt then a barcode could not be identified in the image&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This processing is fairly light computationally and so there is no need to resize the &amp;quot;may be a barcode&amp;quot; image region before attempting the work. In fact, it&#x27;s benefical to &lt;em&gt;not&lt;/em&gt; shrink it as shrinking it will likely make the barcode section fuzzier and that makes the above steps less likely to work - the ideal case for creating a binary mask is where there is no significant &amp;quot;seepage&amp;quot; of pixel intensity between the black bar areas and the white bar areas. That&#x27;s not to say that the images have to be crystal clear or perfectly aligned with the camera because the redundancy built into the format works in our favour here - if one line across the image can&#x27;t be read because it&#x27;s fuzzy then there&#x27;s a good chance that one of the other lines will be legible.&lt;/p&gt;&#xA;&lt;p&gt;60 length values is the precise number that we expect to find - there is expected to be some blank space before the barcode starts (1) and then a guard section of three single-width lines that we use to gauge bar width (3) and then six numbers that are encoded in four bars each (6x4=24) and then a guard section of five single-width lines (5) and then six numbers (6x4=24) and then a final guard region of three single-width bars, giving 1&#x2B;3&#x2B;24&#x2B;5&#x2B;24&#x2B;3=60.&lt;/p&gt;&#xA;&lt;p&gt;There will likely be another section of blank content after the barcode that we ignore&lt;/p&gt;&#xA;&lt;p&gt;If we don&#x27;t want to validate the final guard region then we can work with a barcode image where some of the end of cut off, so long as the data for the 12 digits is there; in this case, 57 lengths if the minimum number that we can accept&lt;/p&gt;&#xA;&lt;h3&gt;Reading the numeric value with code&lt;/h3&gt;&#xA;&lt;p&gt;I&#x27;m going to try to present the code in approximately the same order as the steps presented above. So, firstly we need to convert the sub image to greyscale and create a binary mark from it. Then we&#x27;ll go line by line down the image data and try to read a value. So we&#x27;ll take this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public static string? TryToReadBarcodeValue(Bitmap subImage)&#xA;{&#xA;    const double threshold = 0.5;&#xA;&#xA;     // Black lines are considered 1 and so we set to true if it&#x27;s a dark pixel (and 0 if light)&#xA;    var mask = subImage.GetGreyscale().Transform(intensity =&amp;gt; intensity &amp;lt; (256 * threshold));&#xA;    for (var y = 0; y &amp;lt; mask.Height; y&#x2B;&#x2B;)&#xA;    {&#xA;        var value = TryToReadBarcodeValueFromSingleLine(mask, y);&#xA;        if (value is object)&#xA;            return value;&#xA;    }&#xA;    return null;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and the read-each-slice-of-the-image code looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static string? TryToReadBarcodeValueFromSingleLine(&#xA;    DataRectangle&amp;lt;bool&amp;gt; barcodeDetails,&#xA;    int sliceY)&#xA;{&#xA;    if ((sliceY &amp;lt; 0) || (sliceY &amp;gt;= barcodeDetails.Height))&#xA;        throw new ArgumentOutOfRangeException(nameof(sliceY));&#xA;&#xA;    var lengths = GetBarLengthsFromBarcodeSlice(barcodeDetails, sliceY).ToArray();&#xA;    if (lengths.Length &amp;lt; 57)&#xA;    {&#xA;        // As explained, we&#x27;d like 60 bars (which would include the final guard region) but we&#xA;        // can still make an attempt with 57 (but no fewer)&#xA;        // - There will often be another section of blank content after the barcode that we ignore&#xA;        // - If we don&#x27;t want to validate the final guard region then we can work with a barcode&#xA;        //   image where some of the end is cut off, so long as the data for the 12 digits is&#xA;        //   there (this will be the case where there are only 57 lengths)&#xA;        return null;&#xA;    }&#xA;&#xA;    var offset = 0;&#xA;    var extractedNumericValues = new List&amp;lt;int&amp;gt;();&#xA;    for (var i = 0; i &amp;lt; 14; i&#x2B;&#x2B;)&#xA;    {&#xA;        if (i == 0)&#xA;        {&#xA;            // This should be the first guard region and it should be a pattern of three single-&#xA;            // width bars&#xA;            offset &#x2B;= 3;&#xA;        }&#xA;        else if (i == 7)&#xA;        {&#xA;            // This should be the guard region in the middle of the barcode and it should be a&#xA;            // pattern of five single-width bars&#xA;            offset &#x2B;= 5;&#xA;        }&#xA;        else&#xA;        {&#xA;            var value = TryToGetValueForLengths(&#xA;                lengths[offset],&#xA;                lengths[offset &#x2B; 1],&#xA;                lengths[offset &#x2B; 2],&#xA;                lengths[offset &#x2B; 3]&#xA;            );&#xA;            if (value is null)&#xA;                return null;&#xA;            extractedNumericValues.Add(value.Value);&#xA;            offset &#x2B;= 4;&#xA;        }&#xA;    }&#xA;&#xA;    // Calculate what the checksum should be based upon the first 11 numbers and ensure that&#xA;    // the 12th matches it&#xA;    if (extractedNumericValues.Last() != CalculateChecksum(extractedNumericValues.Take(11)))&#xA;        return null;&#xA;&#xA;    return string.Join(&amp;quot;&amp;quot;, extractedNumericValues);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;With the code below, we find the runs of continous 0 or 1 lengths that will represent bars are return that list (again, for larger images each run will be longer and for smaller images each run will be shorter but this will be taken care of later) -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static IEnumerable&amp;lt;int&amp;gt; GetBarLengthsFromBarcodeSlice(&#xA;    DataRectangle&amp;lt;bool&amp;gt; barcodeDetails,&#xA;    int sliceY)&#xA;{&#xA;    if ((sliceY &amp;lt; 0) || (sliceY &amp;gt;= barcodeDetails.Height))&#xA;        throw new ArgumentOutOfRangeException(nameof(sliceY));&#xA;&#xA;    // Take the horizontal slice of the data&#xA;    var values = new List&amp;lt;bool&amp;gt;();&#xA;    for (var x = 0; x &amp;lt; barcodeDetails.Width; x&#x2B;&#x2B;)&#xA;        values.Add(barcodeDetails[x, sliceY]);&#xA;&#xA;    // Split the slice into bars - we only care about how long each segment is when they&#xA;    // alternate, not whether they&#x27;re dark bars or light bars&#xA;    var segments = new List&amp;lt;Tuple&amp;lt;bool, int&amp;gt;&amp;gt;();&#xA;    foreach (var value in values)&#xA;    {&#xA;        if ((segments.Count == 0) || (segments[^1].Item1 != value))&#xA;            segments.Add(Tuple.Create(value, 1));&#xA;        else&#xA;            segments[^1] = Tuple.Create(value, segments[^1].Item2 &#x2B; 1);&#xA;    }&#xA;    if ((segments.Count &amp;gt; 0) &amp;amp;&amp;amp; !segments[0].Item1)&#xA;    {&#xA;        // Remove the white space before the first bar&#xA;        segments.RemoveAt(0);&#xA;    }&#xA;    return segments.Select(segment =&amp;gt; segment.Item2);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now we need to implement the &amp;quot;TryToGetValueForLengths&amp;quot; method that &amp;quot;TryToReadBarcodeValueFromSingleLine&amp;quot; calls. This takes four bar lengths that are thought to represent a single digit in the bar code value (they are not part of a guard region or anything like that). It take those four bar lengths and guesses how many pixels across a single bar would be - which is made my simpler by the fact that all of the possible combinations of bar lengths in the lookup chart that we saw earlier add up to 7.&lt;/p&gt;&#xA;&lt;p&gt;There&#x27;s a little flexibility introduced here to try to account for a low quality image or if the threshold was a bit strong in the creation of the binary mask; we&#x27;ll take that calculated expected width of a single bar and tweak it up or down a little if apply that division to the bar lengths means that we made some of the bars too small that they disappeared or too large and it seemed like the total width would be more than seven single estimated-width bars. There&#x27;s only a &lt;em&gt;little&lt;/em&gt; flexibility here because if we fail then we can always try another line of the image! (Or maybe it will turn out that this sub image was a false positive match and there isn&#x27;t a bar code in it at all).&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static int? TryToGetValueForLengths(int l0, int l1, int l2, int l3)&#xA;{&#xA;    if (l0 &amp;lt;= 0)&#xA;        throw new ArgumentOutOfRangeException(nameof(l0));&#xA;    if (l1 &amp;lt;= 0)&#xA;        throw new ArgumentOutOfRangeException(nameof(l1));&#xA;    if (l2 &amp;lt;= 0)&#xA;        throw new ArgumentOutOfRangeException(nameof(l2));&#xA;    if (l3 &amp;lt;= 0)&#xA;        throw new ArgumentOutOfRangeException(nameof(l3));&#xA;&#xA;    // Take a guess at what the width of a single bar is based upon these four values&#xA;    // (the four bars that encode a number should add up to a width of seven)&#xA;    var raw = new[] { l0, l1, l2, l3 };&#xA;    var singleWidth = raw.Sum() / 7d;&#xA;    var adjustment = singleWidth / 10;&#xA;    var attemptedSingleWidths = new HashSet&amp;lt;double&amp;gt;();&#xA;    while (true)&#xA;    {&#xA;        var normalised = raw.Select(x =&amp;gt; Math.Max(1, (int)Math.Round(x / singleWidth))).ToArray();&#xA;        var sum = normalised.Sum();&#xA;        if (sum == 7)&#xA;            return TryToGetNumericValue(normalised[0], normalised[1], normalised[2], normalised[3]);&#xA;&#xA;        attemptedSingleWidths.Add(singleWidth);&#xA;        if (sum &amp;gt; 7)&#xA;            singleWidth &#x2B;= adjustment;&#xA;        else&#xA;            singleWidth -= adjustment;&#xA;        if (attemptedSingleWidths.Contains(singleWidth))&#xA;        {&#xA;            // If we&#x27;ve already tried this width-of-a-single-bar value then give up -&#xA;            // it doesn&#x27;t seem like we can make the input values make sense&#xA;            return null;&#xA;        }&#xA;    }&#xA;&#xA;    static int? TryToGetNumericValue(int i0, int i1, int i2, int i3)&#xA;    {&#xA;        var lookFor = string.Join(&amp;quot;&amp;quot;, new[] { i0, i1, i2, i3 });&#xA;        var lookup = new[]&#xA;        {&#xA;            // These values correspond to the lookup chart shown earlier&#xA;            &amp;quot;3211&amp;quot;, &amp;quot;2221&amp;quot;, &amp;quot;2122&amp;quot;, &amp;quot;1411&amp;quot;, &amp;quot;1132&amp;quot;, &amp;quot;1231&amp;quot;, &amp;quot;1114&amp;quot;, &amp;quot;1312&amp;quot;, &amp;quot;1213&amp;quot;, &amp;quot;3112&amp;quot;&#xA;        };&#xA;        for (var i = 0; i &amp;lt; lookup.Length; i&#x2B;&#x2B;)&#xA;        {&#xA;            if (lookFor == lookup[i])&#xA;                return i;&#xA;        }&#xA;        return null;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Finally we need the CalculateChecksum method (as noted in the code, there&#x27;s a great explanation of how to do this in &lt;a href=&quot;https://en.wikipedia.org/wiki/Check_digit#UPC&quot;&gt;wikipedia&lt;/a&gt;) -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private static int CalculateChecksum(IEnumerable&amp;lt;int&amp;gt; values)&#xA;{&#xA;    if (values == null)&#xA;        throw new ArgumentNullException(nameof(values));&#xA;    if (values.Count() != 11)&#xA;        throw new ArgumentException(&amp;quot;Should be provided with precisely 11 values&amp;quot;);&#xA;&#xA;    // See https://en.wikipedia.org/wiki/Check_digit#UPC&#xA;    var checksumTotal = values&#xA;        .Select((value, index) =&amp;gt; (index % 2 == 0) ? (value * 3) : value)&#xA;        .Sum();&#xA;    var checksumModulo = checksumTotal % 10;&#xA;    if (checksumModulo != 0)&#xA;        checksumModulo = 10 - checksumModulo;&#xA;    return checksumModulo;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;With this code, we have executed all of the planned steps outlined before.&lt;/p&gt;&#xA;&lt;p&gt;It should be noted that, even with the small amount of flexibility in the &amp;quot;TryToGetValueForLengths&amp;quot; method, in the peanut butter bar code example it requires 15 calls to &amp;quot;GetBarLengthsFromBarcodeSlice&amp;quot; until a bar code is successfully matched! Presumably, this is because there is a little more distortion further up the bar code due to the curve of the jar.&lt;/p&gt;&#xA;&lt;p&gt;That&#x27;s not to say, however, that this approach to bar reading is particularly fussy. The redundancy and simplicity, not to mention the &lt;em&gt;size&lt;/em&gt; of the average bar code, means that there is plenty of opportunity to try reading a sub image in multiple slices until one of them does match. In fact, I mentioned earlier that the barcode doesn&#x27;t have to be perfectly at 90 degrees in order to be interpretable and that some rotation is acceptable. This hopefully makes some intuitive sense based upon the logic above and how it doesn&#x27;t matter how long each individual bar code line is because they are averaged out - if a bar code was rotated a little and then a read was attempted of it line by line then the ratios between each line should remain consistent and the same data should be readable.&lt;/p&gt;&#xA;&lt;p&gt;To illustrate, here&#x27;s a zoomed-in section of the middle of the peanut butter bar code in the orientation shown so far:&lt;/p&gt;&#xA;&lt;img alt=&quot;A strip of the peanut butter jar&#x27;s bar code&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-SingleStrip.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;If we then rotate it like this:&lt;/p&gt;&#xA;&lt;img alt=&quot;The peanut butter jar rotated slightly&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-Rotated.png&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;.. then the code above will still read the value correctly because a strip across the rotated bar code looks like this:&lt;/p&gt;&#xA;&lt;img alt=&quot;A strip of the peanut butter jar&#x27;s bar code from the rotated image&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-SingleStripFromRotated.png&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;Hopefully it&#x27;s clear enough that, for each given line, the ratios are essentially the same as for the non-rotated strip:&lt;/p&gt;&#xA;&lt;img alt=&quot;A strip of the peanut butter jar&#x27;s bar code&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/PeanutBarcode-SingleStrip.jpg&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&#xA;&lt;p&gt;To get a reading from an image that is rotated more than this requires a very clear source image and will still be limited by the first stage of processing - that tried to find sections where the horizontal image intensity changed with steep gradients but the vertical intensity did not. If the image is rotated too much then there will be more vertical image intensity differences encountered and it is less likely to identify it as a &amp;quot;maybe a bar code&amp;quot; region.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(Note: I experimented with rotated images that were produced by an online barcode generator and had more success - meaning that I could rotate them more than I could with real photographs - but that&#x27;s because those images are generated with stark black and white and the horizontal / vertical intensity gradients are maintained for longer when the image is rotated if they start with such a high level of clarity.. I&#x27;m more interested in reading values from real photographs and so I would suggest that only fairly moderate rotation will work - though it would still be plenty for an MyFitnessPal-type app that expects the User to hold the bar code in roughly the right orientation!)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Tying it all together&lt;/h3&gt;&#xA;&lt;p&gt;We&#x27;ve looked at the separate steps involved in the whole reading process, all that is left is to combine them. The &amp;quot;GetPossibleBarcodeAreasForBitmap&amp;quot; and &amp;quot;TryToReadBarcodeValue&amp;quot; methods can be put together into a fully functioning program like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;static void Main()&#xA;{&#xA;    using var image = new Bitmap(&amp;quot;Source.jpg&amp;quot;);&#xA;&#xA;    var barcodeValues = new List&amp;lt;string&amp;gt;();&#xA;    foreach (var area in GetPossibleBarcodeAreasForBitmap(image))&#xA;    {&#xA;        using var areaBitmap = new Bitmap(area.Width, area.Height);&#xA;        using (var g = Graphics.FromImage(areaBitmap))&#xA;        {&#xA;            g.DrawImage(&#xA;                image,&#xA;                destRect: new Rectangle(0, 0, areaBitmap.Width, areaBitmap.Height),&#xA;                srcRect: area,&#xA;                srcUnit: GraphicsUnit.Pixel&#xA;            );&#xA;        }&#xA;        var valueFromBarcode = TryToReadBarcodeValue(areaBitmap);&#xA;        if (valueFromBarcode is object)&#xA;            barcodeValues.Add(valueFromBarcode);&#xA;    }&#xA;&#xA;    if (!barcodeValues.Any())&#xA;        Console.WriteLine(&amp;quot;Couldn&#x27;t read any bar codes from the source image :(&amp;quot;);&#xA;    else&#xA;    {&#xA;        Console.WriteLine(&amp;quot;Read the following bar code(s) from the image:&amp;quot;);&#xA;        foreach (var barcodeValue in barcodeValues)&#xA;            Console.WriteLine(&amp;quot;- &amp;quot; &#x2B; barcodeValue);&#xA;    }&#xA;&#xA;    Console.WriteLine();&#xA;    Console.WriteLine(&amp;quot;Press [Enter] to terminate..&amp;quot;);&#xA;    Console.ReadLine();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;Finito!&lt;/h3&gt;&#xA;&lt;p&gt;And with that, we&#x27;re finally done! I must admit that I started writing this post about three years ago and it&#x27;s been in my TODO list for a loooooong time now. But I&#x27;ve taken a week off work and been able to catch up with a few things and have finally been able to cross it off the list. And I&#x27;m quite relieved that I didn&#x27;t give up on it entirely because it was a fun little project and coming back to it now allowed me to tidy it up a bit with the newer C# 8 syntax and even enable the nullable reference types option on the project (I sure do hate unintentional nulls being allowed to sneak in!)&lt;/p&gt;&#xA;&lt;p&gt;A quick reminder if you want to see it in action or play about it yourself, the &lt;a href=&quot;https://github.com/ProductiveRage/BarcodeReader&quot;&gt;GitHub repo is here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Thanks to anyone that read this far!&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/face-or-no-face-finding-faces-in-photos-using-c-sharp-and-accordnet&quot;&gt;Face or no face (finding faces in photos using C# and Accord.NET)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/a-followup-to-implementing-f-sharp-inspired-with-updates-in-c-sharp&quot;&gt;A follow-up to &amp;quot;Implementing F#-inspired &amp;#x27;with&amp;#x27; updates in C#&amp;quot;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/implementing-f-sharp-inspired-with-updates-for-immutable-classes-in-c-sharp&quot;&gt;Implementing F#-inspired &amp;quot;with&amp;quot; updates for immutable classes in C#&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Fri, 07 Aug 2020 23:24:00 GMT</pubDate>
            </item>
            <item>
                <title>Removing ALL assembly names in Json.NET TypeNameHandling output</title>
                <link>https://www.productiverage.com/removing-all-assembly-names-in-jsonnet-typenamehandling-output</link>
                <guid>https://www.productiverage.com/removing-all-assembly-names-in-jsonnet-typenamehandling-output</guid>
                <description>&lt;p&gt;In some cases, it may be desirable to include type name information in &lt;a href=&quot;https://www.newtonsoft.com/json&quot;&gt;Json.NET&lt;/a&gt; output but for those type names to not include assembly names.&lt;/p&gt;&#xA;&lt;p&gt;In my case it&#x27;s because I have a &lt;a href=&quot;https://dev.to/rionmonster/sharing-is-caring-using-shared-projects-in-aspnet-e17&quot;&gt;Shared Project&lt;/a&gt; that contains classes that I want to appear in my .NET Core C# server code and in my &lt;a href=&quot;https://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt; client code and this results in the class names existing in assemblies with different names (but there are also other people with their own cases, such as &lt;a href=&quot;https://stackoverflow.com/questions/8039910/how-do-i-omit-the-assembly-name-from-the-type-name-while-serializing-and-deseria&quot;&gt;How do I omit the assembly name from the type name while serializing and deserializing in JSON.Net?&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Json.NET has support for customising how the type names are emitted and there is an answer in the Stack Overflow question that I linked just above that points to an &lt;a href=&quot;http://james.newtonking.com/archive/2011/11/19/json-net-4-0-release-4-bug-fixes&quot;&gt;article&lt;/a&gt; written by the Json.NET author illustrating how to do it. Essentially, you create a custom serialization binder that looks a bit like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public sealed class TypeNameAssemblyExcludingSerializationBinder : ISerializationBinder&#xA;{&#xA;    public static TypeNameAssemblyExcludingSerializationBinder Instance { get; }&#xA;        = new TypeNameAssemblyExcludingSerializationBinder();&#xA;&#xA;    private TypeNameAssemblyExcludingSerializationBinder() { }&#xA;&#xA;    public void BindToName(Type serializedType, out string assemblyName, out string typeName)&#xA;    {&#xA;        assemblyName = null;&#xA;        typeName = serializedType.FullName;&#xA;    }&#xA;&#xA;    public Type BindToType(string assemblyName, string typeName)&#xA;    {&#xA;        // Note: Some additional work may be required here if the assembly name has been removed&#xA;        // and you are not loading a type from the current assembly or one of the core libraries&#xA;        return Type.GetType(typeName);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Then you serialise your content something like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var json = JsonConvert.SerializeObject(&#xA;    new ExampleClass(123, &amp;quot;Test&amp;quot;),&#xA;    new JsonSerializerSettings&#xA;    {&#xA;        Formatting = Formatting.Indented,&#xA;        TypeNameHandling = TypeNameHandling.All,&#xA;        SerializationBinder = TypeNameAssemblyExcludingSerializationBinder.Instance&#xA;    }&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;If the &lt;strong&gt;ExampleClass&lt;/strong&gt; looked like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public sealed class ExampleClass&#xA;{&#xA;    public ExampleClass(int key, string name)&#xA;    {&#xA;        Key = key;&#xA;        Name = name;&#xA;    }&#xA;    public int Key { get; }&#xA;    public string Name { get; }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and was in a namespace called &amp;quot;Tester&amp;quot; then the resulting JSON would look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &amp;quot;$type&amp;quot;: &amp;quot;Tester.ExampleClass&amp;quot;,&#xA;  &amp;quot;Key&amp;quot;: 123,&#xA;  &amp;quot;Name&amp;quot;: &amp;quot;Test&amp;quot;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;To make the difference clear, if the custom serialisation binder had not been used (and if the containing assembly was also called &amp;quot;Tester&amp;quot;) then the JSON would have looked like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &amp;quot;$type&amp;quot;: &amp;quot;Tester.ExampleClass, Tester&amp;quot;,&#xA;  &amp;quot;Key&amp;quot;: 123,&#xA;  &amp;quot;Name&amp;quot;: &amp;quot;Test&amp;quot;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;So.. problem solved!&lt;/p&gt;&#xA;&lt;p&gt;Yes?&lt;/p&gt;&#xA;&lt;p&gt;No.&lt;/p&gt;&#xA;&lt;h3&gt;ISerializationBinder is not applied to generic type parameters&lt;/h3&gt;&#xA;&lt;p&gt;While everything was hunkydory in the example above, there are cases where it isn&#x27;t. For example, if we wanted to serialise a &lt;em&gt;list&lt;/em&gt; of &lt;strong&gt;ExampleClass&lt;/strong&gt; instances then we&#x27;d have code like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var json = JsonConvert.SerializeObject(&#xA;    new List&amp;lt;ExampleClass&amp;gt; { new ExampleClass(123, &amp;quot;Test&amp;quot;) },&#xA;    new JsonSerializerSettings&#xA;    {&#xA;        Formatting = Formatting.Indented,&#xA;        TypeNameHandling = TypeNameHandling.All,&#xA;        SerializationBinder = TypeNameAssemblyExcludingSerializationBinder.Instance&#xA;    }&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and the resulting JSON would look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &amp;quot;$type&amp;quot;: &amp;quot;System.Collections.Generic.List`1[[Tester.ExampleClass, Tester]]&amp;quot;,&#xA;  &amp;quot;$values&amp;quot;: [&#xA;    {&#xA;      &amp;quot;$type&amp;quot;: &amp;quot;Tester.ExampleClass&amp;quot;,&#xA;      &amp;quot;Key&amp;quot;: 123,&#xA;      &amp;quot;Name&amp;quot;: &amp;quot;Test&amp;quot;&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Without the custom serialisation binder, it would have looked like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &amp;quot;$type&amp;quot;: &amp;quot;System.Collections.Generic.List`1[[Tester.ExampleClass, Tester]], System.Private.CoreLib&amp;quot;,&#xA;  &amp;quot;$values&amp;quot;: [&#xA;    {&#xA;      &amp;quot;$type&amp;quot;: &amp;quot;Tester.ExampleClass, Tester&amp;quot;,&#xA;      &amp;quot;Key&amp;quot;: 123,&#xA;      &amp;quot;Name&amp;quot;: &amp;quot;Test&amp;quot;&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and so we&#x27;ve successfully removed &lt;em&gt;some&lt;/em&gt; of the assembly names as there is no mention of &amp;quot;System.Private.CoreLib&amp;quot; in the List&#x27;s type and the $type string for the &lt;strong&gt;ExampleClass&lt;/strong&gt; instance no longer mentions the &amp;quot;Tester&amp;quot; assembly name but the generic type of the List &lt;em&gt;does&lt;/em&gt; mention the &amp;quot;Tester&amp;quot; assembly name and we were trying to prevent assembly names from appearing in the type data!&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;ve had a good Google around this and there doesn&#x27;t seem to be a definitive answer anywhere and I had a need for one, so I&#x27;ve put together a solution that does what I need. There is an answer to a similar(ish) stack overflow question &lt;a href=&quot;https://stackoverflow.com/a/19927484/3813189&quot;&gt;here&lt;/a&gt; but it ends with a disclaimer that the regex provided would need tweaking to support nested types and &lt;strong&gt;a)&lt;/strong&gt; I definitely wanted to support nested generic type parameters (eg. a Dictionary that maps string keys to List-of-int values) and &lt;strong&gt;b)&lt;/strong&gt; regexes and me are not the best of friends - hence my going about it my own way!&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public sealed class TypeNameAssemblyExcludingSerializationBinder : ISerializationBinder&#xA;{&#xA;    public static TypeNameAssemblyExcludingSerializationBinder Instance { get; }&#xA;        = new TypeNameAssemblyExcludingSerializationBinder();&#xA;    private TypeNameAssemblyExcludingSerializationBinder() { }&#xA;&#xA;    public void BindToName(Type serializedType, out string assemblyName, out string typeName)&#xA;    {&#xA;        // Note: Setting the assemblyName to null here will only remove it from the main type itself -&#xA;        // it won&#x27;t remove it from any types specified as generic type parameters (that&#x27;s what the&#xA;        // RemoveAssemblyNames method is needed for)&#xA;        assemblyName = null;&#xA;        typeName = RemoveAssemblyNames(serializedType.FullName);&#xA;    }&#xA;&#xA;    public Type BindToType(string assemblyName, string typeName)&#xA;    {&#xA;        // Note: Some additional work may be required here if the assembly name has been removed&#xA;        // and you are not loading a type from the current assembly or one of the core libraries&#xA;        return Type.GetType(typeName);&#xA;    }&#xA;&#xA;    private static string RemoveAssemblyNames(string typeName)&#xA;    {&#xA;        var index = 0;&#xA;        var content = new StringBuilder();&#xA;        RecusivelyRemoveAssemblyNames();&#xA;        return content.ToString();&#xA;&#xA;        void RecusivelyRemoveAssemblyNames()&#xA;        {&#xA;            // If we started inside a type name - eg.&#xA;            //&#xA;            //   &amp;quot;System.Int32, System.Private.CoreLib&amp;quot;&#xA;            //&#xA;            // .. then we want to look for the comma that separates the type name from the assembly&#xA;            // information and ignore that content. If we started inside nested generic type content&#xA;            // - eg.&#xA;            //&#xA;            //  &amp;quot;[System.Int32, System.Private.CoreLib], [System.String, System.Private.CoreLib]&amp;quot;&#xA;            //&#xA;            // .. then we do NOT want to start ignoring content after any commas encountered. So&#xA;            // it&#x27;s important to know here which case we&#x27;re in.&#xA;            var insideTypeName = typeName[index] != &#x27;[&#x27;;&#xA;&#xA;            var ignoreContent = false;&#xA;            while (index &amp;lt; typeName.Length)&#xA;            {&#xA;                var c = typeName[index];&#xA;                index&#x2B;&#x2B;;&#xA;&#xA;                if (insideTypeName &amp;amp;&amp;amp; (c == &#x27;,&#x27;))&#xA;                {&#xA;                    ignoreContent = true;&#xA;                    continue;&#xA;                }&#xA;&#xA;                if (!ignoreContent)&#xA;                    content.Append(c);&#xA;&#xA;                if (c == &#x27;[&#x27;)&#xA;                    RecusivelyRemoveAssemblyNames();&#xA;                else if (c == &#x27;]&#x27;)&#xA;                {&#xA;                    if (ignoreContent)&#xA;                    {&#xA;                        // If we encountered a comma that indicated that we were about to start&#xA;                        // an assembly name then we&#x27;ll have stopped adding content to the string&#xA;                        // builder but we don&#x27;t want to lose this closing brace, so explicitly&#xA;                        // add it in if that&#x27;s the case&#xA;                        content.Append(c);&#xA;                    }&#xA;                    break;&#xA;                }&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;A note about resolving types from type names (without assemblies)&lt;/h3&gt;&#xA;&lt;p&gt;In .NET, the &amp;quot;Type.GetType&amp;quot; method will return null if it is given a type name that does not correspond to a type that exists in either the current assembly or in one of the core .NET libraries. In Bridge.NET, it doesn&#x27;t appear that they maintained that requirement and I believe that all types are available, even if an assembly name is not specified - but whether it is or isn&#x27;t, a similar approach could be used in both cases where you use reflection to look at all loaded assemblies and all of their available types and try to map assembly-name-less type names onto one of those. Getting into this would be completely out of the scope of this post and I&#x27;m hoping that you already have an idea in mind if you had got to the point where you wanted to remove all assembly names from your type metadata!&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/language-detection-and-wordsinsentence-classification-in-c-sharp&quot;&gt;Language detection and words-in-sentence classification in C#&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/writing-a-brackets-extension-in-typescript-in-brackets&quot;&gt;Writing a Brackets extension in TypeScript, in Brackets&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/if-you-can-keep-your-head-when-all-about-you-are-losing-theirs-and-blaming-it-on-vbscript&quot;&gt;If you can keep your head when all about you are losing theirs and blaming it on VBScript&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Tue, 04 Aug 2020 17:25:00 GMT</pubDate>
            </item>
            <item>
                <title>Private / local C# analysers (without NuGet)</title>
                <link>https://www.productiverage.com/private-local-c-sharp-analysers-without-nuget</link>
                <guid>https://www.productiverage.com/private-local-c-sharp-analysers-without-nuget</guid>
                <description>&lt;p&gt;(&lt;strong&gt;Note:&lt;/strong&gt; The information here depends upon the &amp;quot;new&amp;quot; .csproj format being used.. but it&#x27;s not that new any more, so hopefully that&#x27;s not a limitation for too many people)&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;m a big fan of writing analysers to catch common mistakes at compile time rather than run time. For example, the &lt;a href=&quot;https://github.com/ProductiveRage/DanSerialiser&quot;&gt;DanSerialiser&lt;/a&gt;, &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.Immutable&quot;&gt;Bridge.Immutable&lt;/a&gt; and &lt;a href=&quot;https://github.com/ProductiveRage/ProductiveRage.SealedClassVerification&quot;&gt;ProductiveRage.SealedClassVerification&lt;/a&gt; libraries that I&#x27;ve published all include some. The way that they&#x27;re traditionally distributed is as a NuGet package that installs the analyser into the desired project, which is great if you&#x27;re publishing a public package that you expect to be installed via nuget.org. But what if you wanted to create a non-public analyser for something that you were working on, can you do so &lt;em&gt;without&lt;/em&gt; creating a NuGet package? Yes.. but with some caveats.&lt;/p&gt;&#xA;&lt;p&gt;If you&#x27;re still interested then read on for the details!&lt;/p&gt;&#xA;&lt;p&gt;(For anyone who finds themselves in the &lt;strong&gt;&amp;quot;too lazy; didn&#x27;t read&amp;quot;&lt;/strong&gt; category, hopefully this gives you enough information as to whether to continue or not)&lt;/p&gt;&#xA;&lt;h3&gt;What I wish existed&lt;/h3&gt;&#xA;&lt;p&gt;Actually, before I talk about what I wish already existed (but which, unfortunately, does &lt;em&gt;not&lt;/em&gt; exist), I&#x27;ll get one option out of the way first; nuget.org is not the only place that NuGet packages can be published to. If you decided that you wanted to write an analyser for some conventions internal to your company then you could create a NuGet package and publish it on an &lt;em&gt;internal&lt;/em&gt; NuGet feed. It&#x27;s pretty easy and you have a range of options such as a private NuGet feed service within your network, a private hosted service (possible with MyGet, I believe) or you can even chuck all of your private NuGet .nupkg files into a folder (on your local computer or, I presume, on a network - though I&#x27;ve not tested that option) and then add that as a NuGet feed in Visual Studio. This &lt;em&gt;is&lt;/em&gt; straight forward but, still, occasionally I wish that it was possible to include an analyser project as part of a solution and have that analyser added to one of the other projects. Which brings me to..&lt;/p&gt;&#xA;&lt;p&gt;What I&#x27;ve really wanted, from time to time, is to be able to have one project (say, &amp;quot;MyLibrary&amp;quot;) in a solution and another project (say, &amp;quot;MyAnalyser&amp;quot;) where the second project is added an analyser reference to the first project.&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;d like it to be as simple as clicking on References on the &amp;quot;MyLibrary&amp;quot; project, then &amp;quot;Add an Analyzer&amp;quot; and then choosing the &amp;quot;MyAnalyser&amp;quot; project. This, however, is not currently possible.&lt;/p&gt;&#xA;&lt;p&gt;It seems that I&#x27;m not the only one that thinks that this would be nice, there is an issue on the &lt;a href=&quot;https://github.com/dotnet/roslyn/&quot;&gt;.NET Compiler Platform (&amp;quot;Roslyn&amp;quot;)&lt;/a&gt; repo relating to this: &lt;a href=&quot;https://github.com/dotnet/roslyn/issues/18093&quot;&gt;Adding Analyzers Via a Project Reference&lt;/a&gt;. The first reply is from a Senior Software Engineer at Microsoft who says:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;This would be one of the coolest features ever&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;.. which sounds like a great and promising start!&lt;/p&gt;&#xA;&lt;p&gt;However, the issue was raised in March 2017 and I don&#x27;t think that any progress has been made on it, so I don&#x27;t know when / if it will be tackled*.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(Having said that, just last month it was recategorised from &amp;quot;Backlog&amp;quot; to &amp;quot;IDE: InternalPriority&amp;quot; and even assigned Priority 1 - so maybe this &lt;strong&gt;will&lt;/strong&gt; change in the near future! We&#x27;ll have to wait and see)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3&gt;What &lt;em&gt;does&lt;/em&gt; exist&lt;/h3&gt;&#xA;&lt;p&gt;So the bad news is that there is no way in the UI to do what I want. But the good news is that there &lt;em&gt;is&lt;/em&gt; a way to move towards it with some manual .csproj editing.&lt;/p&gt;&#xA;&lt;p&gt;If I opened the MyLibrary.csproj from the example earlier then I could add the following section:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;ItemGroup&amp;gt;&#xA;  &amp;lt;ProjectReference Include=&amp;quot;..\MyAnalyser\MyAnalyser.csproj&amp;quot;&amp;gt;&#xA;    &amp;lt;ReferenceOutputAssembly&amp;gt;false&amp;lt;/ReferenceOutputAssembly&amp;gt;&#xA;    &amp;lt;OutputItemType&amp;gt;Analyzer&amp;lt;/OutputItemType&amp;gt;&#xA;  &amp;lt;/ProjectReference&amp;gt;&#xA;&amp;lt;/ItemGroup&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and the MyAnalyser would now be added to MyLibrary and it would check over the code that I&#x27;d written in MyLibrary project - reporting any resulting messages, warnings or error in the VS Error List. Hurrah!&lt;/p&gt;&#xA;&lt;p&gt;It seems like a pity that something seemingly so simple needs to be done by hand-editing the .csproj file instead of there being something in the VS GUI to do this but there are other features where you have to do the same. For example, if you want a project to target multiple frameworks when it&#x27;s built then you have to manually edit the .csproj file and rename the &amp;quot;targetframework&amp;quot; node to &amp;quot;targetframeworks&amp;quot; and then type in a semi-colon-delimited list of IDs of frameworks that you&#x27;re interested in - eg. from this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;TargetFramework&amp;gt;netcoreapp2.1&amp;lt;/TargetFramework&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. to this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;TargetFrameworks&amp;gt;netcoreapp2.1;net461&amp;lt;/TargetFrameworks&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;(It&#x27;s quite common to do this in &lt;a href=&quot;https://benchmarkdotnet.org/&quot;&gt;BenchmarkDotNet&lt;/a&gt; projects so that you can see how the results vary when your library is imported into different frameworks)&lt;/p&gt;&#xA;&lt;p&gt;The good news is that hand-editing the .csproj file is much easier with the file format that we have now than the old one! So having to do this is not the end of the world.&lt;/p&gt;&#xA;&lt;p&gt;It&#x27;s not &lt;em&gt;all&lt;/em&gt; rainbows and unicorns, though..&lt;/p&gt;&#xA;&lt;h3&gt;What are the downsides?&lt;/h3&gt;&#xA;&lt;p&gt;The biggest (and only, so far as I can tell) downside is that it seem like Visual Studio will somehow cache the analyser assembly after it loads it. This means that when you first open the solution, the analyser(s) in the MyAnalyser project will be run against the MyLibrary code and any messages, warnings and errors displayed.. &lt;em&gt;but&lt;/em&gt;, if you then change the MyAnalyser code and rebuild then those changes won&#x27;t affect the checks performed against MyLibrary.&lt;/p&gt;&#xA;&lt;p&gt;Even if you rebuild the entire solution (rebuilding MyAnalyser first and &lt;em&gt;then&lt;/em&gt; rebuilding MyLibrary, to try to force the new analyser assembly to be loaded).&lt;/p&gt;&#xA;&lt;p&gt;Even if you rebuild it and then unload the solution and then reload the solution and build &lt;em&gt;again&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;It seems like the only way to get it to reliably load the new analyser assembly is to close the Visual Studio instance entirely and start it again.&lt;/p&gt;&#xA;&lt;p&gt;A cryptic note in the &lt;a href=&quot;https://github.com/dotnet/roslyn/issues/18093&quot;&gt;GitHub issue&lt;/a&gt; that I referenced earlier made me wonder if changing the assembly version of the analyser project would help.. but it didn&#x27;t.&lt;/p&gt;&#xA;&lt;p&gt;Now, &lt;em&gt;hopefully,&lt;/em&gt; in real world usage this isn&#x27;t as bad as it sounds. The process of writing analysers lends itself very nicely to a test driven development style because you can set up a test suite where every test is of the format &amp;quot;for code snippet, will I get the analyser messages that I expect?&amp;quot; and you can build up a nice suite of tests for middle-of-the-road cases and edge cases and have them all run quickly. I actually find this to be the easiest way for me to debug things when I get myself into a situation where I don&#x27;t understand why the analyser code isn&#x27;t doing what I expect; I write a test with a snippet of code and then debug the test to step through the code. So you should be to get your analyser working nicely without having to test it against your &amp;quot;MyLibrary&amp;quot; code over and over.&lt;/p&gt;&#xA;&lt;p&gt;Of course, sometimes you&#x27;ll want to run it against your entire code base (otherwise, what was the point of writing it!) and then you &lt;em&gt;will&lt;/em&gt; have to close VS and restart it. And this is inconvenient and I wish that it wasn&#x27;t the case.&lt;/p&gt;&#xA;&lt;p&gt;I think, though, that you would be in the same situation if you decided to go down the NuGet distribution route (whether from a private or public feed) - in the past, I&#x27;ve found that if a new version of a NuGet package includes a new version of an analyser then Visual Studio won&#x27;t load the new version of the analyser without me restarting VS. Which is just as frustrating. Maybe this is part of what&#x27;s delaying the work on Microsoft&#x27;s side; they know that if they make adding analysers easier then they&#x27;ll have to fix the cached-analyser-doesn&#x27;t-get-updated problem at the same time.&lt;/p&gt;&#xA;&lt;h3&gt;To conclude&lt;/h3&gt;&#xA;&lt;p&gt;I&#x27;m going to keep my eye on that GitHub issue. It would be great to see some movement on it but I have no idea how much weight &amp;quot;IDE: InternalPriority&amp;quot; cases have, even if they are listed as Priority 1 within that category.. to be honest, I&#x27;m presuming that Priority 1 means &lt;strong&gt;top priority&lt;/strong&gt; but it&#x27;s just as feasible that it means &lt;em&gt;lowest&lt;/em&gt; priority. There&#x27;s a nice view of the &lt;a href=&quot;https://github.com/dotnet/roslyn/projects/35#card-16650341&quot;&gt;&amp;quot;IDE: Internal Priority&amp;quot; category in GitHub here&lt;/a&gt; in case you want to join in on the guessing game!&lt;/p&gt;&#xA;&lt;p&gt;At the end of the day, though, I still think that this is a powerful technology to have access to and I&#x27;d still rather have it with these caveats than not have it at all. I really believe that analysers provide a way to improve code quality and I encourage everyone to have a play around with them!&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/creating-a-c-sharp-roslyn-analyser-for-beginners-by-a-beginner&quot;&gt;Creating a C# (&amp;quot;Roslyn&amp;quot;) Analyser - For beginners by a beginner&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Wed, 10 Jul 2019 21:42:00 GMT</pubDate>
            </item>
            <item>
                <title>Type aliases in Bridge.NET (C#)</title>
                <link>https://www.productiverage.com/type-aliases-in-bridgenet-c-sharp</link>
                <guid>https://www.productiverage.com/type-aliases-in-bridgenet-c-sharp</guid>
                <description>&lt;p&gt;Back in 2016, I wrote &lt;a href=&quot;https://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-three&quot;&gt;Writing React apps using Bridge.NET - The Dan Way (Part Three)&lt;/a&gt; and I talked about trying to tighten up the representation of values in the type system. One of my pet peeves that I talked about was how &amp;quot;no value&amp;quot; is represented in reference types and, in particular, with strings.&lt;/p&gt;&#xA;&lt;p&gt;As a reminder, I was having a rant about how I hate the uncertainty of wondering &amp;quot;should I expect to get null passed in here / returned from here&amp;quot; and I decided to draw a hard line and say that &lt;strong&gt;no&lt;/strong&gt;, in &lt;em&gt;my&lt;/em&gt; code I would &lt;em&gt;never&lt;/em&gt; expect a reference type to have a null value - instead I would always use the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct that I included in my NuGet package &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt;. This allows me to make it clear when a method may return a null value (because its return type would be something like &lt;strong&gt;Optional&amp;lt;PersonDetails&amp;gt;&lt;/strong&gt;) and it would allow me to make it clear when a method will and won&#x27;t accept null arguments (it &lt;em&gt;will&lt;/em&gt; if the parameter type is &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; and it &lt;em&gt;won&#x27;t&lt;/em&gt; if it&#x27;s &lt;em&gt;not&lt;/em&gt;).&lt;/p&gt;&#xA;&lt;p&gt;Strings, however, have &lt;em&gt;another&lt;/em&gt; &amp;quot;no value&amp;quot; state - when they are blank. If I want to have a method argument whose type indicates &amp;quot;this argument must be a string that is not null AND that is not blank&amp;quot; then we can&#x27;t communicate that. To address that, my blog post introduced &lt;em&gt;another&lt;/em&gt; type; the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class NonBlankTrimmedString&#xA;{&#xA;    public NonBlankTrimmedString(string value)&#xA;    {&#xA;        if (string.IsNullOrWhiteSpace(value))&#xA;            throw new ArgumentException(&amp;quot;Null, blank or whitespace-only value specified&amp;quot;);&#xA;        Value = value.Trim();&#xA;    }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will never be null, blank or have any leading or trailing whitespace&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public string Value { get; }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// It&#x27;s convenient to be able to pass a NonBlankTrimmedString instance as any argument&#xA;    /// that requires a string&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public static implicit operator string(NonBlankTrimmedString value)&#xA;    {&#xA;        if (value == null)&#xA;            throw new ArgumentNullException(&amp;quot;value&amp;quot;);&#xA;        return value.Value;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This would allow me to have a method that clearly indicates that it needs a string &lt;em&gt;with a real value&lt;/em&gt; - eg.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;void DoSomething(NonBlankTrimmedString value);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and it could be combined with &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; to define a method whose type signature indicates that it will take a string with a real value OR it will accept a &amp;quot;no value&amp;quot; - eg.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;void DoSomething(Optional&amp;lt;NonBlankTrimmedString&amp;gt; value);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This method will &lt;em&gt;not&lt;/em&gt; accept a blank string because that&#x27;s just another state that is not necessary; either you give me a real (non-blank) value or you don&#x27;t. There is no half-way house of &amp;quot;non-null but still with no value&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;As another example, I might want to write a &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.React&quot;&gt;Bridge.React&lt;/a&gt; component whose &lt;strong&gt;Props&lt;/strong&gt; type can optionally take an additional class name to render as part of the component - in which case, I might write the class a bit like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public sealed class Props&#xA;{&#xA;    public Props(&#xA;        /* .. other property values, */&#xA;        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())&#xA;    {&#xA;        // .. other properties set here&#xA;        ClassName = className;&#xA;    }&#xA;&#xA;    // .. other public properties exposed here&#xA;&#xA;    public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This is all fine and dandy and, pretty much, it just works. If I want to expand this richer type system so that it&#x27;s used in API requests / responses as well then I can have &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; and &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; types defined in the .NET code that runs on the server as well as in my Bridge project. And if I want to avoid code duplication then I can define the types in a &lt;a href=&quot;https://dev.to/rionmonster/sharing-is-caring-using-shared-projects-in-aspnet-e17&quot;&gt;Shared Project&lt;/a&gt; that is referenced by both the Bridge project and the server API project.&lt;/p&gt;&#xA;&lt;p&gt;One downside to this approach, though, is that JSON payloads from API calls are going to be larger if I wrap all of my strings in &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instances. And there will be more work for &lt;a href=&quot;https://github.com/bridgedotnet/Bridge.Newtonsoft.Json&quot;&gt;Bridge&#x27;s version of Newtonsoft Json.NET&lt;/a&gt; to do because it has to parse more data and it has to deserialise more instances of types; for every string, instead of just deserialising a value into a string, it needs to deserialise that string value &lt;em&gt;and then&lt;/em&gt; create an instance of a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; to wrap it. If you have any API calls that return 100s or 1000s of strings then this can become a non-negligible cost.&lt;/p&gt;&#xA;&lt;p&gt;The full .NET version of Newtonsoft Json.NET has some flexibility with how types are serialised to/from JSON. For example, if I wanted to tell the serialiser that &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instances should appear in the JSON as plain strings then I could do so using a &lt;strong&gt;JsonConverter&lt;/strong&gt; (there is sample code in the Newtonsoft website that demonstrates how to do it for the &lt;strong&gt;Version&lt;/strong&gt; type and the principle would be exactly the same for &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; - see &lt;a href=&quot;https://www.newtonsoft.com/json/help/html/CustomJsonConverterGeneric.htm&quot;&gt;Custom JsonConverter&amp;lt;T&amp;gt;&lt;/a&gt;).&lt;/p&gt;&#xA;&lt;p&gt;The Bridge version of the library has no support for custom JsonConverters, though, so we may appear to be a bit stuck.. if it weren&#x27;t for the fact that Bridge has some low-level tricks that we can use to our advantage.&lt;/p&gt;&#xA;&lt;p&gt;In order to allow C# code to be written that interacts with JavaScript libraries, Bridge has a few escape hatches for the type system that we can use in a careful manner. For example, I could rewrite the Bridge version of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; to look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class NonBlankTrimmedString&#xA;{&#xA;    protected NonBlankTrimmedString() { }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will never be null, blank or have any leading or trailing whitespace&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public extern string Value { [Template(&amp;quot;{this}&amp;quot;)] get; }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// Create a NonBlankTrimmedString instance by explicitly casting a string&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public static explicit operator NonBlankTrimmedString(string value)&#xA;    {&#xA;        if (value == null)&#xA;            return null;&#xA;        value = value.Trim();&#xA;        if (value == &amp;quot;&amp;quot;)&#xA;            throw new ArgumentException(&amp;quot;Can not cast from a blank or whitespace-only string&amp;quot;);&#xA;        return Script.Write&amp;lt;NonBlankTrimmedString&amp;gt;(&amp;quot;value&amp;quot;);&#xA;    }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// It&#x27;s convenient to be able to pass a NonBlankTrimmedString instance as any argument&#xA;    /// that requires a string&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    [Template(&amp;quot;{value}&amp;quot;)]&#xA;    public extern static implicit operator string(NonBlankTrimmedString value);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This changes things up a bit. Now there is no public constructor and the only way to get a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instance from a plain string is to explicitly cast to it - eg.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var x = (NonBlankTrimmedString)&amp;quot;hi!&amp;quot;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;If the source string is blank or whitespace-only then attempting to cast it to a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; will result in an exception being thrown.&lt;/p&gt;&#xA;&lt;p&gt;What&#x27;s interesting about this class is that it exists only to provide type information to the C# compiler - there will never be an instance of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; alive runtime in JavaScript. The reason for this is that the explicit cast performs some validation but then, at runtime, returns the string instance directly back; it &lt;em&gt;doesn&#x27;t&lt;/em&gt; wrap it in an instance of a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; class. Similarly, when the &amp;quot;Value&amp;quot; property is requested in C# code, this is translated into JS as a direct reference to &amp;quot;this&amp;quot; (which we know is a plain string). This is sounding complicated as I write this, so let me try to make it clear with an example!&lt;/p&gt;&#xA;&lt;p&gt;The following C# code:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// Start with a plain string&#xA;var source = &amp;quot;Hi!&amp;quot;;&#xA;&#xA;// Create a NonBlankTrimmed by explicitly casting the string&#xA;var x = (NonBlankTrimmedString)source;&#xA;&#xA;// Write the value of the NonBlankTrimmedString to the console&#xA;Console.WriteLine(x.Value);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. is translated into this JS:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// Start with a plain string&#xA;var source = &amp;quot;Hi!&amp;quot;;&#xA;&#xA;// Create a NonBlankTrimmed by explicitly casting the string&#xA;var x = Demo.NonBlankTrimmedString.op_Explicit(source);&#xA;&#xA;// Write the value of the NonBlankTrimmedString to the console&#xA;System.Console.WriteLine(x);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The reference &amp;quot;x&amp;quot; in the JS runtime is actually just a string (and so the C# &amp;quot;x.Value&amp;quot; is translated into simply &amp;quot;x&amp;quot;) and the explicit operator (the method call &amp;quot;Demo.NonBlankTrimmedString.op_Explicit&amp;quot;) performs some validation but then (if the validation passes) returns the string right back but claims (for the benefit of the C# compiler and type system) that it is now a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;This has a couple of benefits - now, plain string values that appear in JSON can be deserialised into &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instances by Bridge (while the Bridge version of Json.NET doesn&#x27;t support type converters, it &lt;em&gt;does&lt;/em&gt; support deserialising types using implicit or explicit operators - so, here, it would see a string in the JSON and see that the target type was a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; and it would use &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;&#x27;s explicit operator to instantiate the target type), so the JSON returned from the server can be cleaner. &lt;em&gt;And&lt;/em&gt; it means that the JS runtime doesn&#x27;t have to actually create instances of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; to wrap those strings up in, which makes the life of the garbage collector easier (again, may be important if you have API responses that need to return 1000s of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;).&lt;/p&gt;&#xA;&lt;p&gt;This is an interesting concept that I&#x27;m referring to as a &amp;quot;type alias&amp;quot; - a type that exists only for the compiler and that doesn&#x27;t affect the runtime. The phrase &amp;quot;type alias&amp;quot; exists in TypeScript and in F# (and in other languages, I&#x27;m sure) but I think that it means something slightly different there.. which may mean that I&#x27;ve chosen a confusing name for this C# / Bridge.NET concept! In TypeScript and F#, I don&#x27;t believe that they allow the level of compiler validation that I&#x27;m talking about - certainly in TypeScript, type aliases are more of a convenience that allow you say something like:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;type Vector = number[];&#xA;type Vectors = Vector[];&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. so that you can then write a method signature that looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;function process(data: Vectors) {&#xA;    // ..&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. instead of:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;function process(data: number[][]) {&#xA;    // ..&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. but the two are identical. TypeScript &amp;quot;type aliases&amp;quot; make things more flexible, &lt;em&gt;not&lt;/em&gt; more constrained. To make that clearer, if you wrote:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;type CustomerID = number;&#xA;&#xA;function process(id: CustomerID) {&#xA;    // ..&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. then you could still call:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;process(1); // Passing a plain number into a method whose signature specifies type CustomerID&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In other words, the TypeScript alias means &amp;quot;anywhere that you see CustomerID, you can pass in a &#x27;number&#x27;&amp;quot;. This is the opposite of what I want, I want to be able to have methods that specify that they want a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; and &lt;em&gt;not&lt;/em&gt; just any old string.&lt;/p&gt;&#xA;&lt;p&gt;I go into this in a little more detail in the section &amp;quot;Type aliases in other languages&amp;quot; at the end of this blog post. My point here was that maybe &amp;quot;type alias&amp;quot; is not the best phrase to use and maybe I&#x27;ll revisit this in the future.&lt;/p&gt;&#xA;&lt;p&gt;For now, though, let&#x27;s get back to the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; definition that I&#x27;ve proposed because it has some downsides, as well. As the type &lt;em&gt;only&lt;/em&gt; exists at compile time and &lt;em&gt;not&lt;/em&gt; at runtine, if I try to query the type of a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instance at runtime then it will report that it is a &amp;quot;System.String&amp;quot; - this is to be expected, since part of the benefit of this approach is that no additional instances are required other than the plain string itself - but if you were wanted to do some crazy reflection for some reason then it might catch you off guard.&lt;/p&gt;&#xA;&lt;p&gt;Another downside is that if I wanted to create specialised versions of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; then I have to duplicate some code. For example, I might want to &lt;a href=&quot;https://andrewlock.net/using-strongly-typed-entity-ids-to-avoid-primitive-obsession-part-1/&quot;&gt;strongly type&lt;/a&gt; my entity IDs and define them as classes derived from &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;. With the version of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; from my 2016 blog post, this would be as simple as this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// If NonBlankTrimmedString is a regular class then creating derived types is easy as this&#xA;public class OrderID : NonBlankTrimmedString&#xA;{&#xA;    public OrderID(string value) : base(value) { }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. but with this &amp;quot;type alias&amp;quot; approach, it becomes more verbose -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// The explicit operator needs to be reimplemented for each derived type with the type alias&#xA;// alias approach shown earlier :(&#xA;public class ClassName : NonBlankTrimmedString&#xA;{&#xA;    protected ClassName() { }&#xA;&#xA;    public static explicit operator ClassName(string value)&#xA;    {&#xA;        if (value == null)&#xA;            return null;&#xA;        value = value.Trim();&#xA;        if (value == &amp;quot;&amp;quot;)&#xA;            throw new ArgumentException(&amp;quot;Can not cast from a blank or whitespace-only string&amp;quot;);&#xA;        return Script.Write&amp;lt;ClassName&amp;gt;(&amp;quot;value&amp;quot;);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;However, we could make this a little simpler by changing the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; type definition to this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class NonBlankTrimmedString&#xA;{&#xA;    protected NonBlankTrimmedString() { }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// This will never be null, blank or have any leading or trailing whitespace&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public extern string Value { [Template(&amp;quot;{this}&amp;quot;)] get; }&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// Create a NonBlankTrimmedString instance by explicitly casting a string&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public static explicit operator NonBlankTrimmedString(string value)&#xA;        =&amp;gt; Wrap&amp;lt;NonBlankTrimmedString&amp;gt;(value);&#xA;&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// It&#x27;s convenient to be able to pass a NonBlankTrimmedString instance as any argument&#xA;    /// that requires a string&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    [Template(&amp;quot;{value}&amp;quot;)]&#xA;    public extern static implicit operator string(NonBlankTrimmedString value);&#xA;&#xA;    protected static T Wrap&amp;lt;T&amp;gt;(string value) where T : NonBlankTrimmedString&#xA;    {&#xA;        if (value == null)&#xA;            return null;&#xA;        value = value.Trim();&#xA;        if (value == &amp;quot;&amp;quot;)&#xA;            throw new ArgumentException(&amp;quot;Can not cast from a blank or whitespace-only string&amp;quot;);&#xA;        return Script.Write&amp;lt;T&amp;gt;(&amp;quot;value&amp;quot;);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and then derived types would look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class OrderID : NonBlankTrimmedString&#xA;{&#xA;    protected OrderID() { }&#xA;    public static explicit operator OrderID(string value) =&amp;gt; Wrap&amp;lt;OrderID&amp;gt;(value);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;(Sort-of-)immutability for &amp;quot;free&amp;quot; through type aliases&lt;/h3&gt;&#xA;&lt;p&gt;Another use case where this sort of approach seemed interesting was when I was writing some client-side code that received data in the form of arrays and then did some clever calculations and drew some pretty graphs. The API response data was 10s of 1000s of arrays, where each array was 100 floating point numbers. The calculation logic took those arrays and passed them through a bunch of methods to come up with the results but I got myself in a bit of a muddle when there were one or two places that had to manipulate a subset of the data and I realised that I was confusing myself as to whether the data should be altered in place or whether local copies of those parts of the data should be taken and then changed. To make the code easier to follow, I wanted those methods to take local copies to make the changes, rather than mutating them in-place and risking messing up calculations performed on the data later in the pipeline.&lt;/p&gt;&#xA;&lt;p&gt;What I really wanted was for those methods to have type signatures that would either take an immutable data type or a readonly data type. Immutable is the ideal because it means that not only can the receiving methods not change the data but &lt;em&gt;nothing&lt;/em&gt; can change the data. Having readonly types on the method signatures means that the methods can&#x27;t change the data but it&#x27;s still technically possible for the caller to change the data. To try to illustrate this, I&#x27;ll use the &lt;strong&gt;ReadOnlyCollection&amp;lt;T&amp;gt;&lt;/strong&gt; type from .NET in an example:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public static void Main()&#xA;{&#xA;    var items = new List&amp;lt;int&amp;gt; { 0, 1, 2, 3 };&#xA;    var readOnlyItems = items.AsReadOnly();&#xA;    DoSomething(&#xA;        readOnlyItems,&#xA;        halfwayPointCallback: () =&amp;gt; items.RemoveAt(0)&#xA;    );&#xA;}&#xA;&#xA;static void DoSomething(ReadOnlyCollection&amp;lt;int&amp;gt; readOnlyItems, Action halfwayPointCallback)&#xA;{&#xA;    Console.WriteLine(&amp;quot;Number of readonlyItems: &amp;quot; &#x2B; readOnlyItems.Count);&#xA;    halfwayPointCallback();&#xA;    Console.WriteLine(&amp;quot;Number of readonlyItems: &amp;quot; &#x2B; readOnlyItems.Count);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Here, the &amp;quot;Main&amp;quot; method declares a mutable list and then it create a readonly wrapper around it. The readonly wrapper is passed into the &amp;quot;DoSomething&amp;quot; method and this means &amp;quot;DoSomething&amp;quot; can &lt;em&gt;not&lt;/em&gt; directly alter that list. However, it&#x27;s still possible for the &amp;quot;Main&amp;quot; method to change the underlying list while &amp;quot;DoSomething&amp;quot; is running.&lt;/p&gt;&#xA;&lt;p&gt;In practice, this is not something that I find commonly happens. As such, while I would &lt;em&gt;prefer&lt;/em&gt; immutable structures at all times (because then &amp;quot;Main&amp;quot; &lt;em&gt;couldn&#x27;t&lt;/em&gt; change the contents of the list while &amp;quot;DoSomething&amp;quot; is working on it), being able to wrap the data in a readonly structure is still a significant improvement.&lt;/p&gt;&#xA;&lt;p&gt;So, some of the more obvious options available to me were:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Stick with using arrays and be careful not to write code that performs any alteration &amp;quot;in place&amp;quot; (&lt;strong&gt;I don&#x27;t like this situation - C#&#x27;s type system has great potential and I want it to help me and save me from myself where possible!&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Pass the arrays into the methods as &lt;strong&gt;IEnumerable&amp;lt;float&amp;gt;&lt;/strong&gt; (&lt;strong&gt;this isn&#x27;t a terrible idea in general - it quite clearly communicates that the provided data should be considered read only - but the calculations that I was doing wanted to get the length of the array and to read particular indexed values from the array in unpredictable orders and this isn&#x27;t very efficient with enumerable types&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Create an &amp;quot;immutable list&amp;quot; class that takes an array into the constructor, copies the data and then allows access to the copy only through tightly-controlled members; ie. Length and an indexed property (&lt;strong&gt;This is the most type-safe way but it felt expensive doing this for the 10s of 1000s of arrays that I had&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Convert each array into a &lt;strong&gt;List&amp;lt;float&amp;gt;&lt;/strong&gt; and then call &amp;quot;.AsReadOnly()&amp;quot; on them (&lt;strong&gt;this is very little code but it also felt expensive with the amount of data that I had&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Create a &amp;quot;ReadOnlyArray&amp;lt;T&amp;gt;&amp;quot; type that would be very similar in nature to the &lt;strong&gt;ReadOnlyCollection&amp;lt;T&amp;gt;&lt;/strong&gt; in that it would take an array into its constructor and then provide a read only interface for it, &lt;em&gt;without&lt;/em&gt; copying the array (&lt;strong&gt;This is a reasonable option and I might have gone this way were it not for liking the idea of option six&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Create a &amp;quot;ReadOnlyArray&amp;lt;T&amp;gt;&amp;quot; type &lt;em&gt;alias&lt;/em&gt; that I could use to instruct the type system that the data should not be altered but without having to introduce &lt;em&gt;any&lt;/em&gt; new types or instances at runtime&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;I went with the last one because I was all excited about experimenting with &amp;quot;Bridge.NET type aliases&amp;quot; and I wanted to see how well they could work! (In reality, the fifth option was also a good one and some of the others would also be perfectly fine for smaller data sets.. to be honest, there is a chance that they wouldn&#x27;t have made &lt;em&gt;too&lt;/em&gt; much difference even with the data that I was looking at but, again, sometimes you need to make opportunity to experiment! :)&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public sealed class ReadOnlyArray&amp;lt;T&amp;gt; : IEnumerable&amp;lt;T&amp;gt;&#xA;{&#xA;    [Template(&amp;quot;{data}&amp;quot;)]&#xA;    public extern ReadOnlyArray(T[] data);&#xA;&#xA;    [External] // Required due to https://github.com/bridgedotnet/Bridge/issues/4015&#xA;    public extern T this[int index] { [Template(&amp;quot;{this}[{index}]&amp;quot;)] get; }&#xA;&#xA;    public extern int Length { [Template(&amp;quot;length&amp;quot;)] get; }&#xA;&#xA;    [External]&#xA;    public extern IEnumerator&amp;lt;T&amp;gt; GetEnumerator();&#xA;&#xA;    [External]&#xA;    extern IEnumerator IEnumerable.GetEnumerator();&#xA;&#xA;    [Template(&amp;quot;{value}&amp;quot;)]&#xA;    public extern static implicit operator ReadOnlyArray&amp;lt;T&amp;gt;(T[] value);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The structure of this class is similar in some ways to that of the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;. Unlike that class, there is no validation that is required - I &lt;em&gt;only&lt;/em&gt; want to provide access to an array in a limited manner and so it&#x27;s fine to expose a public constructor (as opposed to the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;, where it&#x27;s important to check that the value is neither null nor blank nor whitespace-only and the [Template] attribute on the constructor doesn&#x27;t easily allow for any validation).&lt;/p&gt;&#xA;&lt;p&gt;Even though the constructor may be used on this class, there is still an operator to change an array into a &lt;strong&gt;ReadOnlyArray&lt;/strong&gt; so that the deserialisation process is able to read an array of items into a &lt;strong&gt;ReadOnlyArray&lt;/strong&gt; instance. I&#x27;ve chosen to use an implicit operator (rather than en explicit operator) here because there is no validation to perform - the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; has an explicit operator because that&lt;em&gt;does&lt;/em&gt; perform some validation and so it&#x27;s a casting action that could fail and so I want it to be explicit in code.&lt;/p&gt;&#xA;&lt;p&gt;As with the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;, this type will exist only at compile time and the compiled JavaScript will always be operating directly against the original array. As far as the JS code is aware, there &lt;em&gt;is no&lt;/em&gt; wrapper class involved at all. The following C# -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var values = new[] { 1, 2, 3 };&#xA;Console.WriteLine(values.Length);&#xA;&#xA;var readOnlyValuesCtor = new ReadOnlyArray&amp;lt;int&amp;gt;(values);&#xA;Console.WriteLine(readOnlyValuesCtor.Length);&#xA;&#xA;ReadOnlyArray&amp;lt;int&amp;gt; readOnlyValuesCast = values;&#xA;Console.WriteLine(readOnlyValuesCast.Length);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. is translated into this JS:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var values = System.Array.init([1, 2, 3], System.Int32);&#xA;System.Console.WriteLine(values.length);&#xA;&#xA;var readOnlyValuesCtor = values;&#xA;System.Console.WriteLine(readOnlyValuesCtor.length);&#xA;&#xA;var readOnlyValuesCast = values;&#xA;System.Console.WriteLine(readOnlyValuesCast.length);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Whether the &lt;strong&gt;ReadOnlyArray&amp;lt;int&amp;gt;&lt;/strong&gt; is created by calling its constructor or by an implicit cast in the C# code, the JS is unaware of any change required of the reference and continues to operate on the original array. This is the &amp;quot;free&amp;quot; part of this approach - there is no runtime cost in terms of type conversions or additional references.&lt;/p&gt;&#xA;&lt;p&gt;The other members of the class need a little more explanation, though. The indexer &lt;em&gt;should&lt;/em&gt; be implemented just like the &amp;quot;Length&amp;quot; property, by having an extern property that has a getter with a [Template] attribute on it. However, there is a bug in the Bridge compiler that necessitate an additional [External] attribute be added to the property. Not the end of the world and I&#x27;m sure that the Bridge Team will fix it in a future version of the compiler.&lt;/p&gt;&#xA;&lt;p&gt;The &amp;quot;GetEnumerator&amp;quot; methods require a tiny bit more explanation. In order for the class to implement &lt;strong&gt;IEnumerable&amp;lt;T&amp;gt;&lt;/strong&gt;, these methods must be present. But we don&#x27;t actually have to implement them ourselves. Whenever Bridge encouters a &amp;quot;foreach&amp;quot; in the source C# code, it translates it into JS that calls &amp;quot;GetEnumerator&amp;quot; and then steps through each value. For example, this C# code:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;foreach (var value in readOnlyValuesCtor)&#xA;    Console.WriteLine(value);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. becomes this JS:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$t = Bridge.getEnumerator(readOnlyValuesCtor);&#xA;try {&#xA;    while ($t.moveNext()) {&#xA;        var value = $t.Current;&#xA;        System.Console.WriteLine(value);&#xA;    }&#xA;} finally {&#xA;    if (Bridge.is($t, System.IDisposable)) {&#xA;        $t.System$IDisposable$Dispose();&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Because Bridge needs to support enumerating over arrays, the function &amp;quot;Bridge.getEnumerator&amp;quot; knows what to do if it is given an array reference. And since a &lt;strong&gt;ReadOnlyArray&lt;/strong&gt; &lt;em&gt;is&lt;/em&gt; an array reference at runtime, we don&#x27;t have to do anything special - we don&#x27;t have to provide a GetEnumerator implementation.&lt;/p&gt;&#xA;&lt;p&gt;And there we go! As I explained above, I originally encountered this problem when passing an array into a complicated calculation process but this type could &lt;em&gt;also&lt;/em&gt; be used for deserialising JSON into a richer type model, just like the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; earlier - again, without any overhead in doing so (no instances of wrapper types will be present runtime and there will be no additional references for the garbage collector to track).&lt;/p&gt;&#xA;&lt;h3&gt;&lt;em&gt;Only&lt;/em&gt; possible in Bridge.NET?&lt;/h3&gt;&#xA;&lt;p&gt;I was wracking my brains about whether it would be possible to do something similar with C# running in a .NET environment and I couldn&#x27;t think of anything. People sometimes think &lt;em&gt;&amp;quot;structs!&amp;quot;&lt;/em&gt; when trying to concoct ways to avoid adding references that the garbage collector needs to track but structs are only immune to this if they don&#x27;t contain any object references within their fields and properties (and there are other edge cases besides this but they&#x27;re not important right now).&lt;/p&gt;&#xA;&lt;p&gt;At the end of the day, this &amp;quot;type alias&amp;quot; concept might be a bit of a niche technique and it &lt;em&gt;might&lt;/em&gt; even be a case of me playing around, more than it being something that you might use in production.. but I thought that it was interesting nonetheless. And it has made me wish, again, that C# had support for something like this - I&#x27;ve written code before that defines all variety of strongly typed IDs (strings) and Keys (integers) to avoid passing the wrong type of value into the wrong place but it&#x27;s always felt cumbersome (it&#x27;s felt worth the effort but that didn&#x27;t stop wishing me that it was &lt;em&gt;less&lt;/em&gt; effort).&lt;/p&gt;&#xA;&lt;h3&gt;Type aliases in other languages&lt;/h3&gt;&#xA;&lt;p&gt;I&#x27;ve linked above to an article &lt;a href=&quot;https://andrewlock.net/using-strongly-typed-entity-ids-to-avoid-primitive-obsession-part-1/&quot;&gt;Using strongly-typed entity IDs to avoid primitive obsession&lt;/a&gt;, which is excellent and eloquently expresses some of my thoughts, but I thought that I&#x27;d add a summary in here as well (which also gives me an opportunity to go into more detail about the options in TypeScript and F#).&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;ll start with an anecdote to set the scene. In a company that I used to work at, we had systems that would retrieve and render different data for different language options. Sometimes data would vary only by language (&amp;quot;English&amp;quot;, &amp;quot;French&amp;quot;, etc..) but sometimes it would be more specific and vary by language &lt;em&gt;culture&lt;/em&gt; (eg. &amp;quot;English - United Kingdom&amp;quot;, &amp;quot;English - United States&amp;quot;, etc..). An older version of the system would pass around int values for the language or language culture keys. So there might be a method such as:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private string GetTranslatedName(int languageKey)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;A problem that occurred over and over again is that language keys and language culture keys would get mixed up in the code base - in other words, it was quite common for someone to accidentally pass a language key into a method where a language &lt;em&gt;culture&lt;/em&gt; key was expected (this situation was not helped by the fact that much of the developer testing was done in English and the language key and language culture key values in many of the databases were both 1 for English / English UK). Something that I was very keen to get into a new version of the system was to introduce &amp;quot;strongly typed keys&amp;quot; so that this sort of accident could no longer occur. The method&#x27;s signature would be changed to something like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private string GetTranslatedName(LanguageKey languageKey)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and we would not describe language or language culture keys as ints in the code base. They would always be either an instance of &lt;strong&gt;LanguageKey&lt;/strong&gt; or &lt;strong&gt;LanguageCultureKey&lt;/strong&gt; - this way, if you attempted to pass a key of the wrong type into a method then you would get a compile error.&lt;/p&gt;&#xA;&lt;p&gt;The downside is that each key type had to be defined as its own struct, with the following (quite verbose) structure:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public struct LanguageKey : IEquatable&amp;lt;LanguageKey&amp;gt;&#xA;{&#xA;    public LanguageKey(int value) =&amp;gt; Value = value;&#xA;&#xA;    public int Value { get; }&#xA;&#xA;    public bool Equals(LanguageKey other) =&amp;gt; Value.Equals(other.Value);&#xA;    public override bool Equals(object obj) =&amp;gt; (obj is LanguageKey key) &amp;amp;&amp;amp; (key.Value == Value);&#xA;    public override int GetHashCode() =&amp;gt; Value;&#xA;&#xA;    public static bool operator ==(LanguageKey x, LanguageKey y) =&amp;gt; x.Value == y.Value;&#xA;    public static bool operator !=(LanguageKey x, LanguageKey y) =&amp;gt; !(x == y);&#xA;&#xA;    public static explicit operator LanguageKey(int value) =&amp;gt; new LanguageKey(value);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Really, though, that is the &lt;em&gt;only&lt;/em&gt; downside. As the strongly typed keys are structs without any reference properties or fields, there is no additional work for the garbage collector and there is no memory overhead vs tracking a simple int. But it &lt;em&gt;does&lt;/em&gt; still feel a little arduous to have to have these definitions in the code base, particularly when the equivalent F# code looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;[&amp;lt;Struct&amp;gt;] type LanguageKey = LanguageKey of int&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;It&#x27;s worth noting that this is not actually referred to as a &amp;quot;type alias&amp;quot; in F#; this is a &amp;quot;single case union type&amp;quot;. There &lt;em&gt;is&lt;/em&gt; a concept called a &amp;quot;type alias&amp;quot; in F# that looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;type LanguageKey = int&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. but that code simply says &amp;quot;allow me to use the word &#x27;LanguageKey&#x27; anywhere in place of int&amp;quot; - eg. if I have the LanguageKey type alias specified as a method argument type in F# method, like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;let getTranslatedName (language: LanguageKey) =&#xA;    // (Real work to retrieve translated name would go here but we&#x27;ll&#xA;    //  just return the string &amp;quot;Whatever&amp;quot; for the sake of this example)&#xA;    &amp;quot;Whatever&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. then the compiler would allow me to pass an int into that method -&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// A LanguageKey type alias lets me pass any old int into the method - rubbish!&#xA;let name = getTranslatedName 123&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and that&#x27;s exactly what I wanted to avoid!&lt;/p&gt;&#xA;&lt;p&gt;On the other hand, if the type &lt;strong&gt;LanguageKey&lt;/strong&gt; was a &amp;quot;single case union type&amp;quot; then the code above would not compile:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// error FS0001: This expression was expected to have type &#x27;LanguageKey&#x27; but here has type &#x27;int&#x27;&#xA;let name = getTranslatedName 123&#xA;&#xA;// This DOES compile because the types match&#xA;let key = LanguageKey 123&#xA;let name = getTranslatedName 123&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. and that&#x27;s exactly what I &lt;em&gt;did&lt;/em&gt; want!&lt;/p&gt;&#xA;&lt;p&gt;(TypeScript&#x27;s type aliases are like F#&#x27;s type aliases - they are more of a convenience and do not add the sort of type checking that I want)&lt;/p&gt;&#xA;&lt;p&gt;Things get a bit more awkward if we want to deal with reference types, such as strings, becase we could create a C# class similar to &lt;strong&gt;LanguageKey&lt;/strong&gt; (or we could create an F# single case union type) but that would introduce a new instance of a type that must be tracked by the garbage collector - every strongly typed ID involves &lt;em&gt;two&lt;/em&gt; references; the underlying string value and the strongly typed wrapper. Much of the time, that&#x27;s no problem - I&#x27;ve had the odd issue with the .NET GC in the past but, on the whole, it&#x27;s an amazing and reliable tool.. but because I &lt;em&gt;have&lt;/em&gt; had these problems before, it makes me more aware of the trade-off when I introduce wrappers like this.&lt;/p&gt;&#xA;&lt;p&gt;I&#x27;m convinced that using strongly typed IDs is the right thing to do in 99% of cases because it improves code quality and can eradicate a class of real-world mistake. But the concept became even more interesting to me as it appeared possible to introduce a form of type alias into Bridge.NET code that enables those compile time checks but with zero runtime cost. Granted, the type erasure that occurs means that &lt;em&gt;runtime&lt;/em&gt; type checking is not possible (the Bridge code can not differentiate between a &lt;strong&gt;string&lt;/strong&gt; or a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; or a type that is &lt;em&gt;derived&lt;/em&gt; from &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;) but the main driver for me was to improve compile time checking and so that wasn&#x27;t a problem for me. Maybe it would be a problem in other scenarios, in which case these Bridge.NET &amp;quot;type aliases&amp;quot; might not be appropriate.&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/stronglytyped-react-with-bridgenet&quot;&gt;Strongly-typed React (with Bridge.net)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/a-followup-to-implementing-f-sharp-inspired-with-updates-in-c-sharp&quot;&gt;A follow-up to &amp;quot;Implementing F#-inspired &amp;#x27;with&amp;#x27; updates in C#&amp;quot;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/implementing-f-sharp-inspired-with-updates-for-immutable-classes-in-c-sharp&quot;&gt;Implementing F#-inspired &amp;quot;with&amp;quot; updates for immutable classes in C#&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Tue, 02 Jul 2019 21:59:00 GMT</pubDate>
            </item>
            <item>
                <title>I didn&#x27;t understand why people struggled with (.NET&#x27;s) async</title>
                <link>https://www.productiverage.com/i-didnt-understand-why-people-struggled-with-nets-async</link>
                <guid>https://www.productiverage.com/i-didnt-understand-why-people-struggled-with-nets-async</guid>
                <description>&lt;p&gt;Long story short (I know that some readers love a TL;DR), I have almost always worked with async/await in C# projects where it&#x27;s been async from top-to-bottom and so I&#x27;ve rarely tried to start integrating async code into a large project that is primarily &lt;em&gt;non&lt;/em&gt;-async. Due to this, I have never encountered any async problems.. so I&#x27;ve occasionally wondered &amp;quot;why would people be worried about getting deadlocks?&amp;quot;&lt;/p&gt;&#xA;&lt;p&gt;Recently, this changed and I wanted to start integrating components that use async methods into a big project that doesn&#x27;t. And it didn&#x27;t take long until I got a hanging application!&lt;/p&gt;&#xA;&lt;p&gt;Before I get to my story (and my solution), let me quickly recap what all the fuss is about.&lt;/p&gt;&#xA;&lt;h3&gt;What is &amp;quot;async&amp;quot; and why is it good?&lt;/h3&gt;&#xA;&lt;p&gt;To put things into context, I&#x27;m talking about a web application - code that hosts a website and spend 99% of its day &amp;quot;read only&amp;quot; and just rendering pages for people.&lt;/p&gt;&#xA;&lt;p&gt;These do not tend to be computationally-intensive applications and if a page is slow to render then it&#x27;s probably because the code is waiting for something.. like a database call to complete or an external cache request or the loading of a file.&lt;/p&gt;&#xA;&lt;p&gt;Within IIS, when an ASP.NET application is hosted and is responding to requests, the simple model for synchronous code is that each request is allocated a thread to work on and it will keep hold of that thread for the duration of the request. A thread is an operating system construct and it occupies some resources - in other words, they&#x27;re not free and, given the the choice, we would like to need less of them rather than more of them. The threads in .NET are an abstraction over OS threads but to avoid getting too far off course, we&#x27;ll think of them as being equivalent because they&#x27;re close enough for the purposes of this post.&lt;/p&gt;&#xA;&lt;p&gt;This model is very easy to understand but it&#x27;s also easy to see how it could be quite wasteful. If the majority of our web server requests spend much of their time waiting for something external (database, other network I/O, local file system, etc..) then do we really need to tie up a thread for that time? Couldn&#x27;t we free it up for another request (that &lt;em&gt;isn&#x27;t&lt;/em&gt; waiting for something external) to use and then try to get it back when whatever we&#x27;re waiting on has finished doing its thing?&lt;/p&gt;&#xA;&lt;p&gt;This is essentially what async / await is trying to solve. It introduces a simple way for us to write code that can say &amp;quot;I&#x27;m doing something that will perform an asynchronous action now - I&#x27;m expecting to wait for a little bit and so you (the .NET hosting environment) can have my thread back for a little while&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;(Before async / await, it was possible to do this but it was much more convoluted and you had to deal with code that might follow a tangled web of callbacks and you would have to manually pass around any references that you would want to access in those callbacks - it was possible to do but made for code that was harder to read and write and, thusly, was more likely to contain mistakes)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;When the .NET environment deals with &amp;quot;await&amp;quot;, the thread that the await call happened on will be free&#x27;d back up. Then, when the async work is completed, a thread will be given back to that request so that it can carry on doing its thing. You might be wondering &amp;quot;how does .NET &lt;em&gt;know&lt;/em&gt; when the work has completed? Surely that requires another thread to monitor whether the external resource has responded and, if so, aren&#x27;t we right back where we started because we&#x27;re blocking threads?&amp;quot; This is what I thought when I was first learning about async / await (and so I happen to think that it&#x27;s an entirely reasonable question!) but it&#x27;s not the case. The operating system and its drivers expose ways to say (and I&#x27;m grossly simplifying again because it&#x27;s only the gist that we need here, not the full nitty gritty) &amp;quot;start sending this network data and notify me when data starts coming back in response&amp;quot; (and similar mechanisms for other types of I/O). When that notification occurs, the .NET environment can provide a thread to the request that was awaiting and let it carry on.&lt;/p&gt;&#xA;&lt;p&gt;To try to illustrate this, imagine that the below image represents a web request. The blue parts are when computational work is being done on the thread and the white parts are when it&#x27;s waiting on an external resource (like a database) -&lt;/p&gt;&#xA;&lt;img alt=&quot;Illustration of a web request with delays for external data shown&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/Threads-SingleExample.png&quot; class=&quot;NoBorder FullWidth&quot;&gt;&#xA;&lt;p&gt;At a glance, it&#x27;s clear that there will be a lot of wasted time that a thread spends doing nothing (in a blocked state) if we&#x27;re using the old model of &amp;quot;one thread for the entirety of the request&amp;quot;. What might be slightly less easy to envisage, though, is &lt;em&gt;just how many&lt;/em&gt; unnecessary threads that we might be occupying at any given time if all requests are like this.&lt;/p&gt;&#xA;&lt;p&gt;To try to illustrate that, I&#x27;ve stacked eight identical web requests representations on top of each other, staggered slightly in time -&lt;/p&gt;&#xA;&lt;img alt=&quot;Illustration of a staggered concurrent web requests&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/Threads-Stacked.png&quot; class=&quot;NoBorder FullWidth&quot;&gt;&#xA;&lt;p&gt;Again, the blue represents time when each request is actively doing work and the white represents time when it&#x27;s waiting for something (grey before a request is time before that request arrived at the server and grey after a request is time after it completed).&lt;/p&gt;&#xA;&lt;p&gt;With the classic &amp;quot;one thread for the entirety of the request&amp;quot;, we would be using up to eight threads for much of this time; initially only one thread would be active and then the second request would arrive and a second thread would get tied up and then a third thread would be used when the third request arrived and the threads wouldn&#x27;t start getting free&#x27;d until the first request completed.&lt;/p&gt;&#xA;&lt;p&gt;On the other hand, if we could free up a request&#x27;s thread every time that it was waiting for an external resource then we would &lt;em&gt;never&lt;/em&gt; require eight threads at any one time for these eight requests because there is no point in time when all eight of the requests are actively doing work at the exact same time.&lt;/p&gt;&#xA;&lt;p&gt;Time for a graph!&lt;/p&gt;&#xA;&lt;img alt=&quot;Threads required for async vs non-async concurrent web requests&quot; src=&quot;https://www.productiverage.com/Content/Images/Posts/Threads-Graph.png&quot; class=&quot;NoBorder FullWidth&quot;&gt;&#xA;&lt;p&gt;The blue line shows the number of active requests. If we have one-thread-per-request then that blue line also shows how many threads would be required to handle those requests.&lt;/p&gt;&#xA;&lt;p&gt;The green line shows how many requests are actually doing work at any one time. If we are able to use the async / await model and only have web requests occupy threads while they&#x27;re actively doing work then this is how many threads would be required. It&#x27;s always less than the number of active requests and it&#x27;s less than &lt;em&gt;half&lt;/em&gt; for nearly all of the time in this example.&lt;/p&gt;&#xA;&lt;p&gt;The async / await model means that we need to use less threads and that&#x27;s less resources and that&#x27;s a good thing!&lt;/p&gt;&#xA;&lt;h3&gt;A lightning overview of thread distribution&lt;/h3&gt;&#xA;&lt;p&gt;There was a lot of talk above of how &amp;quot;each request is allocated a thread to work&amp;quot; and &amp;quot;a thread will be given back to that request&amp;quot; and it&#x27;s worth quickly reviewing how threads are created.&lt;/p&gt;&#xA;&lt;p&gt;A thread in C# &lt;em&gt;can&lt;/em&gt; be created using:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;var thread = new Thread(nameOfMethodThatHasWorkToDoOnTheNewThread);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;However, threads are a relatively expensive resource to new up and then discard over and over again and so .NET offers a way to &amp;quot;pool&amp;quot; threads. What this boils down to is that the &lt;strong&gt;ThreadPool&lt;/strong&gt; framework class will maintain a list of threads and reuse them when someone needs one. This is used internally in many places within the .NET framework and it may be used like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ThreadPool.QueueUserWorkItem(nameOfMethodThatHasWorkToDoOnTheNewThread);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The &lt;strong&gt;ThreadPool&lt;/strong&gt; will keep track of how many threads would need to exist at any given time to service all &amp;quot;QueueUserWorkItem&amp;quot; requests and it will track this over time so it can try to keep its pool at the optimium size for the application - too many means a waste of resources but too few means that it will take longer before the work requested via &amp;quot;QueueUserWorkItem&amp;quot; calls can be executed (if there is no thread free when a &amp;quot;QueueUserWorkItem&amp;quot; is made then that work will still happen but it will be queued up until the &lt;strong&gt;ThreadPool&lt;/strong&gt; has a thread become free).&lt;/p&gt;&#xA;&lt;p&gt;It would make for a fairly simple mental model if async / await always used the &lt;strong&gt;ThreadPool&lt;/strong&gt; - if, when a request made an &amp;quot;await&amp;quot; call then it gave its current thread back to the &lt;strong&gt;ThreadPool&lt;/strong&gt; and then, when the async work was completed, the request could continue on a thread provided by the &lt;strong&gt;ThreadPool&lt;/strong&gt;. This would be straight forward and easy to understand and sometimes it &lt;em&gt;is&lt;/em&gt; the case - Console Applications and Windows Services will work like this with async / await, for example. We can picture it a bit like this:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A Windows Service receives a request and is given Thread &amp;quot;A&amp;quot; from the &lt;strong&gt;ThreadPool&lt;/strong&gt; to start working on&lt;/li&gt;&#xA;&lt;li&gt;At some point, the request needs to perform an asynchronous action and so there is an &amp;quot;await&amp;quot; in the code - when this happens, Thread &amp;quot;A&amp;quot; is released back to the &lt;strong&gt;ThreadPool&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;When that async task has completed, the request can carry on - however, Thread &amp;quot;A&amp;quot; was given to a &lt;em&gt;different&lt;/em&gt; request while this request was waiting for the async work and so the &lt;strong&gt;ThreadPool&lt;/strong&gt; gives it Thread &amp;quot;B&amp;quot;&lt;/li&gt;&#xA;&lt;li&gt;The request does some more synchronous work on Thread &amp;quot;B&amp;quot; and finishes, so Thread &amp;quot;B&amp;quot; is released back to the &lt;strong&gt;ThreadPool&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Easy peasy.&lt;/p&gt;&#xA;&lt;h3&gt;Thread distribution troublemakers&lt;/h3&gt;&#xA;&lt;p&gt;However.. some project types get a bit possessive about their threads - when a request starts on one thread then it wants to be able to continue to use that thread forever. I suspect that this is most commonly known about WinForms projects where it was common to see code that looked like the following (that I have borrowed from a &lt;a href=&quot;https://stackoverflow.com/a/661686/3813189&quot;&gt;Stack Overflow answer&lt;/a&gt;):&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private void OnWorkerProgressChanged(object sender, ProgressChangedArgs e)&#xA;{&#xA;    // Cross thread - so you don&#x27;t get the cross-threading exception&#xA;    if (this.InvokeRequired)&#xA;    {&#xA;        this.BeginInvoke((MethodInvoker)delegate&#xA;        {&#xA;            OnWorkerProgressChanged(sender, e);&#xA;        });&#xA;        return;&#xA;    }&#xA;&#xA;    // Change control&#xA;    this.label1.Text = e.Progress;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;With WinForms, you must never block the main thread because then your whole application window will go into a &amp;quot;not responding&amp;quot; state. So, if you wanted to start a process that is unlikely to complete instantly - such as a file upload - then you might have a component that performs the work on a different thread and that has events for &amp;quot;progress changed&amp;quot; (so that it can report {x}% complete) and &amp;quot;upload completed&amp;quot;. When these events are raised, we&#x27;ll want to update the UI of the application but there is a problem: when these callbacks are executed, they will be run on the thread that the file upload is running on and not the main UI thread. The reason that this is a problem is that UI components may &lt;em&gt;only&lt;/em&gt; be updated by code that is running on the UI thread. The way around this is to check the &amp;quot;InvokeRequired&amp;quot; property on a UI component before trying to update any of the component&#x27;s properties. If &amp;quot;InvokeRequired&amp;quot; returns false then it meant that the current thread is the UI thread and that no funny business was required. However, if it returns true then it means that the current thread is &lt;em&gt;not&lt;/em&gt; the UI thread and that a special method &amp;quot;BeginInvoke&amp;quot; would have to be called, which was a way to say &amp;quot;please execute this code on the UI thread&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;Eventually, people got used to this and would ensure that they used &amp;quot;InvokeRequired&amp;quot; and  &amp;quot;BeginInvoke&amp;quot; when updating UI elements if they were dealing with code that might do some &amp;quot;background processing&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;When async / await were introduced, though, one of the aims was to make it easy and neat and tidy to write async code - basically, to be able to write code that &lt;em&gt;looked&lt;/em&gt; synchronous while still getting the benefits of being &lt;em&gt;asynchronous&lt;/em&gt;. That meant trying to avoid code that looked like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private async void btnUpload_Click(object sender, EventArgs e)&#xA;{&#xA;    var filename = await UploadContent();&#xA;&#xA;    // Why do I need to do this?! I haven&#x27;t (explicitly) fired&#xA;    // up any new threads or anything! :S&#xA;    if (this.InvokeRequired)&#xA;    {&#xA;        this.BeginInvoke((MethodInvoker)delegate&#xA;        {&#xA;            this.lblFilename.Text = filename;&#xA;        });&#xA;        return;&#xA;    }&#xA;    this.lblFilename.Text = filename;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Instead, it should just look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;private async void btnUpload_Click(object sender, EventArgs e)&#xA;{&#xA;    var filename = await UploadContent();&#xA;    this.lblFilename.Text = filename;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The problem with this is that some magic will be required somewhere. If the &lt;strong&gt;ThreadPool&lt;/strong&gt; is responsible for providing a thread to execute on after async work has completed, things are going to go wrong if it provides one thread to start the request on and a different thread to continue on after the async work has completed. It was fine for the Windows Service example request above to start on Thread &amp;quot;A&amp;quot; and then change to working on Thread &amp;quot;B&amp;quot; because Windows Services don&#x27;t have limitations on what threads can and can&#x27;t do, whereas WinForms UI components &lt;em&gt;do&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The &amp;quot;magic&amp;quot; involved is that .NET provides a way for threads to be assigned a special &amp;quot;Synchronization Context&amp;quot;. This is a mechanism that changes how async / await interacts with the &lt;strong&gt;ThreadPool&lt;/strong&gt; and makes it possible for WinForms applications to say &amp;quot;When I await an asynchronous task and that task completes, I want to carry on my work on the same thread&amp;quot;. This is why there is no need to check InvokeRequired / BeginInvoke when writing async event handlers for WinForms UI components.&lt;/p&gt;&#xA;&lt;p&gt;One downside to this is that it puts constraints on how the &lt;strong&gt;ThreadPool&lt;/strong&gt; can and can&#x27;t distribute threads and means that it&#x27;s not as free to optimise usage solely for efficiency and throughput. It also means that either the request&#x27;s thread must remain allocated to the request until the request completes (negating one of the benefits of await / async) &lt;em&gt;or&lt;/em&gt; the request may have to wait after an async call completes before the thread that it wants to continue on becomes free*.&lt;/p&gt;&#xA;&lt;p&gt;* &lt;em&gt;(I&#x27;m not actually sure which of these two options happens in real world use but it feels like the sort of thing that is an implementation detail of the framework and it would be best to not presume that it would be one or the other)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Update (Jan 2021):&lt;/strong&gt; &lt;a href=&quot;https://blog.stephencleary.com/&quot;&gt;Stephen Cleary&lt;/a&gt; pointed out in a comment that actually the situation is not quite as bad as indicated with the pre-Core ASP.NET as it has some tricks up its sleeve regarding its synchronization context - the context can actually change threads, allowing it to fully release its current thread when it is awaiting something. This means that the impact on the ThreadPool is not as bad. I have, however, still encountered deadlocks in pre-Core ASP.NET and so it makes the issue less likely but not impossible. We&#x27;re only talking about pre-Core ASP.NET here because ASP.NET on .NET Core doesn&#x27;t have a synchronization context to worry about - see the section &amp;quot;Approach Five&amp;quot; further down in this post.&lt;/p&gt;&#xA;&lt;p&gt;There is another downside, though, which is that it&#x27;s quite easy to get into bother if you try to call async code from a &lt;em&gt;non&lt;/em&gt;-async method - as I&#x27;m about to show you!&lt;/p&gt;&#xA;&lt;h3&gt;The classic deadlock (aka. &amp;quot;why has my application hung?&amp;quot;)&lt;/h3&gt;&#xA;&lt;p&gt;This problem has been encountered so many times that a lot of async&#x27;ers recognise it straight away and there are plenty of questions on Stack Overflow about it. There is also good advice that  is often repeated about how to prevent it. However, I think that it&#x27;s particularly nasty because the code might not look hideously wrong at a glance but it will be able to cause your application to hang when it&#x27;s run - not throw an exception (which at least makes it clear where something has gone wrong), but to just &lt;em&gt;hang&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        return View(&#xA;            GetTitleAsync().Result&#xA;        );&#xA;    }&#xA;&#xA;    private async Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;When I encountered this problem, I was much deeper down the stack but the concept was the same -&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I was in code that was being called by an MVC action method and that method was not async&lt;/li&gt;&#xA;&lt;li&gt;I needed to call an async method&lt;/li&gt;&#xA;&lt;li&gt;I tried to access &amp;quot;.Result&amp;quot; on the task that I got back from the async method - this will block the current thread until the task completes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;The key factor&lt;/strong&gt;: ASP.NET applications also have a special synchronization context, similar to the WinForms one in that it returns to the same thread after an async call completes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;If you ran the code above then something like the following chain of events would occur:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would be given to the request to run on and &amp;quot;Index&amp;quot; would be called&lt;/li&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would call &amp;quot;GetTitleAsync&amp;quot; and get a &lt;strong&gt;Task&amp;lt;string&amp;gt;&lt;/strong&gt; reference&lt;/li&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would then request the &amp;quot;.Result&amp;quot; property of that task and would block until the task completed&lt;/li&gt;&#xA;&lt;li&gt;The &amp;quot;Task.Delay&amp;quot; call would complete and .NET would try to continue the &amp;quot;GetTitleAsync&amp;quot; work&lt;/li&gt;&#xA;&lt;li&gt;The ASP.NET synchronization context would require that work continue on Thread &amp;quot;A&amp;quot; and so the work would be placed on a queue for Thread &amp;quot;A&amp;quot; to deal with when it gets a chance (the &amp;quot;work&amp;quot; in this case is simply the line that returns the string &amp;quot;Hello!&amp;quot; but that code has to be executed somewhere)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;And this is how we become stuck!&lt;/p&gt;&#xA;&lt;p&gt;Thread &amp;quot;A&amp;quot; is waiting for the &amp;quot;GetTitleAsync&amp;quot; work to complete but the &amp;quot;GetTitleAsync&amp;quot; work can not complete until Thread &amp;quot;A&amp;quot; gets involved (which it can&#x27;t because it&#x27;s in a blocked state).&lt;/p&gt;&#xA;&lt;p&gt;This is the problem and it seem oh-so-obvious if you know how async / await work and about the ASP.NET synchronization context and if you&#x27;re paying close attention when you&#x27;re writing this sort of code. But if you &lt;em&gt;don&#x27;t&lt;/em&gt; then you get a horrible runtime problem.&lt;/p&gt;&#xA;&lt;p&gt;So let&#x27;s look at solutions.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach one: Don&#x27;t mix async and non-async code&lt;/strong&gt;. This is good advice when starting new codes - begin with async and then it&#x27;s async all the way down, no blocking of threads while accessing &amp;quot;.Result&amp;quot; and so no problem! However, with a big project it&#x27;s not very helpful.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach two: Always use &amp;quot;.ConfigureAwait(false)&amp;quot;&lt;/strong&gt;. This is the oft-repeated good advice that I mentioned earlier. As a rule of thumb, many people recommend &lt;em&gt;always&lt;/em&gt; including &amp;quot;.ConfigureAwait(false)&amp;quot; when you use await, like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;await Task.Delay(1000).ConfigureAwait(false);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The &amp;quot;false&amp;quot; value is for the &amp;quot;continueOnCapturedContext&amp;quot; parameter and this parameter effectively overrides the synchronization context about what thread the work must continue on when the async work has completed.&lt;/p&gt;&#xA;&lt;p&gt;If we changed our code to this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        return View(&#xA;            GetTitleAsync().Result&#xA;        );&#xA;    }&#xA;&#xA;    private async Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000).ConfigureAwait(false);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;.. then the chain of events goes more like this:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would be given to the request to run on and &amp;quot;Index&amp;quot; would be called&lt;/li&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would call &amp;quot;GetTitleAsync&amp;quot; and get a &lt;strong&gt;Task&amp;lt;string&amp;gt;&lt;/strong&gt; reference&lt;/li&gt;&#xA;&lt;li&gt;Thread &amp;quot;A&amp;quot; would then request the &amp;quot;.Result&amp;quot; property of that task and would block until the task completed&lt;/li&gt;&#xA;&lt;li&gt;The &amp;quot;Task.Delay&amp;quot; call would complete and .NET would try to continue the &amp;quot;GetTitleAsync&amp;quot; work&lt;/li&gt;&#xA;&lt;li&gt;Because we used &amp;quot;.ConfigureAwait(false)&amp;quot;, we are not restricted in terms of where can continue the &amp;quot;GetTitleAsync&amp;quot; work and so that will be done on Thread &amp;quot;B&amp;quot;&lt;/li&gt;&#xA;&lt;li&gt;The work for Thread &amp;quot;B&amp;quot; is simply to complete the &lt;strong&gt;Task&amp;lt;string&amp;gt;&lt;/strong&gt; by setting its result to &amp;quot;Hello!&amp;quot; (Thread &amp;quot;B&amp;quot; does this and then it is released back to the &lt;strong&gt;ThreadPool&lt;/strong&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Since the &lt;strong&gt;Task&amp;lt;string&amp;gt;&lt;/strong&gt; has completed, Thread &amp;quot;A&amp;quot; is no longer blocking on the &amp;quot;.Result&amp;quot; access and it can carry on with its work and return the &lt;strong&gt;ActionResult&lt;/strong&gt; from the method&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The good news here is that this solves the problem - there is no longer a deadlock that can occur!&lt;/p&gt;&#xA;&lt;p&gt;The bad news is that you must remember to add &amp;quot;.ConfigureAwait(false)&amp;quot; to your await calls. If you forget then there is a chance that your code will result in an application hang and you won&#x27;t find out until runtime. I don&#x27;t like this because one of the reasons that I enjoy C# as a strongly-typed language is that the compiler can catch so many mistakes and I &lt;em&gt;don&#x27;t&lt;/em&gt; have to wait until runtime to find problems much of the time. One way to make life easier on this front is to help the compiler help you by installing an analyser, such as the &lt;a href=&quot;https://www.nuget.org/packages/ConfigureAwaitChecker.Analyzer/&quot;&gt;ConfigureAwaitChecker.Analyzer&lt;/a&gt;. Installing this should result in you getting warnings in Visual Studio if you don&#x27;t include &amp;quot;.ConfigureAwait(false)&amp;quot; after any await.&lt;/p&gt;&#xA;&lt;p&gt;Another possible (and subjective) downside to this approach is that it makes the code &amp;quot;noisier&amp;quot; - if &amp;quot;.ConfigureAwait(false)&amp;quot; should be used almost every time you use &amp;quot;await&amp;quot; then shouldn&#x27;t it be the default behaviour and it be the case that you should have to include extra code if you &lt;em&gt;don&#x27;t&lt;/em&gt; want that behaviour? You may not agree with me but it feels like an extra burden that I&#x27;d rather live without.&lt;/p&gt;&#xA;&lt;p&gt;Instead, we could consider..&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach three: Disabling the synchronization context before calling async code&lt;/strong&gt;. The .NET environment allows the host to specify its own synchronization context but it also allows &lt;em&gt;any&lt;/em&gt; code to specify a particular context. We could use this to our advantage by doing something like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        // Get a reference to whatever the current context is, so that we can set&#xA;        // it back after the async work is done&#xA;        var currentSyncContext = SynchronizationContext.Current;&#xA;        string result;&#xA;        try&#xA;        {&#xA;            // Set the context to null so that any restrictions are removed that&#xA;            // relate to what threads async code can continue on&#xA;            SynchronizationContext.SetSynchronizationContext(null);&#xA;&#xA;            // Block this thread until the async work is complete&#xA;            result = GetTitleAsync().Result;&#xA;        }&#xA;        finally&#xA;        {&#xA;            // Set the context back to whatever it was before&#xA;            SynchronizationContext.SetSynchronizationContext(currentSyncContext);&#xA;        }&#xA;&#xA;        return View(result);&#xA;    }&#xA;&#xA;    private async Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This means that we don&#x27;t have to use &amp;quot;.ConfigureAwait(false)&amp;quot; and we &lt;em&gt;still&lt;/em&gt; don&#x27;t get any deadlocks. We can include code like this at the boundary where non-async code calls async code and then we won&#x27;t have to worry about whether the async code includes any await calls that do not specify &amp;quot;.ConfigureAwait(false)&amp;quot;.&lt;/p&gt;&#xA;&lt;p&gt;You wouldn&#x27;t want to include this extra code &lt;em&gt;every&lt;/em&gt; time that you called async code from non-async code and so it would make sense to encapsulate the logic in a method. Something like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController : Controller&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        return View(&#xA;            AsyncCallHelpers.WaitForAsyncResult(GetTitleAsync())&#xA;        );&#xA;    }&#xA;&#xA;    private async static Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&#xA;public static class AsyncCallHelpers&#xA;{&#xA;    /// &amp;lt;summary&amp;gt;&#xA;    /// Avoid the &#x27;classic deadlock problem&#x27; when blocking on async work from non-async&#xA;    /// code by disabling any synchronization context while the async work takes place&#xA;    /// &amp;lt;/summary&amp;gt;&#xA;    public static T WaitForAsyncResult&amp;lt;T&amp;gt;(Task&amp;lt;T&amp;gt; work)&#xA;    {&#xA;        var currentSyncContext = SynchronizationContext.Current;&#xA;        try&#xA;        {&#xA;            SynchronizationContext.SetSynchronizationContext(null);&#xA;            return work.Result;&#xA;        }&#xA;        finally&#xA;        {&#xA;            SynchronizationContext.SetSynchronizationContext(currentSyncContext);&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;I think that this is quite an elegant solution and makes for clear code (it is hopefully fairly clear to a reader of the code that there is something interesting going on at the non-async / async boundary and there is a nice summary comment explaining why).&lt;/p&gt;&#xA;&lt;p&gt;A variation on this theme is..&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach four: Use a custom INotifyCompletion implementation&lt;/strong&gt;. When &lt;strong&gt;Task&lt;/strong&gt;/&lt;strong&gt;Task&amp;lt;T&amp;gt;&lt;/strong&gt; was added to .NET along with async / await, the design included ways to override how awaiting a task should be handled and this gives us another way to remove the synchronization context for async work. We can take advantage of this facility by doing something like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController : Controller&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        return View(&#xA;            GetTitleAsync().Result&#xA;        );&#xA;    }&#xA;&#xA;    private async static Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        await new SynchronizationContextRemover();&#xA;&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&#xA;/// &amp;lt;summary&amp;gt;&#xA;/// This prevents any synchronization context from affecting what happens within&#xA;/// an async method and so we don&#x27;t need to worry if a non-async caller wants to&#xA;/// block while waiting for the result of the async method&#xA;/// &amp;lt;/summary&amp;gt;&#xA;public struct SynchronizationContextRemover : INotifyCompletion&#xA;{&#xA;    public bool IsCompleted =&amp;gt; SynchronizationContext.Current == null;&#xA;&#xA;    public void OnCompleted(Action continuation)&#xA;    {&#xA;        var prevContext = SynchronizationContext.Current;&#xA;        try&#xA;        {&#xA;            SynchronizationContext.SetSynchronizationContext(null);&#xA;            continuation();&#xA;        }&#xA;        finally&#xA;        {&#xA;            SynchronizationContext.SetSynchronizationContext(prevContext);&#xA;        }&#xA;    }&#xA;&#xA;    public SynchronizationContextRemover GetAwaiter() =&amp;gt; this;&#xA;&#xA;    public void GetResult() { }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;(This code comes from the article &amp;quot;&lt;a href=&quot;https://blogs.msdn.microsoft.com/benwilli/2017/02/09/an-alternative-to-configureawaitfalse-everywhere/&quot;&gt;An alternative to ConfigureAwait(false) everywhere&lt;/a&gt;&amp;quot;)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;This has the same effect as the previous approach - it removes any synchronization context until the async work has completed - but there is an important difference in how it is implemented:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When &lt;strong&gt;disabling the synchronization context before calling async code&lt;/strong&gt;, the extra code is included in the non-async code that is calling the async code&lt;/li&gt;&#xA;&lt;li&gt;When we &lt;strong&gt;use a custom INotifyCompletion implementation&lt;/strong&gt;, the extra code is included in the async code and the non-async calling code does not need to be changed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;I prefer these two approaches and choosing which of them to use comes down to what code I&#x27;m writing and what code I&#x27;m integrating with. For example:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;If I was writing the non-async code and I needed to call into a trusted and battle-tested async library then I might be tempted to do nothing at all because I would expect such a library to follow recommended practices such as using &amp;quot;.ConfigureAwait(false)&amp;quot; internally&lt;/li&gt;&#xA;&lt;li&gt;If I was writing non-async code that had to call into async code that I was less confident about then I would call it using &amp;quot;AsyncCallHelpers.WaitForAsyncResult&amp;quot; to be sure that nothing was going to go awry&lt;/li&gt;&#xA;&lt;li&gt;Note: This only applies to non-async code that will be hosted in an environment that uses a synchronization context that I need to be worried about (such as ASP.NET or WinForms but &lt;em&gt;not&lt;/em&gt; Console Applications or Windows Services)&lt;/li&gt;&#xA;&lt;li&gt;If I was writing async code that might be called from different environments (where an awkward synchronization context might come into play), then I would use the &lt;strong&gt;SynchronizationContextRemover&lt;/strong&gt; approach at the public boundaries (so that I wouldn&#x27;t need to specify &amp;quot;.ConfigureAwait(false)&amp;quot; everytime that I await something in my code)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;Two more &amp;quot;solutions&amp;quot; to round out the post&lt;/h3&gt;&#xA;&lt;p&gt;To quickly recap, the commonly-suggested recommendations for avoiding the &#x27;classic deadlock problem&#x27; are:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Don&#x27;t mix async and non-async code&lt;/li&gt;&#xA;&lt;li&gt;Always use &amp;quot;.ConfigureAwait(false)&amp;quot;&lt;/li&gt;&#xA;&lt;li&gt;Disabling the synchronization context before calling async code&lt;/li&gt;&#xA;&lt;li&gt;Use a custom INotifyCompletion implementation&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;.. but there are two others that I think are worthy of mention.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach five: Use ASP.NET Core&lt;/strong&gt; - the synchronization context that was used for previous versions of ASP.NET is not present in ASP.NET Core and so you don&#x27;t have to worry if you&#x27;re able to use it. If you already have a large application using non-Core ASP.NET that you are trying to introduce some async code into then whether or not this approach is feasible will likely depend upon your current code base and how much time you are willing to spend on migrating to ASP.NET Core.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Approach six: Use Task.Run&lt;/strong&gt; - this is a workaround that I have seen in some Stack Overflow answers. We could change our example code to look like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class HomeController&#xA;{&#xA;    public ActionResult Index()&#xA;    {&#xA;        var result = Task.Run(async () =&amp;gt; { return await GetTitleAsync(); }).Result;&#xA;        return View(result);&#xA;    }&#xA;&#xA;    private async Task&amp;lt;string&amp;gt; GetTitleAsync()&#xA;    {&#xA;        // This Task.Delay call simulates an async call that might go off to the&#xA;        // database or other external service&#xA;        await Task.Delay(1000);&#xA;        return &amp;quot;Hello!&amp;quot;;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This works because &amp;quot;Task.Run&amp;quot; will result in work being performed on a &lt;strong&gt;ThreadPool&lt;/strong&gt; thread and so the thread that calls into GetTitleAsync will not be associated with an ASP.NET synchronization context and so the deadlock won&#x27;t occur.&lt;/p&gt;&#xA;&lt;p&gt;It feels more like a workaround, rather than a real solution, and I don&#x27;t like the way that it&#x27;s not as obvious from reading the code &lt;em&gt;why&lt;/em&gt; it works. It &lt;em&gt;could&lt;/em&gt; be wrapped in a method like &amp;quot;AsyncCallHelpers.WaitForAsyncResult&amp;quot; so that comments could be added to explain why it&#x27;s being used but I feel like if you were going to do that then you would be better to use one of the more explicit approaches (such as the &amp;quot;AsyncCallHelpers.WaitForAsyncResult&amp;quot; method shown earlier). I have included it in this post only for completeness and because it is presented as a solution sometimes!&lt;/p&gt;&#xA;&lt;h3&gt;Further reading&lt;/h3&gt;&#xA;&lt;p&gt;To try to keep this post focused, I&#x27;ve skipped over and simplified some of the details involved in how async and await work. I think that it&#x27;s testament to the C# language designers that it can be such a complicated topic while the code &amp;quot;just works&amp;quot; most of the time, without you having to be aware of how it works all the way down.&lt;/p&gt;&#xA;&lt;p&gt;If you would like to find more then I would recommend the following articles. I read and re-read all of them while writing this to try to make sure that I wasn&#x27;t over-simplifying &lt;em&gt;too&lt;/em&gt; much (and to try ensure that I didn&#x27;t say anything patently false!)..&lt;/p&gt;&#xA;&lt;p&gt;Stephen Cleary&#x27;s &amp;quot;&lt;a href=&quot;https://blog.stephencleary.com/2013/11/there-is-no-thread.html&quot;&gt;There is no thread&lt;/a&gt;&amp;quot;&lt;/p&gt;&#xA;&lt;p&gt;Also Stephen Cleary&#x27;s (this time published on msdn.microsoft.com) &amp;quot;&lt;a href=&quot;https://msdn.microsoft.com/en-us/magazine/gg598924.aspx&quot;&gt;Parallel Computing - It&#x27;s All About the SynchronizationContext&lt;/a&gt;&amp;quot;&lt;/p&gt;&#xA;&lt;p&gt;Dixin&#x27;s &amp;quot;&lt;a href=&quot;https://weblogs.asp.net/dixin/understanding-c-sharp-async-await-2-awaitable-awaiter-pattern&quot;&gt;Understanding C# async / await: The Awaitable-Awaiter Pattern&lt;/a&gt;&amp;quot;&lt;/p&gt;&#xA;&lt;div class=&quot;Related&quot;&gt;&lt;h3&gt;You may also be interested in (see &lt;a href=&quot;https://www.productiverage.com/automating-suggested-related-posts-links-for-my-blog-posts&quot;&gt;here&lt;/a&gt; for information about how these are generated):&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/revisiting-net-core-tooling-visual-studio-2017&quot;&gt;Revisiting .NET Core tooling (Visual Studio 2017)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/ramping-up-wcf-web-service-request-handling-on-iis-6-with-net-40&quot;&gt;Ramping up WCF Web Service Request Handling.. on IIS 6 with .Net 4.0&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.productiverage.com/the-net-dictionary-is-fast&quot;&gt;The .Net Dictionary is FAST!&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</description>
                <pubDate>Sun, 30 Sep 2018 20:09:00 GMT</pubDate>
            </item>

    </channel>

</rss>