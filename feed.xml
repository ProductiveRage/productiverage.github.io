<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="/Content/RSS.xslt" type="text/xsl" media="screen"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">

	<channel>
		
		<title>Productive Rage</title>
		<link>http://www.productiverage.com/</link>
		<atom:link href="http://www.productiverage.com/feed" rel="self" type="application/rss+xml"/>
		<description>Dan's techie ramblings</description>
		<language>en-gb</language>

		<lastBuildDate>Sun, 13 Nov 2016 13:38:00 GMT</lastBuildDate>
		<docs>http://blogs.law.harvard.edu/tech/rss</docs>
		
		<image>
			<title>Productive Rage</title>
			<url>http://www.productiverage.com/Content/Images/Grouch.jpg</url>
			<width>142</width>
			<height>142</height>
			<link>http://www.productiverage.com/</link>
		</image>

		<xhtml:meta xmlns:xhtml="http://www.w3.org/1999/xhtml" name="robots" content="noindex" /> 

		<item>
			<title>Migrating my Full Text Indexer to .NET Core (supporting multi-target NuGet packages)</title>
            <link>http://www.productiverage.com/migrating-my-full-text-indexer-to-net-core-supporting-multitarget-nuget-packages</link>
			<guid>http://www.productiverage.com/migrating-my-full-text-indexer-to-net-core-supporting-multitarget-nuget-packages</guid>
			<description>&lt;p&gt;So it looks increasingly like .NET Core is going to be an important technology in the near future, in part because Microsoft is developing much of it in the open (in a significant break from their past approach to software), in part because some popular projects support it (&lt;a href=&quot;https://github.com/StackExchange/dapper-dot-net&quot;&gt;Dapper&lt;/a&gt;, &lt;a href=&quot;http://automapper.org/&quot;&gt;AutoMapper&lt;/a&gt;, &lt;a href=&quot;http://www.newtonsoft.com/json&quot;&gt;Json.NET&lt;/a&gt;) and in part because of excitement from blog posts such as &lt;a href=&quot;http://web.ageofascent.com/asp-net-core-exeeds-1-15-million-requests-12-6-gbps/&quot;&gt;ASP.NET Core – 2300% More Requests Served Per Second&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;All I really knew about it was that it was a cut-down version of the .NET framework which should be able to run on platforms other than Windows, which &lt;em&gt;might&lt;/em&gt; be faster in some cases and which may still undergo some important changes in the near future (such as moving away from the new &quot;project.json&quot; project files and back to something more traditional in terms of Visual Studio projects - see &lt;a href=&quot;https://wildermuth.com/2016/05/12/The-Future-of-project-json-in-ASP-NET-Core&quot;&gt;The Future of project.json in ASP.NET Core&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;To try to find out more, I&#39;ve taken a codebase that I wrote years ago and have migrated it to .NET Core. It&#39;s not enormous but it spans multiple projects, has a (small-but-better-than-nothing) test suite and supports serialising search indexes to and from disk for caching purposes. My hope was that I would be able to probe some of the limitations of .NET Core with this non-trivial project but that it wouldn&#39;t be such a large task that it take more than a few sessions spaced over a few days to complete.&lt;/p&gt;

&lt;h4&gt;Spoilers&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Would I be able to migrate one project at a time within the solution to .NET Core and still have the whole project building successfully (while some of the other projects were still targeting the &quot;full fat&quot; .NET framework)?&lt;/strong&gt; Yes, but some hacks are required.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Would it be easy (or even possible) to create a NuGet package that would work on both .NET Core and .NET 4.5?&lt;/strong&gt; Yes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Would the functionality that is no longer present in .NET Core cause me problems?&lt;/strong&gt; Largely, no. The restricted reflection capabilities, no - if I pull in an extra dependency. The restricted serialisation facilities, &lt;em&gt;yes&lt;/em&gt; (but I&#39;m fairly happy with the solution and compromises that I ended up with).&lt;/p&gt;

&lt;h3&gt;What, really, is .NET Core (and what is the Full Text Indexer)?&lt;/h3&gt;

&lt;p&gt;Essentially,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;.NET Core is a new cross-platform .NET Product .. [and] is composed of the following parts: A .NET runtime .. A set of framework libraries .. A set of SDK tools and language compilers .. The &#39;dotnet&#39; app host, which is used to launch .NET Core apps&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;(from Scott Hanselman&#39;s &quot;&lt;a href=&quot;http://www.hanselman.com/blog/NETCore10IsNowReleased.aspx&quot;&gt;.NET Core 1.0 is now released!.NET Core 1.0 is now released!&lt;/a&gt;&quot; post)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What .NET Core means in the context of this migration is that there are new project types in Visual Studio to use that target new .NET frameworks. Instead of .NET 4.6.1, for example, there is &quot;netstandard1.6&quot; for class libraries and &quot;netcoreapp1.0&quot; for console applications.&lt;/p&gt;

&lt;p&gt;The new Visual Studio project types become available after you install the &lt;a href=&quot;https://www.microsoft.com/net/core#windows&quot;&gt;Visual Studio Tooling&lt;/a&gt; - alternatively, the &quot;dotnet&quot; command line tool makes things very easy so you can could create projects using nothing more than notepad and &quot;dotnet&quot; if you want to! Since I was just getting started, I chose to stick in my Visual Studio comfort zone.&lt;/p&gt;

&lt;p&gt;The Full Text Indexer code that I&#39;m migrating was something that I wrote a few years ago while I was working with a Lucene integration (&quot;this full text indexing lark.. &lt;em&gt;how hard could it really be!&lt;/em&gt;&quot;). It&#39;s a set of class libraries; &quot;Common&quot; (which has no dependencies other than the .NET framework), &quot;Core&quot; (which depends upon Common), &quot;Helpers&quot; (which depends upon both Common and Core), and &quot;Querier&quot; (which also depends upon Common and Core). Then there is a &quot;UnitTests&quot; project and a &quot;Tester&quot; console application, which loads some data from a Sqlite database file, constructs an index and then performs a search or two (just to demonstrate how it works end-to-end).&lt;/p&gt;

&lt;p&gt;My plan was to try migrating one project at a time over to .NET Core, to move in baby steps so that I could be confident that everything would remain in a working state for most of the time.&lt;/p&gt;

&lt;h3&gt;Creating the first .NET Core project&lt;/h3&gt;

&lt;p&gt;The first thing I did was delete the &quot;Common&quot; project entirely (deleted it from Visual Studio and then manually deleted all of the files) and then created a brand new .NET Core class library called &quot;Common&quot;. I then used my source control client to revert the deletions of the class files so that they appeared within the new project&#39;s folder structure. I expected to then have to &quot;Show All Files&quot; and explicitly include these files in the project but it turns out that .NET Core project files don&#39;t specify files to include, it&#39;s presumed that all files in the folder will be included. Makes sense!&lt;/p&gt;

&lt;p&gt;It wouldn&#39;t compile, though, because some of the classes have the &lt;strong&gt;[Serializable]&lt;/strong&gt; attribute on them and this doesn&#39;t exist in .NET Core. As I understand it, that&#39;s because the framework&#39;s serialisation mechanisms have been stripped right back with the intention of the framework being able to specialise at framework-y core competencies and for there to be an increased reliance on external libraries for other functionality.&lt;/p&gt;

&lt;p&gt;This attribute is used through my library because there is an &lt;strong&gt;IndexDataSerialiser&lt;/strong&gt; that allows an index to be persisted to disk for caching purposes. It uses the &lt;strong&gt;BinaryFormatter&lt;/strong&gt; to do this, which requires that the types that you need to be serialised be decorated with the &lt;strong&gt;[Serializable]&lt;/strong&gt; attribute or they implement the &lt;strong&gt;ISerializable&lt;/strong&gt; interface. Neither the &lt;strong&gt;BinaryFormatter&lt;/strong&gt; nor the &lt;strong&gt;ISerializable&lt;/strong&gt; interface are available within .NET Core. I will need to decide what to do about this later - ideally, I&#39;d like to continue to be able to support reading and writing to the same format as I have done before (if only to see if it&#39;s possible when migrating to Core). For now, though, I&#39;ll just remove the &lt;strong&gt;[Serializable]&lt;/strong&gt; attributes and worry about it later.&lt;/p&gt;

&lt;p&gt;So, with very little work, the Common project was compiling for the &quot;netstandard1.6&quot; target framework.&lt;/p&gt;

&lt;p&gt;Unfortunately, the projects that rely on Common weren&#39;t compiling because their references to it were removed when I removed the project from the VS solution. And, if I try to add references to the new Common project I&#39;m greeted with this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A reference to &#39;Common&#39; could not be added. An assembly must have a &#39;dll&#39; or &#39;exe&#39; extension in order to be referenced.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem is that Common is being built for &quot;netstandard1.6&quot; but &lt;em&gt;only&lt;/em&gt; that framework. I also want it to support a &quot;full fat&quot; .NET framework, like 4.5.2 - in order to do this I need to edit the project.json file so that the build process creates multiple versions of the project, one .NET 4.5.2 as well as the one for netstandard. That means changing it from this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;version&quot;: &quot;1.0.0-*&quot;,

  &quot;dependencies&quot;: {
    &quot;NETStandard.Library&quot;: &quot;1.6.0&quot;
  },

  &quot;frameworks&quot;: {
    &quot;netstandard1.6&quot;: {
      &quot;imports&quot;: &quot;dnxcore50&quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;version&quot;: &quot;1.0.0-*&quot;,

  &quot;dependencies&quot;: {},

  &quot;frameworks&quot;: {
    &quot;netstandard1.6&quot;: {
      &quot;imports&quot;: &quot;dnxcore50&quot;,
      &quot;dependencies&quot;: {
        &quot;NETStandard.Library&quot;: &quot;1.6.0&quot;
      }
    },
    &quot;net452&quot;: {}
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two things have happened - an additional entry has been added to the &quot;frameworks&quot; section (&quot;net452&quot; joins &quot;netstandard1.6&quot;) and the &quot;NETStandard.Library&quot; dependency has moved from being something that is always required by the project to something that is only required by the project when it&#39;s being built for netstandard.&lt;/p&gt;

&lt;p&gt;Now, Common may be added as a reference to the other projects.&lt;/p&gt;

&lt;p&gt;However.. they won&#39;t compile. Visual Studio will be full of errors that required classes do not exist in the current context.&lt;/p&gt;

&lt;h3&gt;Adding a reference to a .NET Core project from a .NET 4.5.2 project in the same solution&lt;/h3&gt;

&lt;p&gt;Although the project.json configuration does mean that two version of the Common library are being produced (looking in the bin/Debug folder, there are two sub-folders &quot;net452&quot; and &quot;netstandard1.6&quot; and each have their own binaries in), it seems that the &quot;Add Reference&quot; functionality in Visual Studio doesn&#39;t (currently) support adding references. There is an issue on GitHub about this; &lt;a href=&quot;https://github.com/dotnet/core/issues/231&quot;&gt;Allow &quot;Add Reference&quot; to .NET Core class library that uses .NET Framework from a traditional class library&lt;/a&gt; but it seems like the conclusion is that this will be fixed in the future, when the changes have been completed that move away from .NET Core projects having a project.json file and towards a new kind of &quot;.csproj&quot; file.&lt;/p&gt;

&lt;p&gt;There is a workaround, though. Instead of selecting the project from the Add Reference dialog, you click &quot;Browse&quot; and then select that file in the &quot;Common/bin/Debug/net452&quot; folder. Then the project &lt;em&gt;will&lt;/em&gt; build. This isn&#39;t a perfect solution, though, since it will &lt;em&gt;always&lt;/em&gt; reference the Debug build. When building in Release configuration, you also want the referenced binaries from other projects to be built in Release configuration. To do that, I had to open each &quot;.csproj&quot; file notepad and change&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Reference Include=&quot;Common&quot;&amp;gt;
  &amp;lt;HintPath&amp;gt;..\Common\bin\Debug\net452\Common.dll&amp;lt;/HintPath&amp;gt;
&amp;lt;/Reference&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Reference Include=&quot;Common&quot;&amp;gt;
  &amp;lt;HintPath&amp;gt;..\Common\bin\$(Configuration)\net452\Common.dll&amp;lt;/HintPath&amp;gt;
&amp;lt;/Reference&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A little bit annoying but not the end of the world (credit for this fix, btw, goes to this Stack Overflow answer to &lt;a href=&quot;http://stackoverflow.com/a/37323585/3813189&quot;&gt;Attach unit tests to ASP.NET Core project&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;What makes it even more annoying is the link from the referencing project (say, the Core project) to the &lt;em&gt;referenced&lt;/em&gt; project (the Common project) is not as tightly integrated as when a project reference is normally added through Visual Studio. For example, while you can set breakpoints on the Common project and they will be hit when the Core project calls into that code, using &quot;Go To Definition&quot; to navigate from code in the Core project into code in the referenced Common project &lt;em&gt;doesn&#39;t&lt;/em&gt; work (it takes you to a &quot;from metadata&quot; view rather than taking you to the actual file). On top of this, the referencing project doesn&#39;t know that it needs to be rebuilt if the referenced project is rebuilt - so, if the Common library is changed and rebuilt then the Core library may continue to work against an old version of the Common binary unless you explicitly rebuild Core as well.&lt;/p&gt;

&lt;p&gt;These are frustrations that I would not want to live with long term. However, the plan here is to migrate all of the projects over to .NET Core and so I think that I can put up with these limitations so long as they only affect me as I migrate the projects over one-by-one.&lt;/p&gt;

&lt;h3&gt;The second project (additional dependencies required)&lt;/h3&gt;

&lt;p&gt;I repeated the procedure for second project; &quot;Core&quot;. This also contained files with types marked as &lt;strong&gt;[Serializable]&lt;/strong&gt; (which I just removed for now) and there was the &lt;strong&gt;IndexDataSerialiser&lt;/strong&gt; class that used the &lt;strong&gt;BinaryFormatter&lt;/strong&gt; to allow data to be persisted to disk - this also had to go, since there was no support for it in .NET Core (I&#39;ll talk about what I did with serialisation later on). I needed to add a reference to the Common project - thankfully adding a reference to a .NET Core project &lt;em&gt;from&lt;/em&gt; a .NET Core project works perfectly, so the workaround that I had to apply before (when the Core project was still .NET 4.5.2) wasn&#39;t necessary.&lt;/p&gt;

&lt;p&gt;However, it still didn&#39;t compile.&lt;/p&gt;

&lt;p&gt;In the &quot;Core&quot; project lives the &lt;strong&gt;EnglishPluralityStringNormaliser&lt;/strong&gt; class, which
is used to adjust tokens (ie. words) so that the singular and plural versions of the same word are considered equivalent (eg. &quot;cat&quot; and &quot;cats&quot;, &quot;category&quot; and &quot;categories&quot;). Internally, it generates a compiled LINQ expression to try to perform its work as efficiently as possible and it requires reflection to do that. Calling &quot;GetMethod&quot; and &quot;GetProperty&quot; on a &lt;strong&gt;Type&lt;/strong&gt; is not supported in netstandard, though, and an additional dependency is required. So the Core project.json file needed to be changed to look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;version&quot;: &quot;1.0.0-*&quot;,

  &quot;dependencies&quot;: {
    &quot;Common&quot;: &quot;1.0.0-*&quot;
  },

  &quot;frameworks&quot;: {
    &quot;netstandard1.6&quot;: {
      &quot;imports&quot;: &quot;dnxcore50&quot;,
      &quot;dependencies&quot;: {
        &quot;NETStandard.Library&quot;: &quot;1.6.0&quot;
        &quot;System.Reflection.TypeExtensions&quot;: &quot;4.1.0&quot;
      }
    },
    &quot;net452&quot;: {}
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Common project is a dependency regardless of what the target framework is during the build process but the &quot;System.Reflection.TypeExtensions&quot; package is also required when building for netstandard (but not .NET 4.5.2), as this includes extensions methods for &lt;strong&gt;Type&lt;/strong&gt; such as &quot;GetMethod&quot; and &quot;GetProperty&quot;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Since these are extension methods in netstandard, a &quot;using System.Reflection;&quot; statement is required at the top of the class - this is not required when building for .NET 4.5.2 because &quot;GetMethod&quot; and &quot;GetProperty&quot; are instance methods on &lt;strong&gt;Type&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There was one other dependency that was required for Core to build - &quot;System.Globalization.Extensions&quot;. This was because the &lt;strong&gt;DefaultStringNormaliser&lt;/strong&gt; class includes the line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var normalisedValue = value.Normalize(NormalizationForm.FormKD);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which resulted in the error&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&#39;string&#39; does not contain a definition for &#39;Normalize&#39; and no extension method &#39;Normalize&#39; accepting a first argument of type &#39;string&#39; could be found (are you missing a using directive or an assembly reference?)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is another case of functionality that is in .NET 4.5.2 but that is an optional package for .NET Core. Thankfully, it&#39;s easy to find out what additional package needs to be included - the &quot;lightbulb&quot; code fix options will try to look for a package to resolve the problem and it correctly identifies that &quot;System.Globalization.Extensions&quot; contains a relevant extension method (as illustrated below).&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;TODO&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/SystemGlobalizationExtensionsDependency.png&quot; class=&quot;AlwaysFullWidth NoBorder&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Selecting the &quot;Add package System.Globalization.Extensions 4.0.1&quot; option will add the package as a dependecy for netstandard in the project.json file and it will add the required &quot;using System.Globalization;&quot; statement to the class - which is very helpful of it!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;All that remained now was to use the workaround from before to add the .NET Core version of the &quot;Core&quot; project as a reference to the projects that required it.&lt;/p&gt;

&lt;h3&gt;The third and fourth projects (both class libraries)&lt;/h3&gt;

&lt;p&gt;The process for the &quot;Helpers&quot; and &quot;Querier&quot; class libraries was simple. Neither required anything that wasn&#39;t included in netstandard1.6 and so it was just a case of going through the motions.&lt;/p&gt;

&lt;h3&gt;The &quot;Tester&quot; Console Application&lt;/h3&gt;

&lt;p&gt;At this point, all of the projects that constituted the actual &quot;Full Text Indexer&quot; were building for both the netstandard1.6 framework and .NET 4.5.2 - so I could have stopped here, really (aside from the serialisation issues I had been putting off). But I thought I might as well go all the way and see if there were any interesting differences in migrating Console Applications and xUnit test suite projects.&lt;/p&gt;

&lt;p&gt;For the Tester project; no, not much was different. It has an end-to-end example integration where it loads data from a Sqlite database file of Blog posts using Dapper and then creates a search index. The posts contain markdown content and so three NuGet packages were required - &lt;a href=&quot;https://www.nuget.org/packages/Dapper&quot;&gt;Dapper&lt;/a&gt;, &lt;a href=&quot;https://www.nuget.org/packages/System.Data.Sqlite&quot;&gt;System.Data.Sqlite&lt;/a&gt; and &lt;a href=&quot;https://www.nuget.org/packages/MarkdownSharp&quot;&gt;MarkdownSharp&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dapper supports .NET Core and so that was no problem but the other two did not. Thankfully, though, there were alternatives that &lt;em&gt;did&lt;/em&gt; support netstandard - &lt;a href=&quot;https://www.nuget.org/packages/Microsoft.Data.Sqlite&quot;&gt;Microsoft.Data.Sqlite&lt;/a&gt; and &lt;a href=&quot;https://www.nuget.org/packages/Markdown&quot;&gt;Markdown&lt;/a&gt;. Using Microsoft.Data.Sqlite required some (very minor) code changes while Markdown exposed exactly the same interface as MarkdownSharp.&lt;/p&gt;

&lt;h3&gt;The xUnit Test Suite Project&lt;/h3&gt;

&lt;p&gt;The &quot;UnitTests&quot; project didn&#39;t require anything &lt;em&gt;very&lt;/em&gt; different but there are a few gotchas to watch out for..&lt;/p&gt;

&lt;p&gt;The first is that you need to create a &quot;Console Application (.NET Core)&quot; project since xUnit works with the &quot;netcoreapp1.0&quot; framework (which console applications target) and not &quot;netstandard1.6&quot; (which is what class libraries target).&lt;/p&gt;

&lt;p&gt;The second is that, presuming you want the Visual Studio test runner integration (which, surely, you do!) you need to not only add the &quot;xunit&quot; NuGet package but also the &quot;dotnet-test-xunit&quot; package. Thirdly, you need to enable the &quot;Include prerelease&quot; option in the NuGet Package Manager to locate versions of these packages that work with .NET Core (this will, of course, change with time - but as of November 2016 these packages are only available as &quot;prereleases&quot;).&lt;/p&gt;

&lt;p&gt;Fourthly, you need to add a line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&quot;testRunner&quot;: &quot;xunit&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to the project.json file.&lt;/p&gt;

&lt;p&gt;Having done all of this, the project should compile &lt;em&gt;and&lt;/em&gt; the tests should appear in the Test Explorer window.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: I wanted to fully understand each step required to create an xUnit test project but you could also just follow the instructions at &lt;a href=&quot;https://xunit.github.io/docs/getting-started-dotnet-core.html&quot;&gt;Getting started with xUnit.net (.NET Core / ASP.NET Core)&lt;/a&gt; which provides you a complete project.json to paste in - one of the nice things about .NET Core projects is that changing (and saving) the project.json is all it takes to change from being a class library (and targeting netstandard) to being a console application (and targeting netcoreapp). Similarly, references to other projects and to NuGet packges are all specified there and saving changes to that project file results in those reference immediately being resolved and any specified packages being downloaded.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the class library projects, I made them all target both netstandard and net452. With the test suite project, if the project.json file is changed to target both .NET Core (&quot;netcoreapp1.0&quot;, since it&#39;s a console app) and full fat .NET (&quot;net452&quot;) then two different versions of the suite will be built. The clever thing about this is that if you use the command line to run the tests -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dotnet test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then it will run the tests in both versions. Since there are going to be some differences between the different frameworks and, quite feasibly, between different versions of dependencies then it&#39;s a very handy tool to be able to run the tests against all of the versions of .NET that your libraries target.&lt;/p&gt;

&lt;p&gt;There is a &quot;but&quot; here, though. While the command line test process will target both frameworks, the Visual Studio Test Explorer doesn&#39;t. I &lt;em&gt;think&lt;/em&gt; that it only targets the first framework that is specified in the project.json file but I&#39;m not completely sure. I just know that it doesn&#39;t run them both. Which is a pity. On the bright side, I do like that .NET Core is putting the command line first - not only because I&#39;m a command line junkie but also because it makes it very easy to integrate into build servers and continuous integration  processes. I do hope that one day (soon) that the VS integration will be as thorough as the command line tester, though.&lt;/p&gt;

&lt;h3&gt;Building NuGet packages&lt;/h3&gt;

&lt;p&gt;So, now, there are no errors and everything is building for .NET Core &lt;em&gt;and&lt;/em&gt; for &quot;classic&quot;* .NET.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;I&#39;m still not sure what the accepted terminology is for non-.NET-Core projects, I don&#39;t really think that &quot;full fat framework&quot; is the official designation :)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There are no nasty workarounds required for the references (like when the not-yet-migrated .NET 4.5.2 projects were referencing the .NET Core projects). It&#39;s worth mentioning that that workaround was only required when the .NET 4.5.2 project wanted to reference a .NET Core project &lt;em&gt;from within the same solution&lt;/em&gt; - if the project that targeted both &quot;netstandard1.6&quot; and &quot;net452&quot; was built into a NuGet package then that package could be added to a .NET Core project &lt;em&gt;or&lt;/em&gt; to a .NET 4.5.2 project &lt;em&gt;without any workarounds&lt;/em&gt;. Which makes me think that now is a good time to talk about building NuGet packages from .NET Core projects..&lt;/p&gt;

&lt;p&gt;The project.json file has enough information that the &quot;dotnet&quot; command line can create a NuGet package from it. So, if you run the following command (you need to be in the root of the project that you&#39;re interested in to do this) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dotnet pack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then you will get a NuGet package built, ready to distribute! This is very handy, it makes things very simple. And if the project.json targets both netstandard1.6 and net452 then you will get a NuGet package that may be added to either a .NET Core project or a .NET 4.5.2 (or later) project.&lt;/p&gt;

&lt;p&gt;I hadn&#39;t created the Full Text Indexer as a NuGet package before now, so this seemed like a good time to think about how exactly I wanted to do it.&lt;/p&gt;

&lt;p&gt;There were a few things that I wanted to change with what &quot;dotnet pack&quot; gave me at this point -&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The name and ID of the package comes from the project name, so the Core project resulted into a package named &quot;Core&quot;, which is too vague&lt;/li&gt;
&lt;li&gt;I wanted to include additional metadata in the packages such as a description, project link and icon url&lt;/li&gt;
&lt;li&gt;If each project would be built into a separate package then it might not be clear to someone what packages are required and how they work together, so it probably makes sense to have a combined package that pulls in everything&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For points one and two, the &quot;&lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/articles/core/tools/project-json&quot;&gt;project.json reference&lt;/a&gt;&quot; documentation has a lot of useful information. It describes the &quot;name&quot; attribute -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The name of the project, used for the assembly name as well as the name of the package. The top level folder name is used if this property is not specified.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, it sounds like I could add a line to the Common project -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&quot;name&quot;: &quot;FullTextIndexer.Common&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. which would result in the NuGet package for &quot;Common&quot; having the ID &quot;FullTextIndexer.Common&quot;. And it does!&lt;/p&gt;

&lt;p&gt;However, there is a problem with doing this.&lt;/p&gt;

&lt;p&gt;The &quot;Common&quot; project is going to be built into a NuGet package called &quot;FullTextIndexer.Common&quot; so the projects that depend upon it will need updating - their project.json files need to change the dependency from &quot;Common&quot; to &quot;FullTextIndexer.Common&quot;. If the Core project, for example, wasn&#39;t updated to state &quot;FullTextIndexer.Common&quot; as a dependency then the &quot;Core&quot; NuGet package would have a dependency on a package called &quot;Common&quot;, which wouldn&#39;t exist (because I want to publish it as &quot;FullTextIndexer.Common&quot;). The issue is that if Core&#39;s project.json is updated to specify &quot;FullTextIndexer.Common&quot; as a dependency then the following errors are reported:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NuGet Package Restore failed for one or more packages. See details in the Output window.&lt;/p&gt;
  
  &lt;p&gt;The dependency FullTextIndexer.Common &gt;= 1.0.0-* could not be resolved.&lt;/p&gt;
  
  &lt;p&gt;The given key was not present in the dictionary.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To cut a long story short, after some trial and error experimenting (and having been unable to find any documentation about this or reports of anyone having the same problem) it seems that the problem is that .NET Core dependencies within a solution depend upon the project folders having the same name as the package name - so my problem was that I had a project folder called &quot;Common&quot; that was building a NuGet package called &quot;FullTextIndexer.Common&quot;. Renaming the &quot;Common&quot; folder to &quot;FullTextIndexer.Common&quot; fixed it. It probably makes sense to keep the project name, package name and folder name consistent in general, I just wish that the error messages had been more helpful because the process of discovering this was very frustrating!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Since I renamed the project folder to &quot;FullTextIndexer.Common&quot;, I didn&#39;t need the &quot;name&quot; option in the project.json file and so I removed it (the default behaviour of using the top level folder name is fine).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/articles/core/tools/project-json&quot;&gt;project.json reference&lt;/a&gt; made the second task simple, though, by documenting the &quot;&lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/articles/core/tools/project-json#packoptions&quot;&gt;packOptions&lt;/a&gt;&quot; section. To cut to the chase, I changed the Common&#39;s project.json to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;version&quot;: &quot;1.0.0-*&quot;,

  &quot;packOptions&quot;: {
    &quot;iconUrl&quot;: &quot;https://secure.gravatar.com/avatar/6a1f781d4d5e2d50dcff04f8f049767a?s=200&quot;,
    &quot;projectUrl&quot;: &quot;https://bitbucket.org/DanRoberts/full-text-indexer&quot;,
    &quot;tags&quot;: [ &quot;C#&quot;, &quot;full text index&quot;, &quot;search&quot; ]
  },
  &quot;authors&quot;: [ &quot;ProductiveRage&quot; ],
  &quot;copyright&quot;: &quot;Copyright 2016 ProductiveRage&quot;,

  &quot;dependencies&quot;: {},

  &quot;frameworks&quot;: {
    &quot;netstandard1.6&quot;: {
      &quot;imports&quot;: &quot;dnxcore50&quot;,
      &quot;dependencies&quot;: {
        &quot;NETStandard.Library&quot;: &quot;1.6.0&quot;
      }
    },
    &quot;net452&quot;: {}
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I updated the other class library projects similarly and updated the dependency names on all of the projects in the solution so that everything was consistent and compiling.&lt;/p&gt;

&lt;p&gt;Finally, I created an additional project named simply &quot;FullTextIndexer&quot; whose only role in life is to generate a NuGet package that includes all of the others (it doesn&#39;t have any code of its own). Its project.json file looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;version&quot;: &quot;1.0.0-*&quot;,

  &quot;packOptions&quot;: {
    &quot;summary&quot;: &quot;A project to try implementing a full text index service from scratch in C# and .NET Core&quot;,
    &quot;iconUrl&quot;: &quot;https://secure.gravatar.com/avatar/6a1f781d4d5e2d50dcff04f8f049767a?s=200&quot;,
    &quot;projectUrl&quot;: &quot;https://bitbucket.org/DanRoberts/full-text-indexer&quot;,
    &quot;tags&quot;: [ &quot;C#&quot;, &quot;full text index&quot;, &quot;search&quot; ]
  },
  &quot;authors&quot;: [ &quot;ProductiveRage&quot; ],
  &quot;copyright&quot;: &quot;Copyright 2016 ProductiveRage&quot;,

  &quot;dependencies&quot;: {
    &quot;FullTextIndexer.Common&quot;: &quot;1.0.0-*&quot;,
    &quot;FullTextIndexer.Core&quot;: &quot;1.0.0-*&quot;,
    &quot;FullTextIndexer.Helpers&quot;: &quot;1.0.0-*&quot;,
    &quot;FullTextIndexer.Querier&quot;: &quot;1.0.0-*&quot;
  },

  &quot;frameworks&quot;: {
    &quot;netstandard1.6&quot;: {
      &quot;imports&quot;: &quot;dnxcore50&quot;,
      &quot;dependencies&quot;: {
        &quot;NETStandard.Library&quot;: &quot;1.6.0&quot;
      }
    },
    &quot;net452&quot;: {}
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One final note about NuGet packages before I move on - the default behaviour of &quot;dotnet pack&quot; is to build the project in Debug configuration. If you want to build in release mode then you can use the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dotnet pack --configuration Release
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;&quot;Fixing&quot; the serialisation problem&lt;/h3&gt;

&lt;p&gt;Serialisation in .NET Core seems to a bone of contention - the Microsoft Team are sticking to their guns in terms of not supporting it and, instead, promoting other solutions:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Binary Serialization&lt;/p&gt;
  
  &lt;p&gt;Justification. After a decade of servicing we&#39;ve learned that serialization is incredibly complicated and a huge compatibility burden for the types supporting it. Thus, we made the decision that serialization should be a protocol implemented on top of the available public APIs. However, binary serialization requires intimate knowledge of the types as it allows to serialize object graphs including private state.&lt;/p&gt;
  
  &lt;p&gt;Replacement. Choose the serialization technology that fits your goals for formatting and footprint. Popular choices include data contract serialization, XML serialization, JSON.NET, and protobuf-net.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;(from &quot;&lt;a href=&quot;https://github.com/dotnet/corefx/blob/2b15de70c1cf9f585c4878a722de4dbe42b4940b/Documentation/project-docs/porting.md#binary-serialization&quot;&gt;Porting to .NET Core&lt;/a&gt;&quot;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Meanwhile, people have voiced their disagreement in GitHub issues such as &quot;&lt;a href=&quot;https://github.com/dotnet/corefx/issues/6564&quot;&gt;Question: Serialization support going forward from .Net Core 1.0&lt;/a&gt;&quot;.&lt;/p&gt;

&lt;p&gt;The problem with recommendations such as &lt;a href=&quot;http://www.newtonsoft.com/json&quot;&gt;Json.NET&lt;/a&gt;) and &lt;a href=&quot;https://github.com/mgravell/protobuf-net&quot;&gt;protobuf-net&lt;/a&gt; is that they require changes to code that previously worked with BinaryFormatter - there is no simple switchover. Another consideration is that I wanted to see if it was possible to migrate my code over to supporting .NET Core while still making it compatible with any existing installation, such that it could still deserialise any disk-cached data that had been persisted in the past (the chances of this being a realistic use case are exceedingly slim - I doubt that anyone but me has used the Full Text Indexer - I just wanted to see if it seemed feasible).&lt;/p&gt;

&lt;p&gt;For the sake of this post, I&#39;m going to cheat a little. While I have come up with a way to serialise index data that works with netstandard, it would probably best be covered another day (and it isn&#39;t compatible with historical data, unfortunately). A good-enough-for-now approach was to use &quot;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/4y6tbswk.aspx&quot;&gt;conditional directives&lt;/a&gt;&quot;, which are basically a way to say &quot;if you&#39;re building in this configuration then include this code (and if you&#39;re not, then don&#39;t)&quot;. This allowed me the restore all of the &lt;strong&gt;[Serializable]&lt;/strong&gt; attributes that I removed earlier - but only if building for .NET 4.5.2 (and not for .NET Core). For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if NET452
    [Serializable]
#endif
    public class Whatever
    {
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;strong&gt;[Serializable]&lt;/strong&gt; attribute will be included in the binaries for .NET 4.5.2 and not for .NET Core.&lt;/p&gt;

&lt;p&gt;You need to be careful with precisely what conditions you specify, though. When I first tried this, I used the line &quot;if #net452&quot; (where the string &quot;net452&quot; is consistent with the framework target string in the project.json files) but the attribute wasn&#39;t being included in the .NET 4.5.2 builds. There was no error reported, it just wasn&#39;t getting included. I had to look up the supported values to see if I&#39;d made a silly mistake and it was the casing - it needs to be &quot;NET452&quot; and not &quot;net452&quot;.&lt;/p&gt;

&lt;p&gt;I used the same approach to restore the &lt;strong&gt;ISerializable&lt;/strong&gt; implementations that some classes had and I used it to conditionally compile the entirety of the &lt;strong&gt;IndexDataSerialiser&lt;/strong&gt; (which I got back out of my source control history, having deleted it earlier).&lt;/p&gt;

&lt;p&gt;This meant that if the &quot;FullTextIndexer&quot; package is added to a project building for the &quot;classic&quot; .NET framework then all of the serialisation options that were previously available still will be - any disk-cached data may be read back using the &lt;strong&gt;IndexDataSerialiser&lt;/strong&gt;. It &lt;em&gt;wouldn&#39;t&lt;/em&gt; be possible if the package is added to a .NET Core project but this compromise felt much better than nothing.&lt;/p&gt;

&lt;h3&gt;Final tweaks and parting thoughts&lt;/h3&gt;

&lt;p&gt;The migration is almost complete at this point. There&#39;s one minor thing I&#39;ve noticed while experimenting with .NET Core projects; if a new solution is created whose first project is a .NET Core class library or console application, the project files aren&#39;t put into the root of the solution - instead, they are in a &quot;src&quot; folder. Also, there is a &quot;global.json&quot; file in the solution root that enables.. &lt;em&gt;magic special things&lt;/em&gt;. If I&#39;m being honest, I haven&#39;t quite wrapped my head around all of the potential benefits of global.json (though there is an explanation of one of the benefits here; &lt;a href=&quot;https://ievangelist.github.io/blog/the-global-json/&quot;&gt;The power of the global.json&lt;/a&gt;). What I&#39;m getting around to saying is that I want my now-.NET-Core solution to look like a &quot;native&quot; .NET Core solution, so I tweaked the folder structure and the .sln file to be consistent with a solution that had been .NET Core from the start. I&#39;m a fan of consistency and I think it makes sense to have my .NET Core solution follow the same arrangement as everyone else&#39;s .NET Core solutions.&lt;/p&gt;

&lt;p&gt;Having gone through this whole process, I think that there&#39;s an important question to answer: &lt;strong&gt;Will I now switch to defaulting to supporting .NET Core for all new projects?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;.. and the answer is, today, if I&#39;m being honest.. no.&lt;/p&gt;

&lt;p&gt;There are just a few too many rough edges and question marks. The biggest one is the change that&#39;s going to happen away from &quot;project.json&quot; and to a variation of the &quot;.csproj&quot; format. I&#39;m sure that there will be some sort of simple migration tool but I&#39;d rather know &lt;em&gt;for sure&lt;/em&gt; what the implications are going to be around this change before I commit too much to .NET Core.&lt;/p&gt;

&lt;p&gt;I&#39;m also a bit annoyed that the Productivity Power Tools remove-and-sort-usings-on-save doesn&#39;t work with .NET Core projects (there&#39;s an &lt;a href=&quot;https://github.com/Microsoft/VS-PPT/issues/40&quot;&gt;issue on GitHub&lt;/a&gt; about this but it hasn&#39;t bee responded to since August 2016, so I&#39;m not sure if it will get fixed).&lt;/p&gt;

&lt;p&gt;Finally, I&#39;m sure I read an issue around analysers being included in NuGet packages for .NET Core - that they weren&#39;t getting loaded correctly. I can&#39;t find the issue now so I&#39;ve done some tests to try to confirm or deny the rumour.. I&#39;ve got a very simple project that includes an analyser and whose package targets both .NET 4.5 and netstandard1.6 and the analyser &lt;em&gt;does&lt;/em&gt; seem to install correctly and be included in the build process (see &lt;a href=&quot;https://github.com/ProductiveRage/ProductiveRage.SealedClassVerification&quot;&gt;ProductiveRage.SealedClassVerification&lt;/a&gt;) but I still have a few concerns; in .csproj files, analyser are all explicitly referenced (and may be enabled or disabled in the Solution Explorer by going into References/Analyzers) but I can&#39;t see how they&#39;re referenced in .NET Core projects (and they don&#39;t appear in the Solution Explorer). Another (minor) thing is that, while the analyser does get executed and any warnings displayed in the Error List in Visual Studio, there are no squigglies underlining the offending code. I don&#39;t know why that is and it makes me worry that the integration is perhaps a bit flakey. I&#39;m a big fan of analysers and so I want to be sure that they are fully supported*. Maybe this will get tidied up when the new project format comes about.. whenever that will be.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(&lt;strong&gt;Update:&lt;/strong&gt; Having since added a code fix to the &quot;SealedClassVerification&quot; analyser, I&#39;ve realised that the no-squigglies-in-editor problem is worse than I first thought - it means that the lightbulb for the code fix does not appear in the editor and so the code fix can not be used. I also found the GitHub issue that I mentioned: &quot;&lt;a href=&quot;https://github.com/dotnet/roslyn-analyzers/issues/1028&quot;&gt;Analyzers fail on .NET Core projects&lt;/a&gt;&quot;, it says that improvements are on the way &quot;in .NET Core 1.1&quot; which should be released sometime this year.. maybe then will improve things)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I think that things are &lt;em&gt;close&lt;/em&gt; (and I like that Microsoft is making this all available early on and accepting feedback on it) but I don&#39;t think that it&#39;s quite ready enough for me to switch to it full time yet.&lt;/p&gt;

&lt;p&gt;Finally, should you be curious at all about the Full Text Indexer project that I&#39;ve been talking about, the source code is available here: &lt;a href=&quot;https://bitbucket.org/DanRoberts/full-text-indexer&quot;&gt;bitbucket.org/DanRoberts/full-text-indexer&lt;/a&gt; and there are a range of old posts that I wrote about how it works (see &quot;&lt;a href=&quot;http://www.productiverage.com/the-full-text-indexer-post-roundup&quot;&gt;The Full Text Indexer Post Round-up&lt;/a&gt;&quot;).&lt;/p&gt;
</description>
			<pubDate>Sun, 13 Nov 2016 13:38:00 GMT</pubDate>
		</item>
		<item>
			<title>When a disk cache performs better than an in-memory cache (befriending the .NET GC)</title>
            <link>http://www.productiverage.com/when-a-disk-cache-performs-better-than-an-inmemory-cache-befriending-the-net-gc</link>
			<guid>http://www.productiverage.com/when-a-disk-cache-performs-better-than-an-inmemory-cache-befriending-the-net-gc</guid>
			<description>&lt;h3&gt;TL;DR (especially for Bud Goode)&lt;/h3&gt;

&lt;p&gt;The .NET garbage collector is a complex beast. Occasionally it might infuriate but remember that it&#39;s keeping you from the misery of manual memory management and that you&#39;re better to consider it an ally than a foe.&lt;/p&gt;

&lt;p&gt;Sometimes, ways to improve its performance seem counter-intuitive, such as intentionally keeping objects around that will have to be considered by each of the already-expensive gen 2 collections, even when we have no intention of letting those objects go (aka. object pooling) and such as using disk caching instead of in-memory caching, despite an in-memory cache &quot;obviously&quot; being more performant than having to hit the file system.&lt;/p&gt;

&lt;h3&gt;The deep dive&lt;/h3&gt;

&lt;p&gt;At work we have a service that handles queries from our hundreds of tourism websites and talks to the backend databases when, say, someone searches for Concerts in a particular location or wants to book a Hotel on a particular date. It caches many of the results of these queries for ten or fifteen minutes, which takes a lot of load away from the database servers and greatly reduces the average response times for users of the web sites. It handles a few million requests a day - so it&#39;s hardly Google but it&#39;s also doing enough work to be interesting from a performance point of view.&lt;/p&gt;

&lt;p&gt;The load has been spread over a pair of servers for a few years now, initially for redundancy. However, there was a point at which it became clear that a single server could no longer handle the load. When there were too many concurrent requests, individual requests would take longer to be processed, which resulted in the number of concurrent requests going up and up and the individual request times following suit until requests started timing out. Over time, two servers became four servers and there is concern now that two servers could not reliably handle all of the load.&lt;/p&gt;

&lt;p&gt;On top of this, the memory usage of the service on each of the servers appears to slowly-but-surely increase over time until it gets high enough and, for want of a more technical term, freaks out. The thread count in the service builds and builds as more request are backing up, waiting to be processed. The requests times get longer and longer. Using PerfMon, it looks like several CPU cores are tied up entirely on garbage collection (since we&#39;re using the &quot;server mode&quot; GC configuration, there is a separate managed heap - and a separate collection thread - for each processor). Strangely, at this point, the cores don&#39;t appear to be max&#39;ing out, the average CPU usage for the server is reliatively low, though the &quot;% time in GC&quot; is high. Every few weeks, it seems like one of the servers would need the service restarting on it due to a &quot;memory blow up&quot;.&lt;/p&gt;

&lt;p&gt;The time finally came that we could no longer continue to brush this under the rug - this problem was not going to go away and the occasional &quot;uh-oh, someone is going to have to restart the service again&quot; was no longer acceptable; not only was there a minute or two downtime for the actual service restart, there was also half an hour or so leading up to it during which response times were getting unacceptably long.&lt;/p&gt;

&lt;h3&gt;Blaming the GC&lt;/h3&gt;

&lt;p&gt;It would seem all too easy to blame things on the garbage collector, say that the fault lies there and that there&#39;s nothing we can do about it other than avoiding giving it more load than it can deal with (in other words, throw more servers at the problem). But I recently read &lt;a href=&quot;https://twitter.com/ben_a_adams/status/767174657048993792&quot;&gt;a tweet&lt;/a&gt; that said&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Blaming perf issues on Garbage Collection is like blaming your hangover on your liver... Its the thing that&#39;s saving you from your code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Courtesy of &lt;a href=&quot;https://twitter.com/ben_a_adams/status/767174657048993792&quot;&gt;Ben Adams&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;.. which helped motivate me into trying to find a better solution. On the whole, I&#39;m very grateful that the .NET garbage collector works as well as it does. In the majority of cases, you just don&#39;t have to worry about it. But sometimes you do. Clearly, the data service that I&#39;m talking about is one of those cases.&lt;/p&gt;

&lt;p&gt;The garbage collector uses a range of factors to decide when to collect - some are simple, such as the amount of free memory available in the system (if there&#39;s a lot then there&#39;s less pressure to collect) and the available processor time (if the system is busy doing other work then it would ideal to wait until it&#39;s quieter before throwing GC work on top of the &quot;real work&quot;). Some factors are more complex - for example, if gen 2 collections occur that release zero (or very little) memory then the GC will take this into account and try to collect it less often (since gen 2 collections are the most expensive, it makes sense for the GC to avoid them if possible; if it finds that few references are being released from gen 2 each collections then there&#39;s little point doing the collection work).&lt;/p&gt;

&lt;p&gt;However, there is a limit to how much the GC can deal with things with &lt;a href=&quot;https://en.wikipedia.org/wiki/Clarke%27s_three_laws#Clarke.27s_third_law&quot;&gt;by magic&lt;/a&gt;. Sometimes you need to work &lt;em&gt;with&lt;/em&gt; the garbage collector, rather than just presuming that it will be able to deal with anything you throw at it.&lt;/p&gt;

&lt;p&gt;One way to help is to simply make fewer allocations. The less allocations that are made, the less work that there is for the garbage collector to do.&lt;/p&gt;

&lt;p&gt;Another approach is take on board one of Ben Watson&#39;s key principles for enabling &quot;&lt;a href=&quot;http://www.philosophicalgeek.com/2012/06/04/4-essential-tips-for-high-performance-garbage-collection-on-servers/&quot;&gt;high-performance garbage collection on servers&lt;/a&gt;&quot;, which is:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Objects Live Briefly or Forever&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In order to think about how I can make the GC&#39;s life easier, it&#39;s worth taking a step back and describing a little bit more about what this troublesome service has to do.&lt;/p&gt;

&lt;h3&gt;What the service deals with (and why this might not be GC-friendly)&lt;/h3&gt;

&lt;p&gt;At its core, this service receives requests from websites, gets the required data for that request from an external source or from cache (if from an external source, such as a database, then the results will be cached for subsequent requests), massages the data into the desired form and sends it back to the client. For the majority of the time, the results include only &quot;stubs&quot; of the real data - a unique identifier, the name and its location (latitude, longitude). When the results of a query are cached, such as &quot;get me all of the hotels in Liverpool that are in the city centre and have at least a three star rating, ordered by rating (descending)&quot;, the query and the resulting stubs are cached. The response to the client will include all of those stubs but it will also include full product details for one page of data - if the client says that it wants to show the first page of results to the user and each page shows ten items, then the first ten entries in the result set will be full products and the remaining &quot;n - 10&quot; entries will be stubs. There is a separate service that is responsible for retrieving full product details for given stubs.&lt;/p&gt;

&lt;p&gt;The quickest way that the service may deliver these results is if the query results are stored in cache. In which case, the requests will be dealt with using the following steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The request is deserialised&lt;/li&gt;
&lt;li&gt;Ordered stubs corresponding to the query are retrieved from the &quot;Query Cache&quot;&lt;/li&gt;
&lt;li&gt;Full product details are retrieved for the first page (as specified by the request) of results  - this involves serialising a request for ten unique identifiers, sending it to the external product service and then receiving the details for those products back (which means that there&#39;s a step that involves deserialisation of full product records when the data comes over from the external service)&lt;/li&gt;
&lt;li&gt;The response (which consists of 10 full products and &quot;n - 10&quot; stubs) is serialised to be sent over the wire back to the client&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The core of the service was written in (and has been in use since) 2009, which has a spread of advantages and disadvantages. On the less-good side, it uses .NET remoting (at the time, our servers only had .NET 2.0 installed and so newer technologies such as WCF were out of reach) and much of the serialisation uses the &lt;strong&gt;BinaryFormatter&lt;/strong&gt; (which is unlikely to be anyone&#39;s go-to these days if they are interested in performance). On the other hand, over the years it&#39;s been proven to be largely reliable and it&#39;s been through a few optimisiation drives since the business is so reliant on it. So the places where serialisation performance is most important have had the &lt;strong&gt;BinaryFormatter&lt;/strong&gt; replaced; anywhere that the stubs are serialised/deserialised, for example, uses custom methods to read/write the fixed fields in the stub type. Similarly, the &quot;full product&quot; records are serialised using custom routines (which is a double win when responding to a request since the full product instances must be deserialised when they are received from the external product service and then &lt;em&gt;re-&lt;/em&gt;serialised to be included in the final response to the client, so that&#39;s twice that use of the slow &lt;strong&gt;BinaryFormatter&lt;/strong&gt; is avoided).&lt;/p&gt;

&lt;p&gt;What I&#39;m trying to say here is that any &quot;low hanging fruit&quot; in terms of performance hotspots within the service code had been improved in the past. It genuinely did seem like it was the garbage collector that was responsible for much of the performance problem. (I did use the &lt;a href=&quot;http://www.red-gate.com/products/dotnet-development/ants-performance-profiler/&quot;&gt;ANTS Performance Profiler&lt;/a&gt; on a local installation of the service under load to confirm this but it didn&#39;t reveal anything exciting). So it was firmly in the direction of the garbage collector that I faced.&lt;/p&gt;

&lt;p&gt;I&#39;ve written much of this service&#39;s code, so I&#39;m familiar with its general structure as well as many of the finer details. With this knowledge, I captured a batch* of sample requests and set up a test environment that I could replay these requests against (using &lt;a href=&quot;https://github.com/ProductiveRage/SqlProxyAndReplay&quot;&gt;SqlProxyAndReplay&lt;/a&gt; to remove the database from the equation).&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(The test queries were taken from real web site logs and replayed at the same rate and level of concurrency - so they should be a reasonable approximation of real life load)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The plan being to try to tweak the code that was likely to offend the GC the most and measure after each change to see how it affected the work that the collector had to do. The first candidates were:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The &quot;Query Cache&quot; needs to retrieve from, add to and remove from a structure that will be accessed concurrently be multiple threads. The very first implementation was a dictionary that required a lock for every read or write access. This was changed so that a lock was only required for write actions, which would clone the dictionary and overwrite the internal reference. Read actions wouldn&#39;t require a lock since no dictionary would ever change. However, this clone-for-every-write could mean a lot of churn.&lt;/li&gt;
&lt;li&gt;The custom serialisation uses binary data reader and writer classes. Each individual property value is serialised into a byte array (the &lt;strong&gt;BitConverter&lt;/strong&gt; is used for many types of values and the &lt;strong&gt;UTF8Encoder&lt;/strong&gt; is used for strings) and then these bytes are added to a &lt;strong&gt;List&amp;lt;byte&amp;gt;&lt;/strong&gt; (and the reverse is done to deserialise; sections of the list are extracted into arrays and then translated back into property values). This means that there are a lot of arrays being allocated when serialising or deserialising.&lt;/li&gt;
&lt;li&gt;When serialising/deserialising the full product records, it seems very possible that these records could be over 85,000 bytes of serialised data, which would mean that there would be lots of byte arrays created on the Large Object Heap (where &quot;lots&quot; depends upon how many requests a second are being handled, how many full product records need to be retrieved for the requests and how many of those records were more than 85,000 bytes when serialised). Allocations to the Large Object Heap can be a source of headaches, which I&#39;ll go into in a little more detail later on.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Step 1: Bin the custom &quot;free-reading dictionary&quot;&lt;/h3&gt;

&lt;p&gt;There&#39;s a &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/dd287191(v=vs.110).aspx&quot;&gt;ConcurrentDictionary&lt;/a&gt; in .NET these days, which should improve things when compared to the custom structure we were using. Using it means that read and write actions both lock again but the locks are much more granular (they only affect subsets of the data, rather than there being a single huge lock around the entire reference) and so there is less likely to be contention between operations.&lt;/p&gt;

&lt;p&gt;The batch of test queries were run against this change and the garbage collection frequency performance counters were captured. A few runs were performed and the results averaged and.. er.. annoyingly, I&#39;ve lost my notes relating to this change! There were less collections required for each generation, which was promising. Thankfully I &lt;em&gt;do&lt;/em&gt; have some useful information for the next changes :)&lt;/p&gt;

&lt;h3&gt;Step 2: Bin the custom binary reader and writer classes&lt;/h3&gt;

&lt;p&gt;The .NET library has &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/system.io.binaryreader(v=vs.110).aspx&quot;&gt;BinaryReader&lt;/a&gt; and &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/system.io.binarywriter(v=vs.110).aspx&quot;&gt;BinaryWriter&lt;/a&gt; classes that take a stream and read/write to it in a more efficient manner than the custom reader/writer classes used before (which allocated at least one array for every single property read or write). These aren&#39;t new classes, I just wasn&#39;t aware of them when I wrote the custom versions all that time ago.&lt;/p&gt;

&lt;p&gt;The tests were repeated with this change and, compared to only the Query Cache change, there were on average &lt;strong&gt;56% as many gen 0 collections, 60% as many gen 1 collections and 59% as many gen 2 collections&lt;/strong&gt;.&lt;/p&gt;

&lt;h3&gt;Step 3: Pooling large byte arrays used in serialisation/deserialisation&lt;/h3&gt;

&lt;p&gt;Time to talk about the Large Object Heap. The garbage collector is much happier dealing with &quot;small objects&quot; (which are decided to be those less than 85000 bytes, based upon &quot;a bunch of benchmarks&quot; according to this &lt;a href=&quot;http://stackoverflow.com/a/8953503/3813189&quot;&gt;excellent Stack Overflow answer by Hans Passant&lt;/a&gt;). With small objects, it will allocate them freely and then, after collections, compact the heap for objects that survive the collection. If the heaps are not compacted, then any gaps in between &quot;live&quot; objects (live objects are those that the GC finds to still be in use) could only be used to slot in newly allocated objects if they fit in the gaps. As objects are allocated and then tidied up, it can become more and more difficult to find somewhere to fit new allocations - it might be necessary to look at &lt;em&gt;many&lt;/em&gt; small gaps before finding one that a new object will fit in (this problem is referred to as being caused by fragmentation of the heap). Compacting the heap moves all of the objects so that they&#39;re pushed up together, with no gaps, and is relatively cheap when dealing with small objects since each individual memory operation is cheap. However, copying big chunks of memory around (such as the live objects in the Large Object Heap), which is what would be required to compact the Large Object Heap, is much harder work. Following the same sort of logic (that large objects are more expensive to deal with), the Large Object Heap is only collected during a gen 2 collection.&lt;/p&gt;

&lt;p&gt;If a lot of allocations are made to the Large Object Heap then memory can appear to spiral out of control (because the Large Object Heap is only collected in gen 2 and because it&#39;s not compacted) and the pressure on the GC will increase. Unfortunately, this can be done quite easily when frequently serialising/deserialising to arrays that break the 85,000 byte limit.&lt;/p&gt;

&lt;p&gt;One solution is to &quot;pool&quot; those byte arrays. In other words, to maintain a set of arrays and to reuse them, rather than creating new ones each time (which the GC will have to work hard to tidy up after). It&#39;s not difficult to imagine that this could easily become a very complicated task - whatever is responsible for pooling those arrays would need be thread safe and it would have to apply some sensible logic to when and how to reuse arrays; Should &lt;em&gt;all&lt;/em&gt; arrays be reused? Should only large arrays be reused? Should &lt;em&gt;all&lt;/em&gt; large arrays be reused? Will there be any limits to the pool? What if the limits are exceeded and more arrays are required?&lt;/p&gt;

&lt;p&gt;Interestingly, I read last year about something that might be ideal for the job in the book &lt;a href=&quot;http://www.writinghighperf.net/&quot;&gt;Writing High-Performance .NET Code&lt;/a&gt; (written by Ben Watson, who I quoted earlier - it&#39;s a book I highly recommend, btw). I&#39;m going to lift the overview completely from the blog post &lt;a href=&quot;http://www.philosophicalgeek.com/2015/02/06/announcing-microsoft-io-recycablememorystream/&quot;&gt;Announcing Microsoft.IO.RecycableMemoryStream&lt;/a&gt; (which is a quote lifted from the book) -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In one application that suffered from too many LOH allocations, we discovered that if we pooled a single type of object, we could eliminate 99% of all problems with the LOH. This was MemoryStream, which we used for serialization and transmitting bits over the network. The actual implementation is more complex than just keeping a queue of MemoryStream objects because of the need to avoid fragmentation, but conceptually, that is exactly what it is. Every time a MemoryStream object was disposed, it was put back in the pool for reuse.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That sounds like a very similar use case to what I have. Lots of serialisation/deserialisation for transmitting and receiving data from other servers, with byte arrays large enough to be allocated on the Large Object Heap. All of them being wrapped in &lt;strong&gt;MemoryStream&lt;/strong&gt;s (at least, &lt;strong&gt;MemoryStream&lt;/strong&gt;s were used for serialisation of these large objects after Step 2, above, was implemented).&lt;/p&gt;

&lt;p&gt;So this definitely seemed worth looking into.&lt;/p&gt;

&lt;p&gt;Just to recap precisely why pooling large objects might help; pooling them means keeping hold of them in memory, which seems like the opposite of what we want to do if we want to relieve memory pressure. However, the big benefit is that the Large Object Heap fragmentation will be less of a problem because we&#39;re no longer allocating large objects and then throwing them away and then trying to allocate &lt;em&gt;further&lt;/em&gt; large objects somewhere (such as in a gap that the GC has removed dead objects from or possibly resorting to tacking them on the end of the heap); instead, a &lt;strong&gt;MemoryStream&lt;/strong&gt; (and its large backing array) may be reused after it&#39;s been created once and returned to the pool, so the work to try to find a place to allocate a new large object is not required. This still feels somewhat counterintuitive because it means that there will be more objects that the garbage collector has to consider when it does a gen 2 collection and we&#39;re trying to give the GC as little work as possible - &lt;em&gt;particularly&lt;/em&gt; in gen 2, since collections there are most expensive. This is where the GC&#39;s self-tuning comes in, though. If we&#39;re trying to get towards a position where not many objects make it into gen 2 unless then are going to live forever (as pooled objects do) then the GC will be in a position where it has to evaluate the gen 2 heap but - ideally - find very little to remove. If it consistently finds very little to do then it will reduce the frequency of the gen 2 collections. So, even though it might feel like we&#39;re making the collectors life more difficult by keeping these objects alive on the gen 2 heap, we&#39;re actually making it easier.&lt;/p&gt;

&lt;p&gt;With this change, after running the tests again, there were 61% as many gen 0 collections as after only Step 2, 53% as many gen 1 collections and 45% as many gen 2 collections. This means that Step 2 and Step 3 combined resulted in &lt;strong&gt;34% as many gen 0 collections than after only the changes in Step 1, 32% as many gen 1 collections and 27% as many gen 2&lt;/strong&gt;. This seemed very promising.&lt;/p&gt;

&lt;h3&gt;Testing under increased load&lt;/h3&gt;

&lt;p&gt;The sample data that I&#39;d been using so far wasn&#39;t particularly large, it was around 10k requests that would complete in around ten minutes. This is comparable to the request/sec that the production servers deal with during the day. While each run took place, after the changes made above, the CPU usage averaged around 40% and  the &quot;% time in GC&quot; averaged 2.5%. I had a feeling, though, that it would be while the server was having a really hard time that the original issues would occur. 40% average CPU usage is nowhere near running flat out and that remaining 60% provides a lot of head room for the garbage collector to come and do what it wants whenever it wants.&lt;/p&gt;

&lt;p&gt;So I increased the load and duration. Not massively, but enough that the previous code started to get a little hot under the collar - 100k requests over an hour or so.&lt;/p&gt;

&lt;p&gt;This sample load was run against both the new and the old versions of the service  (where the old version was the code as it was before Steps 1, 2 and 3 from above were applied to it) and the performance metrics compared between the two. On average, the new version required only &lt;strong&gt;84% as much CPU to be used, spent only 30% as much time in the GC, performed 62% as many gen 0 collections, 36% as many gen 1 collections and 22% as many gen 2 collection&lt;/strong&gt;. Things were still looking promising.&lt;/p&gt;

&lt;h3&gt;Testing for the breaking point&lt;/h3&gt;

&lt;p&gt;At this point, it was feeling like a success.&lt;/p&gt;

&lt;p&gt;To stretch things further, though, I thought that I&#39;d see how it responded if I played the requests as fast as I could. In normal operation throughout the day, each server doesn&#39;t have to deal with much more than an average of 12 requests per second. There will be the odd peak of double that, but they tend to be short-lived. There will be busier times of day where the average rate may be more like 16 requests per second, but not usually for more than a few hours. I was only using a single computer to generate load in this case but that was sufficient to create a sustained load of 35-40 requests per second. I figured that if the service would deal with this then we&#39;d be doing great.&lt;/p&gt;

&lt;p&gt;And for about forty minutes, things &lt;em&gt;do&lt;/em&gt; go great. The server is busy, it&#39;s serving a lot (relative to a normal load) of requests, the gen 0 heap peaks and troughs the most, the gen 1 heap blips up and down with less drama, the gen 2 heap makes slower steps up then drops back down then very gently climbs then steps up then is steady then steps up slightly then drops down, carrying on merrily enough.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Gen 2 heap &#39;blow up&#39;&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/Memory Blow Up - Gen 2 Heap.jpg&quot; class=&quot;HalfWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;Until, at some point, the gen 2 heap starts curving up dramatically, followed by many steep steps upward, then a slightly pathetic dip immediately followed by steep steps upward. Having barely hit a gigabyte in size while gently building up and dropping earlier, it&#39;s now got to around 4 gig in a very short space of time. Here, it flatlines. During this steep climb, requests have gotten slower and slower and, at this flatline, they are no longer processed. This state continues for a couple of minutes, after which some work appears to attempt to continue, though the gen 2 heap doesn&#39;t drop in size at all. Some unusual errors are seen in the logs, such as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Timeout expired.  The timeout period elapsed prior to obtaining a connection from the pool.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It&#39;s as if, during this time, &lt;em&gt;everything&lt;/em&gt; within the service stopped. This isn&#39;t a query timeout that occurred because the database server was taking too long, this error suggests that a SqlConnection was requested (with .NET pools internally) and then the world stopped for some time.. after which, the request-for-a-connection gave up since it had been so long since it asked for it.&lt;/p&gt;

&lt;p&gt;I had thought that the point of the GC server mode was to avoid this sort of thing; even if a collection for one heap was taking a long time, each core has its own separate heap (and this server has four cores - it&#39;s not a real server, they&#39;re all virtualised, but that shouldn&#39;t make a huge difference). Could all of the heaps really have got jammed up simultaneously? Hopefully from everything I&#39;ve written above, it&#39;s clear that there are a lot of subtleties to the intricate nature of the garbage collector and so it wouldn&#39;t surprise me if I&#39;d not quite got the whole picture with server mode (or if I was maybe expecting a little too much!).&lt;/p&gt;

&lt;p&gt;Incidentally, after this &quot;flatline period&quot;, as requests appear to (slowly) begin being served again, the gen 2 heap grows to over 5 gig and then another flatline period is entered. This one much longer. So long, in fact, that I gave up waiting for it. Maybe my attention span is a bit short but I think that after more than five minutes of being completely stuck it&#39;s probably not much use even if the service &lt;em&gt;does&lt;/em&gt; start going again.&lt;/p&gt;

&lt;p&gt;The symptoms of this condition sound identical to the occasional &quot;memory blow up&quot; that was seen with the old version of the code on the live servers. It would seem that the changes so far had not provided a magic bullet.&lt;/p&gt;

&lt;h3&gt;Looking for clues&lt;/h3&gt;

&lt;p&gt;&lt;img alt=&quot;GC CPU time during the &#39;blow up&#39;&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/Memory Blow Up - GC CPU.jpg&quot; class=&quot;HalfWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;I wanted some insight into what was going on during these periods of apparent inactivity - well, it seemed like &lt;em&gt;my&lt;/em&gt; code was inactive, though it appeared that the GC was being very busy. The &quot;% time in GC&quot; would spike around during work but seem to get more frenzied in its peaking in the lead up to the gen 2 heap size flat line, then it too would flat line in sympathy. After the first flat line period, it would remain higher but spike up and down, then it would flatline again when the gen 2 heap size flatlined, at a higher level than the time before.&lt;/p&gt;

&lt;p&gt;I initially presumed that there must be something in the requests that caused this behaviour. So, if I skipped the first {whatever} thousand requests then I should be able to get this to happen sooner. Not so - skipping 10k requests still meant that I had to wait the same period of time for the behaviour to present itself. Skipping 20k, the same. If I skipped too many then the requests would complete without blowing up at all.&lt;/p&gt;

&lt;p&gt;My next step was to try to use &lt;a href=&quot;http://www.red-gate.com/products/dotnet-development/ants-memory-profiler/&quot;&gt;ANTS Memory Profiler&lt;/a&gt; and to take a couple of snapshots as the blowout started occurring. Unfortunately, by the time that the gen 2 heap size started climbing sharply, it would quickly get too big for the profiler to snapshot. There&#39;s a hard limit in the software as to how big of a memory dump it will try to process (&quot;for performance reasons&quot;). There&#39;s an option to take less information about each object so that larger dumps may be taken but even enabling that didn&#39;t work. In retrospect, it might have been worth reducing the memory in the virtual box and trying to reproduce the issue then - hopefully ANTS would have been able to deal with it then (everything got stuck when the gen 2 heap reached around four gig out of a total six gig of RAM, if the server only had four gig total then the available memory would be exhausted and the GC would presumably throw a tantrum much earlier, with a much smaller gen 2 heap).&lt;/p&gt;

&lt;p&gt;After that I tried using &lt;a href=&quot;https://blogs.msdn.microsoft.com/dotnet/2012/10/09/improving-your-apps-performance-with-perfview/&quot;&gt;PerfView&lt;/a&gt; since it&#39;s discussed and recommended in the &quot;Writing High-Performance .NET Code&quot; book. I managed to take a snapshot using that, freezing the process while doing so in order to prevent the heaps growing even more (taking the snapshot took almost two hours). When I loaded the dump file into PerfView to analyse, it appeared to show very little information about what types were in use (certainly it didn&#39;t appear to show the long list of types seen in all of the screenshots and tutorial videos about PerfView). There is a small row of information at the top of the heap alloc stack window that shows a summary. This showed 99% unreachable memory. This means that most of the memory is actually ready to be reclaimed by the collector (ie. that its roots are unreachable) and so I presumed that I wouldn&#39;t be able to find out much information about it. I tried finding confirmation for this online but didn&#39;t come up with much when searching for &quot;99% unreachable memory PerfView&quot;. Another regret, looking back, is that I didn&#39;t try a bit harder to unearth information through PerfView. To be completely honest, though, I was losing patience.&lt;/p&gt;

&lt;h3&gt;Giving up and guessing (I prefer to call it intuition)&lt;/h3&gt;

&lt;p&gt;I was frustrated now. I was frustrated with what I was seeing, I was frustrated because I didn&#39;t understand precisely what triggered it and I was frustrated that I couldn&#39;t get any tools to tell me what was going awry. So I thought I&#39;d just take a stab in the dark and see what happened.&lt;/p&gt;

&lt;p&gt;In my defence, it was more sort of an educated guess. It seemed like what the service was asking of the garbage collector was something that the collector would (given enough time) decide it didn&#39;t like. I didn&#39;t feel like it was just allocation churn, my gut* told me that references that were very short lived were not the problem, even if there were a lot of them coming into existence and then disappearing again while the request rate was high. It felt like it was all going to lie with those ten / fifteen minute caches. If the GC likes references to live for very short periods of time or to live &lt;em&gt;forever&lt;/em&gt; then this is the worst case for it. It&#39;s particularly bad since there may be many (ie. 1000s of) sets of cached results in memory at any time and each result set could potentially hold many stubs (again, 1000s).&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(I say &quot;my gut told me&quot; but I think that what that really means is that my sub-conscious, having been stuffed full with a million articles about garbage collection, was just regurgitating information I&#39;d read..)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The logical step, then, would be to move that cache out of process. Maybe Redis, Memcached.. something like that. This would mean that any Query Cache lookup would involve a leap out to another process. Some sort of cache key would have to be generated, any results from the other process would have to be deserialised and then compared against the original search criteria (unless the cache was just a serialised representation of the entire search criteria then there would always be a change of cache key collision, so a single cache key might actually correspond to results from multiple different searches). This seemed like a lot of extra work, compared to just accessing cached references in memory.. &lt;em&gt;but it&#39;s this just-get-bang-it-in-memory approach that has gotten me into trouble in the first place!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;At this point, I was in no way certain that this would solve my problems and so thinking about setting up an external cache service was starting to feel like an exercise in &lt;a href=&quot;http://sethgodin.typepad.com/seths_blog/2005/03/dont_shave_that.html&quot;&gt;yak shaving&lt;/a&gt;. So I went for the simplest alternative, I implemented a disk cache layer. If I was going to use an external cache then I&#39;d still need a way to serialise the data that would need caching (so that I could send and receive it over the wire) and I&#39;d still need a way to generate cache keys from the search criteria (by hashing the options, basically). I would also have to do that if I was going to just stash the cache values on disk. There would be a few minor complications with a disk cache rather than an off-the-shelf external cache (such as ensuring that old cache files are deleted if they&#39;re not accessed again within a reasonable amount of time) but most of the work to implement a disk cache would come in handy if the hypothesis was proved and a general purpose out-of-process cache for these ten-to-fifteen-minute cache items seemed to help.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Just in case it&#39;s not completely obvious why a disk cache might work here, it&#39;s because the data isn&#39;t stored in memory for long periods of time any more - any time that the cached data is read from disk into memory, the in-memory representation only lives for the live of the request that the cached data is helping with - it then is free to be collected, meaning that it should never get out of gen 0).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So I changed the Query Cache so that it didn&#39;t maintain a &lt;strong&gt;ConcurrentDictionary&lt;/strong&gt; of data (meaning, unfortunately, that the work I did for &quot;Step 1&quot; earlier was a waste of time) and, instead, had a simple &lt;strong&gt;ICache&lt;/strong&gt; dependency injected into it. Simple in that it would only have options to read or write serialised data (as byte arrays) for particular keys - the deserialisation and subsequent checking of an &quot;ExpiresAt&quot; time would be handled within the Query Cache class. The &lt;strong&gt;ICache&lt;/strong&gt; implementation read and wrote files on disk, mapping the cache keys onto file names and running a single background thread to tidy up old files that hadn&#39;t been touched for a while. Writing an alternative &lt;strong&gt;ICache&lt;/strong&gt; implementation to talk to Redis would be very easy.&lt;/p&gt;

&lt;p&gt;With this change, I was able to run the entire 100k request sample without issue. In fact, the service has been updated in production using this disk cache. While there are some challenges and compromises with a disk cache*, it&#39;s working &lt;em&gt;well enough&lt;/em&gt; for now that we&#39;re going to leave it be. If it seems like, in the future, that the overhead of persisting to disk is a bottleneck and that a dedicated external cache could significantly improve the performance of individual requests or the overall throughput of the system, then we may change to using one. However, right now, that would just be one more moving part. The advantage of the disk cache is that it&#39;s very simple.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(File IO of this type will suffer contention issues but this is a read-only service and so the worst case is  that some database hits that could theoretically have been avoided are processed; if a request comes in whose results are not available in cache then it will get the data live and then try to write to a cache file - if another request comes in whose search criteria gets hashed to the same key then it won&#39;t be possible to read the data for that key while the writing from the first request is taking place)&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;In conclusion&lt;/h3&gt;

&lt;p&gt;It has now been a couple of weeks that this code has been in production. Over that time, all of the gen 0, 1 and 2 Small Object Heaps have appeared to breathe in and out in a healthy fashion, as has the Large Object Heap. There has been no indication of the slow-memory-usage-climb-to-oblivion that would be seen before.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;GC Memory Graph&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/GC Memory Graph.png&quot; class=&quot;HalfWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;The experience has been very interesting for me, it&#39;s given me a chance to expand my understanding of the garbage collector and to apply what I already knew about it. It would have been the icing on the cake to find out more about just what was happening in the process when it was having one of its &quot;blow ups&quot;, but I&#39;m more glad that it doesn&#39;t look likely to happen again than I am curious as to what was in its mind at the time! It&#39;s given me a fresh appreciation of the garbage collector and it&#39;s served as a reminder that it really is my buddy and not my enemy.&lt;/p&gt;

&lt;p&gt;It&#39;s also gratifying that this service continues to get the love it needs to grow and develop. It doesn&#39;t seem to be particularly uncommon for code to be written that doesn&#39;t expect to be in use more than two years in the future (sometimes simply because a project is released and &quot;handed off&quot; to a client, never to be maintained or updated again - necessitating its replacement in the not-too-distant-future as the real world moves further and further away from what the original solution is able to do).&lt;/p&gt;

&lt;p&gt;I wrote such a large portion of the service code myself that I have to bear the blame for the bad bits as well as the glory for the successes. Those custom non-locking-for-read-but-fully-cloning-for-write dictionaries (replaced in &quot;Step 1&quot; with the more modern &lt;strong&gt;ConcurrentDictionary&lt;/strong&gt;) were my idea and implementation and seemed fanstastic at the time - but I&#39;m not upset in the slightest to have seen the back of them now! It&#39;s a great opoortunity to look back over the years and see not only how technology has moved on since then but also my own knowledge. I very much intend to see it continuing!&lt;/p&gt;
</description>
			<pubDate>Wed, 21 Sep 2016 20:12:00 GMT</pubDate>
		</item>
		<item>
			<title>Performance tuning a Bridge.NET / React app</title>
            <link>http://www.productiverage.com/performance-tuning-a-bridgenet-react-app</link>
			<guid>http://www.productiverage.com/performance-tuning-a-bridgenet-react-app</guid>
			<description>&lt;p&gt;On the whole, React is fast. And, on the whole, writing a web application&#39;s code in C# using &lt;a href=&quot;http://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt; has little overhead compared to writing it directly in JavaScript since Bridge generates sensible JavaScript.&lt;/p&gt;

&lt;p&gt;However, I recently wanted to convince myself that performance would not be an issue with the sort of projects that we&#39;ll be writing at work. We have some applications that are key to the business and yet have unfortunately been left to wither into a barely-maintinable state. The plan is to, over time, rewrite sections of the application using Bridge and React so that the application continues to work at all times but the old code is pruned away. This means that we need to be sure that any crazy forms that existed in the old codebase will work fine in the new architecture. In particular, there is a configuration page that allows a user to select options from a list of almost 1,000 checkboxes. Is this good UI? Most probably not. Do we need to be able to support such configurations in the future? Unfortunately, most probably yes. With a classic server-based MVC application, this would involve 1,000 checkboxes being rendered on the page and then a ginormous form post to send the changes back when the user clicks Save. In a React app, this sort of form will require virtual re-renders each time that a checkbox is clicked on.&lt;/p&gt;

&lt;p&gt;I thought I&#39;d actually go with something slightly more demanding - 5,000 rows on a form where each row has two text boxes and a checkbox. If this can be handled easily then the worst case scenario that we have in mind for our rewrites (1,000 checkboxes) will be a walk in the park.&lt;/p&gt;

&lt;p&gt;So I whipped up a sample app and started using the Chrome profiler.. and the news was not good.&lt;/p&gt;

&lt;p&gt;The total time recorded by the profiler was 838ms to deal with the changing of a single checkbox. It&#39;s said that &lt;a href=&quot;https://www.nngroup.com/articles/response-times-3-important-limits/&quot;&gt;100ms is &quot;the limit for having the user feel that the system is reacting instantaneously&quot;&lt;/a&gt; and 838ms is not just in the same ballpark. What&#39;s even worse is that this delay is experienced not only when a checkbox state is changed but also when any change is applied to one of the text boxes. Waiting almost a second for a checkbox to change is bad but waiting that long for each key press to be registered while typing is unbearable.&lt;/p&gt;

&lt;h3&gt;Examining the test app&lt;/h3&gt;

&lt;p&gt;The test app is fairly simple (and will contain no surprises if you&#39;ve read my &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;Writing React apps using Bridge.NET - The Dan Way&lt;/a&gt; three part mini-series). However, the performance improvements that I&#39;m going to cover will be in versions of libraries that I haven&#39;t yet released - namely, &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.React&quot;&gt;Bridge.React&lt;/a&gt;, &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt; and &lt;a href=&quot;https://github.com/ProductiveRage/Bridge.Immutable.Extensions&quot;&gt;ProductiveRage.Immutable.Extensions&lt;/a&gt;. The ProductiveRage.Immutable.Extensions library includes types that I commonly use when writing Bridge / React apps (such as &lt;strong&gt;RequestId&lt;/strong&gt; and &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;). So you won&#39;t yet be able to try out the changes that I&#39;m going to discuss but (hopefully!) the process of identifying what changes to make will be useful.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(I&#39;m planning to release the updates to these libraries around the time that Bridge 15.0 comes out, which should hopefully be this month - this will include the change to using Roslyn for parsing the C#, rather than NRefactory, and so C# 6 syntax will finally be supported, which is wonderful news).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;One of the types that will be available in ProductiveRage.Immutable.Extensions is &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt;. It&#39;s extremely common for component classes to require the same sort of information - what the initial state is, how to record requests to change that state, what class name to apply to the component, whether it should be in a disabled state or not and what key the component has (for cases where it appears as part of a set of dynamic child components).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class CommonProps&amp;lt;T&amp;gt; : IAmImmutable
{
    public CommonProps(
        T state,
        Action&amp;lt;T&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled,
        Optional&amp;lt;Any&amp;lt;string, int&amp;gt;&amp;gt; key)
    {
        this.CtorSet(_ =&amp;gt; _.State, state);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
        this.CtorSet(_ =&amp;gt; _.Key, key);
    }

    public T State { get; private set; }
    public Action&amp;lt;T&amp;gt; OnChange { get; private set; }
    public Optional&amp;lt;ClassName&amp;gt; ClassName { get; private set; }
    public bool Disabled { get; private set; }
    public Optional&amp;lt;Any&amp;lt;string, int&amp;gt;&amp;gt; Key { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have a custom text box component then you want to be able to set the initial text value and to be informed when the user is performing an action that changes the text value. If you have a row in a table that shows a message (such as in the application built up in the three part series) then each row needs to have state describing what to show in the &quot;Content&quot; text box and what to show in the &quot;Author&quot; text box. When the user tries to change of those values, the row needs to have a way to say that the current message state is changing. As a final example, if there is a Message table component then the initial state will be a set of messages to render and the &quot;OnChange&quot; delegate will be used whenever a user wants to change a value in an existing row or when they want to remove a row or when they want to add a row. So it&#39;s a very common pattern and having a generic class to describe it means that there&#39;s less code to write for each component, since they can use this common class rather than each component having their &lt;em&gt;own&lt;/em&gt; props class.&lt;/p&gt;

&lt;p&gt;There are some static factory methods to make initialising &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; instances easier:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class CommonProps
{
    public static CommonProps&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(
        T state,
        Action&amp;lt;T&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled)
    {
        return new CommonProps&amp;lt;T&amp;gt;(
            state,
            onChange,
            className,
            disabled,
            Optional&amp;lt;Any&amp;lt;string, int&amp;gt;&amp;gt;.Missing
        );
    }

    public static CommonProps&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(
        T state,
        Action&amp;lt;T&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled)
        Any&amp;lt;string, int&amp;gt; key)
    {
        return new CommonProps&amp;lt;T&amp;gt;(state, onChange, className, disabled, key);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that in mind, the code below should be easy to understand. For simplicity, state changes are handled directly by the container component (there is no Dispatcher) and all that the app does is render 5,000 rows and allow the user to change either text box in each row or the checkbox that each row has. It might seem like a lot of code but that&#39;s partly due to the way that the lines are wrapped to fit in the blog post and it&#39;s partly because I&#39;ve included &lt;em&gt;all&lt;/em&gt; of the non-shared-library code from the app, which is important so that we can talk about what is and isn&#39;t worth altering.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class App
{
    [Ready]
    public static void Main()
    {
        React.Render(
            new AppContainer(),
            Document.GetElementById(&quot;main&quot;)
        );
    }
}

public sealed class AppContainer : Component&amp;lt;object, AppContainer.State&amp;gt;
{
    public AppContainer() : base(null) { }

    protected override State GetInitialState()
    {
        return new State(
            Enumerable.Range(1, 5000)
                .Select(i =&amp;gt; Saved.For(
                    i.ToString(),
                    new MessageEditState(&quot;Title&quot; + i, &quot;Content&quot; + i, isAwesome: false)))
                .ToSet()
        );
    }

    public override ReactElement Render()
    {
        return DOM.Div(
            new Attributes { ClassName = &quot;wrapper&quot; },
            new MessageTable(
                state.Messages,
                updatedMessages =&amp;gt; SetState(new State(updatedMessages)),
                className: new ClassName(&quot;messages&quot;),
                disabled: false
            )
        );
    }

    public sealed class State : IAmImmutable
    {
        public State(Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt; messages)
        {
            this.CtorSet(_ =&amp;gt; _.Messages, messages);
        }

        public Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt; Messages { get; private set; }
    }
}

public sealed class Saved&amp;lt;T&amp;gt; : IAmImmutable
{
    public Saved(string id, T value)
    {
        this.CtorSet(_ =&amp;gt; _.Id, id);
        this.CtorSet(_ =&amp;gt; _.Value, value);
    }

    public string Id { get; private set; }
    public T Value { get; private set; }
}

public static class Saved
{
    public static Saved&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(string id, T value)
    {
        return new Saved&amp;lt;T&amp;gt;(id, value);
    }
}

public sealed class MessageEditState : IAmImmutable
{
    public MessageEditState(string title, string content, bool isAwesome)
    {
        this.CtorSet(_ =&amp;gt; _.Title, title);
        this.CtorSet(_ =&amp;gt; _.Content, content);
        this.CtorSet(_ =&amp;gt; _.IsAwesome, isAwesome);
    }

    public string Title { get; private set; }
    public string Content { get; private set; }
    public bool IsAwesome { get; private set; }
}

public sealed class MessageTable : PureComponent&amp;lt;CommonProps&amp;lt;Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt;&amp;gt;&amp;gt;
{
    public MessageTable(
        Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt; state,
        Action&amp;lt;Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt;&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled)
            : base(CommonProps.For(state, onChange, className, disabled)) { }

    public override ReactElement Render()
    {
        return DOM.Div(
            new Attributes { ClassName = props.ClassName.ToNullableString() },
            props.State.Select((savedMessage, index) =&amp;gt; new MessageRow(
                savedMessage.Value,
                updatedMessage =&amp;gt; props.OnChange(
                    props.State.SetValue(index, props.State[index].With(_ =&amp;gt; _.Value, updatedMessage))
                ),
                className: null,
                disabled: false,
                key: savedMessage.Id
            ))
        );
    }
}

public sealed class MessageRow : PureComponent&amp;lt;CommonProps&amp;lt;MessageEditState&amp;gt;&amp;gt;
{
    public MessageRow(
        MessageEditState state,
        Action&amp;lt;MessageEditState&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled,
        Any&amp;lt;string, int&amp;gt; key)
            : base(CommonProps.For(state, onChange, className, disabled, key)) { }

    public override ReactElement Render()
    {
        return DOM.Div(new Attributes { ClassName = props.ClassName.ToNullableString() },
            props.TextBoxFor(_ =&amp;gt; _.Title, &quot;title&quot;),
            props.TextBoxFor(_ =&amp;gt; _.Content, &quot;content&quot;),
            props.CheckboxFor(_ =&amp;gt; _.IsAwesome, &quot;is-awesome&quot;)
        );
    }
}

public static class CommonPropsRenderer
{
    public static ReactElement TextBoxFor&amp;lt;T&amp;gt;(
        this CommonProps&amp;lt;T&amp;gt; props,
        [PropertyIdentifier]Func&amp;lt;T, string&amp;gt; propertyIdentifier,
        string className)
            where T : IAmImmutable
    {
        if (props == null)
            throw new ArgumentNullException(&quot;props&quot;);
        if (propertyIdentifier == null)
            throw new ArgumentNullException(&quot;propertyIdentifier&quot;);

        return DOM.Input(new InputAttributes
        {
            ClassName = className,
            Value = propertyIdentifier(props.State),
            OnChange = e =&amp;gt; props.OnChange(props.State.With(propertyIdentifier, e.CurrentTarget.Value))
        });
    }

    public static ReactElement CheckboxFor&amp;lt;T&amp;gt;(
        this CommonProps&amp;lt;T&amp;gt; props,
        [PropertyIdentifier]Func&amp;lt;T, bool&amp;gt; propertyIdentifier,
        string className)
            where T : IAmImmutable
    {
        if (props == null)
            throw new ArgumentNullException(&quot;props&quot;);
        if (propertyIdentifier == null)
            throw new ArgumentNullException(&quot;propertyIdentifier&quot;);

        return DOM.Input(new InputAttributes
        {
            Type = InputType.Checkbox,
            ClassName = className,
            Checked = propertyIdentifier(props.State),
            OnChange = e =&amp;gt; props.OnChange(props.State.With(propertyIdentifier, e.CurrentTarget.Checked))
        });
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Except for the top-level &lt;strong&gt;AppContainer&lt;/strong&gt;, every component is derived from &lt;strong&gt;PureComponent&amp;lt;T&amp;gt;&lt;/strong&gt; which means that they automatically get implementations for React&#39;s &quot;&lt;a href=&quot;https://facebook.github.io/react/docs/component-specs.html#updating-shouldcomponentupdate&quot;&gt;shouldComponentUpdate&lt;/a&gt;&quot; component life cycle method. This means that if a component needs to be re-rendered by the virtual DOM and if the new props settings are the same as its current props settings then the component will tell React &quot;I&#39;m not going to change, you do not need to re-render me (nor any of my child components)&quot;. I had originally hoped that this would mean that everything would be blazing fast without any additional work. However, as I&#39;ve already said, this was not to be the case.&lt;/p&gt;

&lt;p&gt;Before I get stuck in, it&#39;s worth bearing in mind that this really is a &lt;em&gt;worst case&lt;/em&gt; scenario. If there was a page that required 5,000 entry rows spread over ten different tables then changing any single row would only require the containing table to re-render, the other nine would not need to (the &lt;strong&gt;PureComponent&amp;lt;T&amp;gt;&lt;/strong&gt;&#39;s &quot;shouldComponentUpdate&quot; logic would take take of that). The difficulty here is that all 5,000 rows are in a &lt;em&gt;single&lt;/em&gt; table and so changing any value in any row requires that the table potentially re-render all of its rows. I can&#39;t imagine very many UIs where presenting a user with so many rows simultaneously would be a particularly pleasant experience. Perhaps a spreadsheet of some sort? If you needed to present an interface with tens of thousands of inputs, there are ways to make it faster sucher as &quot;chunking up&quot; groups of rows (so that a change to any single row only requires the other rows in the group potentially to re-render and not any other group). A more complicated (but highly efficient) approach would be to work out what data is currently visible in the browser window and to only update that.&lt;/p&gt;

&lt;p&gt;Rather than considering these alternatives at this point, though, I want to see what we can do with the sample app as it&#39;s presented.&lt;/p&gt;

&lt;h3&gt;Profiling&lt;/h3&gt;

&lt;p&gt;&lt;img alt=&quot;Initial timings (not good)&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/BridgeReactProfiling1.png&quot; class=&quot;NoBorder HalfWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;The first thing to do was to start measuring and digging. I loaded the page in Chrome, opened the dev tools, went to the Profiles tab, clicked &quot;Start CPU profiling&quot;, clicked a checkbox and then &quot;Stop CPU profiling&quot;. The result is shown here. There is a natural split between two processes - the &quot;Render&quot; method of the &lt;strong&gt;MessageTable&lt;/strong&gt; and the &quot;receiveComponent&quot; / &quot;updateComponent&quot; within React. I know that it&#39;s the &lt;strong&gt;MessageTable&lt;/strong&gt;&#39;s Render method because it calls &quot;select&quot; (the LINQ function) and that will be where the &lt;strong&gt;MessageTable&lt;/strong&gt; creates each &lt;strong&gt;MessageRow&lt;/strong&gt;. I&#39;m going to concentrate there first since that&#39;s where most of the time is taken and it&#39;s also what I have the most direct control over.&lt;/p&gt;

&lt;p&gt;Just one thing to check first, though - I&#39;m using the development build of the React library at this point, which has some overhead compared to the production version (since it performs more checks and does more work in order to provide more helpful warnings, where required). Changing to the production build trims some time off; the &lt;strong&gt;MessageTable&lt;/strong&gt; &quot;Render&quot; method still takes 609ms but &quot;receiveComponent&quot; takes about half as much time, now 128ms. Clearly, the production build is not going to magically solve all of my problems.&lt;/p&gt;

&lt;p&gt;The Chrome dev tools allow you to zoom in on sections of the profiler results, so I tried to make sense of what I could see under the &quot;Render&quot; side. The problem was that it seemed like there were lots of nested calls where none were individually very expensive, it seemed like a cumulative problem with just how many components there were. There were a lot of calls to &quot;constructor&quot;, which suggested to me that there may be some overhead in creating Bridge classes. To try to test this theory, I added a new option to the React bindings to enable components to be created by providing a static function rather than creating a component class that is derived from &lt;strong&gt;Component&amp;lt;TProps, TState&amp;gt;&lt;/strong&gt; or &lt;strong&gt;PureComponent&amp;lt;TProps&amp;gt;&lt;/strong&gt;. This allows &lt;strong&gt;MessageRow&lt;/strong&gt; to be rewritten as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class MessageRow
{
    [Name(&quot;MessageRow&quot;)]
    public static ReactElement Render(CommonProps&amp;lt;MessageEditState&amp;gt; props)
    {
        return DOM.Div(new Attributes { ClassName = props.ClassName.ToNullableString() },
            props.TextBoxFor(_ =&amp;gt; _.Title, &quot;title&quot;),
            props.TextBoxFor(_ =&amp;gt; _.Content, &quot;content&quot;),
            props.CheckboxFor(_ =&amp;gt; _.IsAwesome, &quot;is-awesome&quot;)
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which requires &lt;strong&gt;MessageTable&lt;/strong&gt; to be changed to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class MessageTable : PureComponent&amp;lt;CommonProps&amp;lt;Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt;&amp;gt;&amp;gt;
{
    public MessageTable(
        Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt; state,
        Action&amp;lt;Set&amp;lt;Saved&amp;lt;MessageEditState&amp;gt;&amp;gt;&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled)
            : base(CommonProps.For(state, onChange, className, disabled)) { }

    public override ReactElement Render()
    {
        return DOM.Div(
            new Attributes { ClassName = props.ClassName.ToNullableString() },
            props.State.Select((savedMessage, index) =&amp;gt; StaticComponent.Pure(
                MessageRow.Render,
                CommonProps.For(
                    savedMessage.Value,
                    updatedMessage =&amp;gt; props.OnChange(
                        props.State.SetValue(index, props.State[index].With(_ =&amp;gt; _.Value, updatedMessage))
                    ),
                    className: null,
                    disabled: false,
                    key: savedMessage.Id
                )
            ))
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This way, there are 5,000 &lt;strong&gt;MessageRow&lt;/strong&gt; constructor calls saved each time that the &lt;strong&gt;MessageTable&lt;/strong&gt; needs to re-render. (Under the hood, there is still an object created for each row but it&#39;s a very lightweight JavaScript object).&lt;/p&gt;

&lt;p&gt;This reduced the &quot;Render&quot; time to 496ms (it didn&#39;t affect &quot;receiveComponent&quot;, but I didn&#39;t expect it to). This was a good start and made me want to look further into the cost of class instantiation in Bridge.&lt;/p&gt;

&lt;h3&gt;Bridge generic classes are more expensive&lt;/h3&gt;

&lt;p&gt;I whipped up a quick test to try creating lots of instances of a class, like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class App
{
    [Ready]
    public static void Main()
    {
        var x = new MyClass[10000];
        var timer = Stopwatch.StartNew();
        for (var i = 0; i &amp;lt; x.Length; i++)
            x[i] = new MyClass(&quot;test&quot;);
        timer.Stop();
        Console.WriteLine(timer.ElapsedMilliseconds + &quot;ms&quot;);
    }
}

public class MyClass
{
    public MyClass(string value)
    {
        Value = value;
    }
    public string Value { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That only reported 3ms, which didn&#39;t seem like it could be the source of the problem.&lt;/p&gt;

&lt;p&gt;Next I tried going one step more complicated. The &lt;strong&gt;MessageRow&lt;/strong&gt; class that I&#39;ve replaced with a static function was derived from &lt;strong&gt;PureComponent&amp;lt;T&amp;gt;&lt;/strong&gt;, which means that each &lt;strong&gt;MessageRow&lt;/strong&gt; instantiation also involved an instantiation of a generic base class. Clearly &lt;em&gt;something&lt;/em&gt; is still taking up a lot time.. since the &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; class used for &lt;strong&gt;MessageRow&lt;/strong&gt; props was a generic type, maybe it&#39;s something specifically to  do with generic types.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class App
{
    [Ready]
    public static void Main()
    {
        var x = new MyClass&amp;lt;string&amp;gt;[10000];
        var timer = Stopwatch.StartNew();
        for (var i = 0; i &amp;lt; x.Length; i++)
            x[i] = new MyClass&amp;lt;string&amp;gt;(&quot;test&quot;);
        timer.Stop();
        Console.WriteLine(timer.ElapsedMilliseconds + &quot;ms&quot;);
    }
}

public class MyClass&amp;lt;T&amp;gt;
{
    public MyClass(T value)
    {
        Value = value;
    }
    public T Value { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This time it reported 35ms. Still not an earth-shattering duration in isolation but a big step up from the non-generic class&#39; 3ms.&lt;/p&gt;

&lt;p&gt;One of the nice things about Bridge is that it allows you to tweak the way that the JavaScript is generated. By default, it will strike a good balance between creating reasonable JavaScript while also creating code that is faithful to the C# representation. For example, the &lt;strong&gt;MyClass&amp;lt;T&amp;gt;&lt;/strong&gt; class will get the following JavaScript definition:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Bridge.define(&#39;Demo.MyClass$1&#39;, function (T) { return {
    config: {
        properties: {
            Value: Bridge.getDefaultValue(T)
        }
    },
    constructor: function (value) {
        this.setValue(value);
    }
}; });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&#39;s important that the type param &quot;T&quot; be available as a reference at runtime in case you ever need to access it (such as via a call to &quot;default(T)&quot; or when needing to instantiate another generic type whose type param will also be &quot;T&quot;). If the type &quot;T&quot; was not known to the runtime then it wouldn&#39;t be possible for the JavaScript code to do things like create a &quot;default(T)&quot; value appropriate to whatever &quot;T&quot; is; it should be null for a reference type, zero for a numeric type and false for a boolean.&lt;/p&gt;

&lt;p&gt;However, this creation of a class that encapsulates the type parameters must incur some overhead. For comparison, the non-generic class is defined in JavaScript with the following (note the lack of the function that captures &quot;T&quot;) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Bridge.define(&#39;Demo.MyClass&#39;, {
    config: {
        properties: {
            Value: null
        }
    },
    constructor: function (value) {
        this.setValue(value);
    }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One of the options that Bridge has to affect what JavaScript is emitted is the [IgnoreGeneric] attribute. If this is applied to a class then it &lt;em&gt;won&#39;t&lt;/em&gt; be given a JavaScript definition that includes the type parameter. This means that we can create a generic C# class (and continue to fully take advantage of the safety of the C# type system) but have Bridge generate a cheaper-to-instantiate JavaScript representation.&lt;/p&gt;

&lt;p&gt;There is one problem with this, though. The C# code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[IgnoreGeneric]
public class MyClass&amp;lt;T&amp;gt;
{
    public MyClass(T value)
    {
        Value = value;
    }
    public T Value { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will result in the following JavaScript:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Bridge.define(&#39;Demo.MyClass$1&#39;, {
    config: {
        properties: {
            Value: Bridge.getDefaultValue(T)
        }
    },
    constructor: function (value) {
        this.setValue(value);
    }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All properties are set to default values before any instances are created. This is important for cases where there are constructors where one or more properties are not explicitly set since they can&#39;t be left undefined. In C#, if you don&#39;t set a property on a class instance then it will be left as its default value (null for a reference type, zero for a number, etc..) and Bridge has to maintain this behaviour in JavaScript in order to be consistent. The problem here is that the type &quot;T&quot; is not available and so the &quot;Value&quot; property &lt;em&gt;can&#39;t&lt;/em&gt; reliably be set to the correct default value.&lt;/p&gt;

&lt;p&gt;Since I&#39;m considering tweaking the &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; class, this doesn&#39;t apply - every property will explicitly be set in the constructor and so I don&#39;t have to worry about the case of a property needing to be left with the default value for the type.&lt;/p&gt;

&lt;p&gt;Thankfully, Bridge has &lt;em&gt;another&lt;/em&gt; way to control the JavaScript that will be helpful. The [Template] attribute may be applied to property getters and setters and will change how these are represented. The default is for &quot;setValue(x)&quot; and &quot;getValue()&quot; methods to be created on the class (this may be seen in the above code, where &quot;this.setValue(value)&quot; is called in the constructor). If the getter is marked with [Template(&quot;value&quot;)] then anywhere that would previously have called &quot;getValue()&quot; will now simply access &quot;value&quot; and if the setter is marked with [Template(&quot;this.value&quot;)] then the property-setting (which only happens in the constructor for &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt;) will not be a call to &quot;setValue&quot;, it will simply set &quot;this.value&quot;.&lt;/p&gt;

&lt;p&gt;To apply this to the &lt;strong&gt;MyClass&amp;lt;T&amp;gt;&lt;/strong&gt; class, the following C#:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[IgnoreGeneric]
public class MyClass&amp;lt;T&amp;gt;
{
    public MyClass(T value)
    {
        Value = value;
    }
    public T Value { [Template(&quot;value&quot;)]get; [Template(&quot;this.value&quot;)]private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;would result in the following JavaScript:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Bridge.define(&#39;Demo.MyClass$1&#39;, {
    constructor: function (value) {
        this.value = value;
    }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the set-properties-to-default-values code is no longer present in the JavaScript class definition.&lt;/p&gt;

&lt;p&gt;Also, it&#39;s worth noting that this will affect anywhere that the property is accessed by code outside of the class. For example, if there is C# like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var x = new MyClass&amp;lt;string&amp;gt;(&quot;test&quot;);
Console.WriteLine(x.Value);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then, instead of the property being accessed through a getter method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var x = new Demo.MyClass$1(&quot;test&quot;);
Bridge.Console.log(x.getValue());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. it will be accessed directly -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var x = new Demo.MyClass$1(&quot;test&quot;);
Bridge.Console.log(x.value);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This means that the JavaScript is a slightly less faithful representation of the C# code. However, the C# compiler is complete unaware of these changes and it will continue to enforce the type system in the same way that it always does. So (presuming you are writing all of your front end code in C#, using Bridge) you are not losing anything. In fact, there will be some more performance gains to be had by accessing properties directly like this - there is a small overhead to calling functions to return values (small, but not zero) as opposed to retrieving them directly.&lt;/p&gt;

&lt;p&gt;If this is applied to &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; then we get the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[IgnoreGeneric]
public sealed class CommonProps&amp;lt;T&amp;gt;
{
    public CommonProps(
        T state,
        Action&amp;lt;T&amp;gt; onChange,
        Optional&amp;lt;ClassName&amp;gt; className,
        bool disabled,
        Optional&amp;lt;Any&amp;lt;string, int&amp;gt;&amp;gt; key)
    {
        if (state == null)
            throw new ArgumentNullException(&quot;state&quot;);
        if (onChange == null)
            throw new ArgumentNullException(&quot;onChange&quot;);

        State = state;
        OnChange = onChange;
        ClassName = className;
        Disabled = disabled;
        Key = key;
    }

    public T State
    {
        [Template(&quot;state&quot;)]get; [Template(&quot;this.state&quot;)]private set;
    }
    public Action&amp;lt;T&amp;gt; OnChange
    {
        [Template(&quot;onChange&quot;)]get; [Template(&quot;this.onChange&quot;)]private set;
    }
    public Optional&amp;lt;ClassName&amp;gt; ClassName
    {
        [Template(&quot;className&quot;)]get; [Template(&quot;this.className&quot;)]private set;
    }
    public bool Disabled
    {
        [Template(&quot;disabled&quot;)]get; [Template(&quot;this.disabled&quot;)]private set;
    }
    public Optional&amp;lt;Any&amp;lt;string, int&amp;gt;&amp;gt; Key
    {
        [Template(&quot;key&quot;)]get; [Template(&quot;this.key&quot;)]private set; 
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to do this, &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; could no longer be an &lt;strong&gt;IAmImmutable&lt;/strong&gt; type since the &quot;CtorSet&quot; and &quot;With&quot; methods won&#39;t work with properties that rely upon any fancy shenanigans like [Template]. This isn&#39;t a huge deal with the props on components since they are always created fresh for every render, unlike the other data types that represent state. For example, when the title value of a single row is edited, a new &lt;strong&gt;MessageEditState&lt;/strong&gt; instance is created using something like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;newMessage = currentMessage.With(_ =&amp;gt; _.Title, newTitle)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is important for two reasons. Firstly, if &quot;newTitle&quot; is the same as the current title (which can happen if the user does something to a text box that doesn&#39;t actually change ft&#39;s value - such as paste a value into the box that is the same as the current value; React will identfy this as an input change even though the value hasn&#39;t actually been altered) then a new message instance is &lt;em&gt;not&lt;/em&gt; created. When the &lt;strong&gt;MessageRow&lt;/strong&gt; is re-rendered, because the &lt;strong&gt;MessageEditState&lt;/strong&gt; reference won&#39;t have changed, the &lt;strong&gt;PureComponent&lt;/strong&gt; logic will tell React that there is no need to re-render the row, which saves React some work. Secondly, it&#39;s very convenient to be able to get a new instance of a data type with a single property changed in this manner - otherwise you would have to deal with the has-this-value-really-changed logic and either define &quot;With{x}&quot; methods for each individual property or call the constructor with the value that has changed &lt;em&gt;and&lt;/em&gt; all of the ones that haven&#39;t. Which gets old very quickly. (You &lt;em&gt;could&lt;/em&gt; use mutable data types but then you wouldn&#39;t be able perform inexpensive reference equality checks when trying to determine whether a component needs to re-render and so you end up contemplating expensive deep equality checks or you give up on implementing &quot;shouldComponentUpdate&quot; and force React to do much more work).&lt;/p&gt;

&lt;p&gt;One final note: the CtorSet method that &lt;strong&gt;IAmImmutable&lt;/strong&gt; types can use ensures that no value is ever null (if you have a property that may or may not have a value then use the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; type - which can never be null itself since it&#39;s a struct). Since &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; isn&#39;t using CtorSet any more, the constructor needs to include explicit checks for null &quot;state&quot; and &quot;onChange&quot; constructor arguments.&lt;/p&gt;

&lt;p&gt;With this change to &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt;, the &quot;Render&quot; time is now 124ms in the React development build. Interestingly, in the React production, the &quot;Render&quot; time is reduced to 69ms and the &quot;receiveComponent&quot; drops to 98ms. A combined 167ms is much better than the original 838ms.&lt;/p&gt;

&lt;p&gt;With these improvements, there is only a slightly perceptible delay felt when clicking a checkbox. Unfortunately, though, trying to type into a text box when there is a 167ms delay between key presses being recognised is not pleasant. So it&#39;s back to the profiler..&lt;/p&gt;

&lt;h3&gt;Optional&amp;lt;T&amp;gt;&lt;/h3&gt;

&lt;p&gt;Taking another snapshot with the profiler, I&#39;m still going to concentrate on the &quot;Render&quot; method (for the same reasons as before; it&#39;s still the slower part of the work and it&#39;s still what I can most easily control). This time I see a lot of calls to a generic constructor resulting from &quot;op_Implicit&quot; calls.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Unnecessary Optional instantiation&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/BridgeReactProfiling2.png&quot; class=&quot;NoBorder FullWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;The &quot;op_Implicit&quot; methods are the JavaScript representations of implicit operator methods in C#. So, where the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct has an implicit operator from &quot;T&quot; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static implicit operator Optional&amp;lt;T&amp;gt;(T value)
{
    return new Optional&amp;lt;T&amp;gt;(value);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the following JavaScript is generated:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;op_Implicit: function (value) {
    return new (ProductiveRage.Immutable.Optional$1(T)).$constructor1(value);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When a &lt;strong&gt;CommonProps&lt;/strong&gt; instance is created with a null &quot;className&quot; argument (which is the case for every &lt;strong&gt;MessageRow&lt;/strong&gt; in the sample app), each call to the &lt;strong&gt;CommonProps&lt;/strong&gt; &quot;For&quot; method requires the null reference to be implicitly cast to an &lt;strong&gt;Optional&amp;lt;ClassName&amp;gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static CommonProps&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(
    T state,
    Action&amp;lt;T&amp;gt; onChange,
    Optional&amp;lt;ClassName&amp;gt; className,
    bool disabled,
    Any&amp;lt;string, int&amp;gt; key)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each implicit cast requires a call to the implicit operator, which creates a new &lt;strong&gt;Optional&amp;lt;ClassName&amp;gt;&lt;/strong&gt; instance. This feels like unnecessary work.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; has a public static &quot;Missing&quot; property, so one way to avoid the creation of unnecessary instances would be to use&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;className: Optional&amp;lt;ClassName&amp;gt;.Missing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;instead of&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;className: null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But there were a few problems with this. Firstly, &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; is part of the ProductiveRage.Immutable library and I would like it to be as easy to use as possible. I think that it would be quite difficult to justify a significant performance cost in passing null as an Optional rather than &quot;Missing&quot; when there is an implicit cast to perform the translation. Secondly, the &quot;Missing&quot; property was implemented as&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public static Optional&amp;lt;T&amp;gt; Missing { get { new Optional&amp;lt;T&amp;gt;(default(T), false); } }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. which means that a new instance is created each time it&#39;s called anyway, so actually the &quot;Missing&quot; property wouldn&#39;t magically solve anything.&lt;/p&gt;

&lt;p&gt;It would make more sense for the &quot;Missing&quot; property to be set only once, something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static Optional&amp;lt;T&amp;gt; Missing { get { return _missing; } }
private static Optional&amp;lt;T&amp;gt; _missing = new Optional&amp;lt;T&amp;gt;(default(T), false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When I first wrote the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct, that is how I did it. Unfortunately, there was a problem with Bridge 1.10 and I removed the private &quot;_missing&quot; field as a workaround. The Bridge Team have long since resolved that issue and so I can put the code back how I want it.&lt;/p&gt;

&lt;p&gt;This also allows for a tweak to the implicit operator method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static implicit operator Optional&amp;lt;T&amp;gt;(T value)
{
    if (value == null)
        return _missing;
    return new Optional&amp;lt;T&amp;gt;(value);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, one might presume, there would now be no unnecessary instantiations whether &quot;className: Optional&amp;lt;ClassName&amp;gt;.Missing&quot; &lt;em&gt;or&lt;/em&gt; &quot;className: null&quot; was specified. Unfortunately, we&#39;re not quite there yet..&lt;/p&gt;

&lt;p&gt;When structs are passed around in C#, they are copied. This is why they appear to be passed &quot;by value&quot; rather than &quot;by reference&quot; - if a mutable struct is instantiated in method F1 and passed to F2, any changes made to it in F2 are not visible in F1 since they both have different copies of the struct. To ensure consistency with .net, Bridge&#39;s JavaScript must do something similar - any time that a struct is passed around, it is copied. This means that a new instance &lt;em&gt;will&lt;/em&gt; be created each time that &quot;Missing&quot; or &quot;_missing&quot; is accessed. This is wasteful with the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct since it&#39;s immutable; since nothing can alter its contents, there is no need to copy it when passing it around.&lt;/p&gt;

&lt;p&gt;Bridge has another workaround for this, the [Immutable] attribute. When applied to the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct, the Bridge compiler will not copy instances when they are passed from one method to another. These changes reduce the &quot;Render&quot; time to 93ms in the React development build and 61ms in production.&lt;/p&gt;

&lt;p&gt;While this is an improvement, I can still see what looks like a lot of time spent on generic type &lt;em&gt;stuff&lt;/em&gt; in the profiler. Even though the op_Implicit calls for null values are sharing instances now, in order to get to the static op_Implicit method it is necessary to access the representation of the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; struct for the particular type. And, I suspect, this incurs a similar cost to instantiating a new instance.&lt;/p&gt;

&lt;p&gt;To confirm this, I added [IgnoreGeneric] to &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt;. This was not something I really wanted to do since it would require a minor change to the struct&#39;s public interface. There are two properties; IsDefined and Value. Currently there are two states - a state where IsDefined is true and Value has a specified &quot;T&quot; value and a state where IsDefined is false and Value has the default value of &quot;T&quot; (null for a reference type, zero for a number). With the [IgnoreGeneric] attribute, it would not be possible to set the default value of &quot;T&quot; for the &quot;Missing&quot; value state since &quot;T&quot; would not be available at runtime. If I was to apply [IgnoreGeneric] to the struct then &quot;Value&quot; would have to be considered undefined if IsDefined was false. This isn&#39;t a huge deal since I think that that&#39;s how it should have been interpreted anyway, really (an alternative would have been to be more aggressive and throw an exception from the Value property getter if IsDefined is false) but it&#39;s still a change.&lt;/p&gt;

&lt;p&gt;When I added [IgnoreGeneric] to the &lt;strong&gt;CommonProps&amp;lt;T&amp;gt;&lt;/strong&gt; class, I had to apply some workarounds to deal with the type &quot;T&quot; not being available at runtime. I had to do similar with &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt;. The first change was that the following line clearly wouldn&#39;t work:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static Optional&amp;lt;T&amp;gt; _missing = new Optional&amp;lt;T&amp;gt;(default(T), false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so it was replaced with this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static Optional&amp;lt;T&amp;gt; _missing = new Optional&amp;lt;T&amp;gt;(Script.Write&amp;lt;T&amp;gt;(&quot;null&quot;), false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &quot;Script.Write&amp;lt;T&amp;gt;&quot; method in Bridge is a way to directly emit JavaScript (simply &quot;null&quot; in this case) and to tell the C# type system that a value of type &quot;T&quot; is being returned. So, here, the &quot;T&quot; is only used by the C# compiler and does not have any impact on runtime. The compromise is that &quot;null&quot; is being used for the Value property of the &quot;Missing&quot; instance regardless of the type of &quot;T&quot;. So Value will be null even if &quot;T&quot; is an int or a bool in cases where IsDefined is false.&lt;/p&gt;

&lt;p&gt;The other change required completely removing the C# backing field for the Value property -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private readonly T value;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem was that Bridge would generate a struct definition that would try to set &quot;value&quot; to default(T), which it would not be able to do since &quot;T&quot; would not be available at runtime.&lt;/p&gt;

&lt;p&gt;Instead, the value would be written directly by more raw JavaScript. The constructor changed from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Optional(T value) : this(value, value != null) { }
    this.isDefined = isDefined &amp;amp;&amp;amp; (value != null);
    this.value = value;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Optional(T value) : this(value, value != null) { }
    this.isDefined = isDefined &amp;amp;&amp;amp; (value != null);
    Script.Write(&quot;this.value = {0}&quot;, value);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and the property getter changed from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public T Value { get { return this.value; } }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public T Value { get { return Script.Write&amp;lt;T&amp;gt;(&quot;this.value&quot;); } }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, anywhere in the struct that the backing field was accessed was changed so that it went via the public &quot;Value&quot; property getter.&lt;/p&gt;

&lt;p&gt;This meant that there were no potential runtime errors waiting to occur within the struct (none of the code relied on access to the type &quot;T&quot;), that there was type safety for any code instantiating or accessing the struct in C# &lt;em&gt;and&lt;/em&gt; it meant that the struct could have [IgnoreGeneric] applied and hence (theoretically) allow the application to work more efficiently.&lt;/p&gt;

&lt;p&gt;It worked. Using the development build of React, the &quot;Render&quot; time of the &lt;strong&gt;MessageTable&lt;/strong&gt; was now 36ms and the &quot;receiveComponent&quot; time 141ms. With the production build, &quot;Render&quot; took &quot;9ms&quot; and &quot;receiveComponent&quot; 49ms.&lt;/p&gt;

&lt;p&gt;That&#39;s sufficiently fast that there is no perceived delay while typing into the text boxes. And, to put things back into context, the original &quot;worst case scenario&quot; that I was planning for was to deal with up to 1,000 checkboxes. I&#39;ve been measuring the time for 5,000 rows that include two text boxes &lt;em&gt;and&lt;/em&gt; a checkbox. If the sample app was changed to render only 1,000 rows then the React production build handles changes to elements by spending 5ms in &quot;Render&quot; and 17ms in &quot;receiveComponent&quot;. This means that there is no chance of perceptible lag in typing and certainly no perceptible delay in checking or unchecking a checkbox.&lt;/p&gt;

&lt;h3&gt;To summarise&lt;/h3&gt;

&lt;p&gt;I think that it&#39;s fair to call this a success! There are several things that I&#39;ve particuarly enjoyed in this investigation. Firstly, it&#39;s been a good reminder of just how powerful the dev tools are that come free with browsers these days. I was using Chrome but I believe that IE and Firefox have equivalent functionality. Secondly, the options that the Bridge Team have made available are really well thought out and very clever when you examine them - in isolation, each seems quite simple but it&#39;s the recognition that &lt;em&gt;sometimes&lt;/em&gt; it might be beneficial to have more control over the generated JavaScript that helps make Bridge so powerful and to enable me to do what I&#39;ve done here. Thirdly, almost all of the changes that I&#39;ve talked about here were made to my &quot;Bridge.React&quot;, &quot;ProductiveRage.Immutable&quot;, &quot;ProductiveRage.Immutable.Extensions&quot; libraries. That means that, when I make these changes live, anyone using those libraries will automatically reap the benefit. The only change that I made to the sample app was to change the &lt;strong&gt;MessageRow&lt;/strong&gt; implementation from being a component class to being a static function.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: I tried reverting &lt;strong&gt;MessageRow&lt;/strong&gt; back to being a component class and the &quot;Render&quot; time was still only 20ms when editing one of 1,000 rows (compared to 5ms when &lt;strong&gt;MessageRow&lt;/strong&gt; is implemented as a static function). The time spent by React in &quot;receiveComponent&quot; was unaffected. This means that simply updating the Bridge.React, ProductiveRage.Immutable and ProductiveRage.Immutable.Extensions packages could significantly improve the performance of complex applications with zero code changes.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This is one of the benefits of using libraries where the authors care about performance and strive to improve it over time. It reminds me of when the Bridge Team added compiler support for &quot;&lt;a href=&quot;http://bridge.net/bridge-1-11-released/#Lifted_Anonymous_Functions&quot;&gt;Lifted Anonyomous Functions&lt;/a&gt;&quot; (something I suggested after going on a bit of a JavaScript performance research binge a few months ago - but something that the team there deserve much credit for making work) and it reminds me of articles that I&#39;ve read about React which talk about how there are many optimisations yet to be made that their current API will make possible (see &quot;&lt;a href=&quot;https://github.com/acdlite/react-fiber-architecture&quot;&gt;React Fiber Architecture&lt;/a&gt;&quot;); all that we&#39;ll have to do in the future is upgrade the version of the library being used and get more performance!&lt;/p&gt;

&lt;h3&gt;Update: The Bridge Team ruin my fun&lt;/h3&gt;

&lt;p&gt;I&#39;ve been researching and writing this post over the space of a couple of weeks. Once I had observed that generic classes are slower to instantiate in Bridge than non-generic classes, and while I was looking into the workarounds required sometimes in order to use [IgnoreGeneric], I raised a bug on the &lt;a href=&quot;http://forums.bridge.net/forum/bridge-net-pro/bugs&quot;&gt;Bridge Forums&lt;/a&gt; relating to properties that are initially to default(T) (which fails when &quot;T&quot; is not available at runtime).&lt;/p&gt;

&lt;p&gt;While looking into the issue for me, they noted that they found a way to optimise the instantiation of generic types (looking at the &lt;a href=&quot;https://github.com/bridgedotnet/Bridge/pull/1740/files&quot;&gt;pull request&lt;/a&gt; it seems like the work required to form a new specialisation of a class / struct for a given &quot;T&quot; is now cached rather than being repeated each time that a new &lt;strong&gt;Whatever&amp;lt;T&amp;gt;&lt;/strong&gt; is created).&lt;/p&gt;

&lt;p&gt;The good news is that this means that there will very soon be almost zero overhead to generic types in Bridge! The bad news is that many of the findings documented here are unnecessary.. However, that&#39;s the sort of bad news that I&#39;m happy to accept! The compromise around &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt;&#39;s &quot;Value&quot; property (for cases where &quot;IsDefined&quot; is false) will no longer be necessary. And I won&#39;t have to worry so much in the future; if I&#39;m creating a library class, should I be avoiding generics (or using [IgnoreGeneric]) in case it&#39;s used in an expensive loop anywhere?&lt;/p&gt;

&lt;p&gt;Despite being out of date even before being published, I&#39;ll leave this post here for posterity. I had a lot of fun digging into performance tuning my Bridge / React app. And, in a roundabout way, I feel like I contributed to the optimisation (which I imagine will makes its way into the next release of Bridge) that everyone using Bridge can benefit from! I&#39;m going to call that a win.&lt;/p&gt;
</description>
			<pubDate>Tue, 06 Sep 2016 22:04:00 GMT</pubDate>
		</item>
		<item>
			<title>Retrieving Performance Counter from a remote PC using C#</title>
            <link>http://www.productiverage.com/retrieving-performance-counter-from-a-remote-pc-using-c-sharp</link>
			<guid>http://www.productiverage.com/retrieving-performance-counter-from-a-remote-pc-using-c-sharp</guid>
			<description>&lt;p&gt;&lt;a href=&quot;http://www.productiverage.com/why-is-saving-performance-monitor-perfmon-settings-so-difficult-these-days&quot;&gt;PerfMon&lt;/a&gt; can be an invaluable tool for monitoring performance counters on the local or remote computer. It allows you to graph the information live and it allows you to write the data away to disk for future analysis.&lt;/p&gt;

&lt;p&gt;However, for some performance investigation that I was doing, I wanted something slightly different to what PerfMon offers. I was testing a service under load, a service that was being hosted on a dedicated box for the performance investigation - and I was testing it by generating the load from another dedicated server. Since nothing else would be hitting the service host box, what I wanted to do for each test run was to restart the service on the host, hit it with the sample load and record the processor time, % time in GC, number of garbage collections at each generation and some other metrics until the work was fully processed - at that point, there would be no more information to gather for that particular run. The experiment could be repeated a few times and the results filed away, brought back out to compare to the same load being run after some performance tweaks had been made to the code.&lt;/p&gt;

&lt;p&gt;It wouldn&#39;t be the end of the world if I had to do this manually - configure PerfMon to write the counter data to disk somewhere, restart the service before each run and then extract the data from the PerfMon logs that relate to the time period that just passed.. but it&#39;s tedious work that I don&#39;t want to bother with; I want to deploy a change then run-test-and-gather-data with a single button press. Better than that, I want to be able to perform multiple runs without any manual intervention - I want to deploy the new code then have the test harness restart the service, replay the test load, record the counter data in a file and then repeat as many times as desired.&lt;/p&gt;

&lt;h3&gt;Restarting the service&lt;/h3&gt;

&lt;p&gt;This part is easy, we can use a method such as this -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static void Restart(string server, string serviceName)
{
  if (string.IsNullOrWhiteSpace(server))
    throw new ArgumentException($&quot;Null/blank {nameof(server)} specified&quot;);
  if (string.IsNullOrWhiteSpace(serviceName))
    throw new ArgumentException($&quot;Null/blank {nameof(serviceName)} specified&quot;);

  // Add a reference to System.ServiceProcess to make ServiceController available
  using (var serviceController = new ServiceController(serviceName, server))
  {
    serviceController.Stop();
    serviceController.WaitForStatus(ServiceControllerStatus.Stopped);
    serviceController.Start();
    serviceController.WaitForStatus(ServiceControllerStatus.Running);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Querying a performance counter remotely&lt;/h3&gt;

&lt;p&gt;This bit is a little trickier.. I started with code from an article &lt;a href=&quot;http://haishibai.blogspot.co.uk/2010/02/tiy-collect-remote-performance-counters.html&quot;&gt;TIY – Collect remote performance counters using C#&lt;/a&gt; which sounded &lt;em&gt;exactly&lt;/em&gt; like what I wanted. Unfortunately, I was getting an error with the lines&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IntPtr userHandle = new IntPtr(0);
LogonUser(
  &quot;UserA&quot;,
  &quot;DomainA&quot;,
  &quot;PasswordA&quot;,
  LOGON32_LOGON_INTERACTIVE,
  LOGON32_PROVIDER_DEFAULT,
  ref userHandle
);
WindowsIdentity identity = new WindowsIdentity(userHandle);
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Token can not be zero&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This essentially meant that LogonUser had failed and so the &quot;userHandle&quot; reference had not been set (and left as a zero pointer). The code should really have checked the LogonUser return value -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var logonSuccess = LogonUser(
  &quot;UserA&quot;,
  &quot;DomainA&quot;,
  &quot;PasswordA&quot;,
  LOGON32_LOGON_INTERACTIVE,
  LOGON32_PROVIDER_DEFAULT,
  ref userHandle
);
if (!logonSuccess)
  throw new Exception(&quot;LogonUser failed&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. but that wouldn&#39;t actually fix the failure.&lt;/p&gt;

&lt;p&gt;The underlying problem was explained by another article &lt;a href=&quot;https://platinumdogs.me/2008/10/30/net-c-impersonation-with-network-credentials/&quot;&gt;.NET (C#) Impersonation with Network Credentials&lt;/a&gt; that explains that&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you require the impersonated logon to have network credentials, you must select LOGON32_LOGON_NEW_CREDENTIALS as your logon type, which requires that you select LOGON32_PROVIDER_WINNT50 as the logon provider type&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once I got the proof-of-concept working from these two articles, I fleshed things out into the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Runtime.InteropServices;
using System.Security.Principal;

namespace PerformanceCounterCapture
{
  public sealed class PerformanceCounterRetriever : IDisposable
  {
    private const int LOGON32_LOGON_NEW_CREDENTIALS = 9;
    private const int LOGON32_PROVIDER_WINNT50 = 3;

    [DllImport(&quot;advapi32.dll&quot;, CharSet = CharSet.Auto)]
    private static extern bool LogonUser(
      string lpszUserName,
      string lpszDomain,
      string lpszPassword,
      int dwLogonType,
      int dwLogonProvider,
      ref IntPtr phToken);

    private WindowsIdentity _identity;
    private WindowsImpersonationContext _context;
    private bool _disposed;
    private readonly string _server;
    public PerformanceCounterRetriever(string server, string domain, string user, string password)
    {
      if (string.IsNullOrWhiteSpace(server))
        throw new ArgumentException($&quot;Null/blank {nameof(server)} specified&quot;);
      if (string.IsNullOrWhiteSpace(domain))
        throw new ArgumentException($&quot;Null/blank {nameof(domain)} specified&quot;);
      if (string.IsNullOrWhiteSpace(user))
        throw new ArgumentException($&quot;Null/blank {nameof(user)} specified&quot;);
      if (password == null)
        throw new ArgumentNullException(nameof(password));

      try
      {
        var userHandle = new IntPtr(0);
        var logonSuccess = LogonUser(
          user,
          domain,
          password,
          LOGON32_LOGON_NEW_CREDENTIALS,
          LOGON32_PROVIDER_WINNT50,
          ref userHandle
        );
        if (!logonSuccess)
          throw new Exception(&quot;LogonUser failed&quot;);
        _identity = new WindowsIdentity(userHandle);
        _context = _identity.Impersonate();
        _server = server;
        _disposed = false;
      }
      finally
      {
        Dispose();
      }
    }
    ~PerformanceCounterRetriever()
    {
      Dispose(false);
    }

    public IEnumerable&amp;lt;float&amp;gt; Get(
      string categoryName,
      string counterName,
      string optionalInstanceName = null)
    {
      if (string.IsNullOrWhiteSpace(categoryName))
        throw new ArgumentException($&quot;Null/blank {nameof(categoryName)} specified&quot;);
      if (string.IsNullOrWhiteSpace(counterName))
        throw new ArgumentException($&quot;Null/blank {nameof(counterName)} specified&quot;);

      var counters = new List&amp;lt;PerformanceCounter&amp;gt;();
      var category = new PerformanceCounterCategory(categoryName, _server);
      foreach (var instanceName in category.GetInstanceNames())
      {
        if ((optionalInstanceName == null) || (instanceName == optionalInstanceName))
          counters.Add(new PerformanceCounter(categoryName, counterName, instanceName, _server));
      }
      if (!counters.Any())
        yield break;

      while (true)
      {
        foreach (var c in counters)
          yield return c.NextValue();
      }
    }

    public void Dispose()
    {
      Dispose(true);
      GC.SuppressFinalize(this);
    }

    private void Dispose(bool disposing)
    {
      if (_disposed)
        return;

      if (_identity != null)
      {
        _identity.Dispose();
        _identity = null;
      }

      if (_context != null)
      {
        _context.Undo();
        _context.Dispose();
        _context = null;
      }

      _disposed = true;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This class may be used in the following way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using (var counterRetriever = new PerformanceCounterRetriever(&quot;TestBox&quot;, &quot;Home&quot;, &quot;Dan&quot;, &quot;password&quot;))
{
  foreach (var value in counterRetriever.Get(&quot;Process&quot;, &quot;% Processor Time&quot;, &quot;TestService&quot;))
  {
    Console.WriteLine(
      &quot;[{0}] TestService: % Processor Time = {1}&quot;,
      DateTime.Now.ToString(&quot;HH:mm:ss.fff&quot;),
      value
    );
    Thread.Sleep(1000);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &quot;counterRetriever.Get&quot; call returns an &lt;strong&gt;IEnumerable&amp;lt;float&amp;gt;&lt;/strong&gt; which retrieves a new value every time that a new value is requested from the enumerable reference. The code above (very roughly) imitates PerfMon in that it reads a new &quot;% Processor Time&quot; value every second.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Note: The code above never terminates since nothing breaks it out of the loop, which is not useful in many scenarios.. but I&#39;ll talk about dealing with that shortly)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This is a good first step. However, when I&#39;m analysing the results of my test runs, I want to know more than just how much processor time is being used by the service.&lt;/p&gt;

&lt;h3&gt;Querying multiple performance counters remotely&lt;/h3&gt;

&lt;p&gt;If I want to collect the data from multiple performance counters then I need to get multiple &lt;strong&gt;IEnumerable&amp;lt;float&amp;gt;&lt;/strong&gt; instances from multiple &quot;counterRetriever.Get&quot; calls and then retrieve a value from each before pausing and repeating.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using (var counterRetriever = new PerformanceCounterRetriever(&quot;TestBox&quot;, &quot;Home&quot;, &quot;Dan&quot;, &quot;password&quot;))
{
  var processorTime = counterRetriever
    .Get(&quot;Process&quot;, &quot;% Processor Time&quot;, &quot;TestService&quot;)
    .GetEnumerator();
  var percentageTimeInGC = counterRetriever
    .Get(&quot;.NET CLR Memory&quot;, &quot;% Time in GC&quot;, &quot;TestService&quot;)
    .GetEnumerator();
  while (true)
  {
    processorTime.MoveNext();
    Console.WriteLine(
      &quot;[{0}] TestService: % Processor Time = {1}&quot;,
      DateTime.Now.ToString(&quot;HH:mm:ss.fff&quot;),
      processorTime.Current
    );
    percentageTimeInGC.MoveNext();
    Console.WriteLine(
      &quot;[{0}] TestService: % Time in GC = {1}&quot;,
      DateTime.Now.ToString(&quot;HH:mm:ss.fff&quot;),
      percentageTimeInGC.Current
    );
    Thread.Sleep(1000);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This could be extended to do the job (in my case, there are seven counters that I&#39;m interested in so the above could be chopped and changed to record them all) but the code will get a bit verbose and &quot;noisy&quot; quite quickly.&lt;/p&gt;

&lt;h3&gt;Troublesome counters&lt;/h3&gt;

&lt;p&gt;There is also a problem with writing code like the above and presuming that you can track all performance counters in the same way. For example, I also want to track the number of garbage collections that have occurred at generations 0, 1 and 2 since the service was restarted. It probably doesn&#39;t make much sense to record the values of these every second; I don&#39;t really care if there had been a single gen 0 garbage collection after 1s and after 2s and after 3s and after 4s, I&#39;d much rather see that at 1s there had been a single gen 0 collection and then, at 4s, there had been a second. I want to know when these kinds of values change and I&#39;m not interested in the repeated values between the changes.&lt;/p&gt;

&lt;p&gt;As another example, I&#39;m also interested in capturing information about the rate at which bytes are allocated by the service, for which I can consult the &quot;Allocated Bytes/sec&quot; counter. However, this counter is only updated after a GC event and will report zero the result of the time. This doesn&#39;t mean that zero bytes per second really were being allocated each time that the counter reports zero, it&#39;s just that there is nothing that can accurately report a value for this counter &lt;em&gt;except&lt;/em&gt; immediately following a collection. For this counter, it&#39;s probably best for me to exclude zero values - particularly while a performance test is underway, since it is basically impossible that the service will ever be allocating &lt;em&gt;zero&lt;/em&gt; bytes per second while it&#39;s deserialising requests and processing them. As with the &quot;number of collections at gen {x}&quot; counters, it will be worth ignoring some of the counter values but it will be important to know &lt;em&gt;when&lt;/em&gt; the values that we do pay attention to were recorded (since, for the &quot;Allocated Bytes/sec&quot; counter, it should be possible to use this information to approximate the allocation rate at any given time).&lt;/p&gt;

&lt;h3&gt;A complete solution&lt;/h3&gt;

&lt;p&gt;To try to address all of these problems, I&#39;ve come up with the following. It&#39;s not the smallest code sample in the world but it should be easy to follow and understand if you need to extend it for your own purposes -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;

namespace PerformanceCounterCapture
{
  public static class PerformanceCounterLogger
  {
    /// &amp;lt;summary&amp;gt;
    /// This will capture useful performance counter data until the specified cancellation token
    /// is set, at which point it will return the data (as such, it makes sense to call this from
    /// a background thread)
    /// &amp;lt;/summary&amp;gt;
    public static Results Log(
      string server,
      string domain,
      string user,
      string password,
      string serviceName,
      CancellationToken cancellationToken,
      TimeSpan timeBetweenCaptures)
    {
      if (string.IsNullOrWhiteSpace(server))
        throw new ArgumentException($&quot;Null/blank {nameof(server)} specified&quot;);
      if (string.IsNullOrWhiteSpace(domain))
        throw new ArgumentException($&quot;Null/blank {nameof(domain)} specified&quot;);
      if (string.IsNullOrWhiteSpace(user))
        throw new ArgumentException($&quot;Null/blank {nameof(user)} specified&quot;);
      if (password == null)
        throw new ArgumentNullException(nameof(password));
      if (string.IsNullOrWhiteSpace(serviceName))
        throw new ArgumentException($&quot;Null/blank {nameof(serviceName)} specified&quot;);
      if (cancellationToken == null)
        throw new ArgumentNullException(nameof(cancellationToken));
      if (timeBetweenCaptures.Ticks &amp;lt; 0)
        throw new ArgumentOutOfRangeException($&quot;{timeBetweenCaptures} must be a non-negative duration&quot;);

      // These lists will be populated periodically (according to timeBetweenCaptures) and, when the
      // cancellation token is set, they will all be included in the returned data for analysis
      var processorTimes = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var percentageGarbageCollectorTimes = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var numberOfGen0Collections = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var numberOfGen1Collections = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var numberOfGen2Collections = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var largeObjectHeapSize = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      var allocatedBytesPerSeconds = new List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt;();
      using (var performanceCounterRetriever = new PerformanceCounterRetriever(
                                                server, domain, user, password))
      {
        var performanceCountersToRecord = new[]
        {
          new PerformanceCounterDetails(
            &quot;Process&quot;,
            &quot;% Processor Time&quot;,
            serviceName,
            value =&amp;gt; processorTimes.Add(Tuple.Create(DateTime.Now, value))
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;% Time in GC&quot;,
            serviceName,
            value =&amp;gt; percentageGarbageCollectorTimes.Add(Tuple.Create(DateTime.Now, value))
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;# Gen 0 Collections&quot;,
            serviceName,
            value =&amp;gt; AddValueToListIfNew(numberOfGen0Collections, value)
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;# Gen 1 Collections&quot;,
            serviceName,
            value =&amp;gt; AddValueToListIfNew(numberOfGen1Collections, value)
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;# Gen 2 Collections&quot;,
            serviceName,
            value =&amp;gt; AddValueToListIfNew(numberOfGen2Collections, value)
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;Large Object Heap size&quot;,
            serviceName,
            value =&amp;gt; AddValueToListIfNew(largeObjectHeapSize, value)
          ),
          new PerformanceCounterDetails(
            &quot;.NET CLR Memory&quot;,
            &quot;Allocated Bytes/sec&quot;,
            serviceName,
            value =&amp;gt;
            {
              // This is only set after a GC event so there are lots of spurious zeroes that we
              // want to ignore (this value-ignoring is the main reason that the date that the
              // value was recorded is included in the result data, so that it&#39;s possible to
              // approximate values during the missing periods - which may be of variable
              // duration since the useful values recorded for this are related to GC events)
              if (value == 0)
                return;
              allocatedBytesPerSeconds.Add(Tuple.Create(DateTime.Now, value));
            }
          )
        };

        var allCounterEnumerators = performanceCountersToRecord
          .Select(counterDetails =&amp;gt; new {
            Feed =
              performanceCounterRetriever.Get(
                counterDetails.CategoryName,
                counterDetails.CounterName,
                counterDetails.OptionalInstanceName
              )
              .GetEnumerator(),
            ValueLogger = counterDetails.ValueLogger
          })
          .ToArray(); // Don&#39;t call GetFeed every time that we enumerate the set

        // Keep looping and populating the lists until the cancellation token is set - at that
        // point, return a result object that contains all of the data
        while (!cancellationToken.IsCancellationRequested)
        {
          foreach (var counterEnumerator in allCounterEnumerators)
          {
            counterEnumerator.Feed.MoveNext();
            var value = counterEnumerator.Feed.Current;
            counterEnumerator.ValueLogger(value);
          }
          if (!cancellationToken.IsCancellationRequested)
            Thread.Sleep(timeBetweenCaptures);
        }
        return new Results(
          processorTimes,
          percentageGarbageCollectorTimes,
          numberOfGen0Collections,
          numberOfGen1Collections,
          numberOfGen2Collections,
          largeObjectHeapSize,
          allocatedBytesPerSeconds
        );
      }
    }

    private static void AddValueToListIfNew(List&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; values, float value)
    {
      if (values == null)
        throw new ArgumentNullException(nameof(value));

      if (!values.Any() || (values.Last().Item2 != value))
        values.Add(Tuple.Create(DateTime.Now, value));
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also needs the following two classes for its internal initialisation and for returning results -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class PerformanceCounterDetails
{
  public PerformanceCounterDetails(
    string categoryName,
    string counterName,
    string optionalInstanceName,
    Action&amp;lt;float&amp;gt; valueLogger)
  {
    if (string.IsNullOrWhiteSpace(categoryName))
      throw new ArgumentException($&quot;Null/blank {nameof(categoryName)} specified&quot;);
    if (string.IsNullOrWhiteSpace(counterName))
      throw new ArgumentException($&quot;Null/blank {nameof(counterName)} specified&quot;);
    if (valueLogger == null)
      throw new ArgumentNullException(nameof(valueLogger));

    CategoryName = categoryName;
    CounterName = counterName;
    OptionalInstanceName = optionalInstanceName;
    ValueLogger = valueLogger;
  }

  public string CategoryName { get; }
  public string CounterName { get; }
  public string OptionalInstanceName { get; }
  public Action&amp;lt;float&amp;gt; ValueLogger { get; }
}

public sealed class Results
{
  public Results(
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; processorTimes,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; percentageGarbageCollectorTimes,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; numberOfGen0Collections,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; numberOfGen1Collections,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; numberOfGen2Collections,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; largeObjectHeapSize,
    IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; allocatedBytesPerSeconds)
  {
    if (processorTimes == null)
      throw new ArgumentNullException(nameof(processorTimes));
    if (percentageGarbageCollectorTimes == null)
      throw new ArgumentNullException(nameof(percentageGarbageCollectorTimes));
    if (numberOfGen0Collections == null)
      throw new ArgumentNullException(nameof(numberOfGen0Collections));
    if (numberOfGen1Collections == null)
      throw new ArgumentNullException(nameof(numberOfGen1Collections));
    if (numberOfGen2Collections == null)
      throw new ArgumentNullException(nameof(numberOfGen2Collections));
    if (largeObjectHeapSize == null)
      throw new ArgumentNullException(nameof(largeObjectHeapSize));
    if (allocatedBytesPerSeconds == null)
      throw new ArgumentNullException(nameof(allocatedBytesPerSeconds));

    ProcessorTimes = processorTimes;
    PercentageGarbageCollectorTimes = percentageGarbageCollectorTimes;
    NumberOfGen0Collections = numberOfGen0Collections;
    NumberOfGen1Collections = numberOfGen1Collections;
    NumberOfGen2Collections = numberOfGen2Collections;
    LargeObjectHeapSize = largeObjectHeapSize;
    AllocatedBytesPerSeconds = allocatedBytesPerSeconds;
  }

  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; ProcessorTimes { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; PercentageGarbageCollectorTimes { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; NumberOfGen0Collections { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; NumberOfGen1Collections { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; NumberOfGen2Collections { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; LargeObjectHeapSize { get; }
  public IEnumerable&amp;lt;Tuple&amp;lt;DateTime, float&amp;gt;&amp;gt; AllocatedBytesPerSeconds { get; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don&#39;t think that there&#39;s a great deal that requires explaining in depth - the &lt;strong&gt;PerformanceCounterLogger&lt;/strong&gt; will periodically capture values from all of the counters that I&#39;m interested in, dealing with the special cases described earlier (garbage collection frequency, allocated bytes / sec, etc..) in a blocking manner. It continues to capture counter data until the cancellation token passed to it is set.&lt;/p&gt;

&lt;p&gt;That means that it makes sense to capture the performance counter data on a seperate thread. Something like the following (which is basically what I&#39;m using in my test runs) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Restart the service on the test server
Restart(&quot;TestBox&quot;, &quot;TestService&quot;);

// Start recording performance counters on a separate thread
Results performanceCounterResults = null;
var cancellationTokenSource = new CancellationTokenSource();
var resultsReadyIndicator = new ManualResetEvent(initialState: false);
ThreadPool.QueueUserWorkItem(state =&amp;gt;
{
  performanceCounterResults = PerformanceCounterLogger.Log(
    &quot;TestBox&quot;,
    &quot;Home&quot;,
    &quot;Dan&quot;,
    &quot;password&quot;,
    &quot;TestService&quot;,
    cancellationTokenSource.Token,
    TimeSpan.FromSeconds(1)
  );
  resultsReadyIndicator.Set();
});

// TODO: Fire load at the server...........

// Tell the performance counters that it&#39;s time to stop capturing and wait for it to acknowledge
cancellationTokenSource.Cancel();
resultsReadyIndicator.WaitOne();

// TODO: Write the &quot;performanceCounterResults&quot; data away to analyse later...........
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two big TODOs in the above code - somehow the request payload needs to be fired at the remote server that is being measured and somehow the performance counter results need to be compared between one run and the next. Obviously, these will vary from one project to the next and so they will be very dependent upon what kind of service that you&#39;re testing (and what performance counters you&#39;re interested in). In my case, I already had a decent system available for replaying old requests so that changes to the system could be examined, all I needed on top of that was a way to capture some performance counters to bring some &lt;em&gt;cold hard numbers&lt;/em&gt; into proceedings - if you&#39;re in a similar position then hopefully this post will be helpful!&lt;/p&gt;

&lt;h3&gt;Shameless plug&lt;/h3&gt;

&lt;p&gt;Although I had a system in place to replay historical requests in order to simulate load, there was a slight problem with this in that the service would read from a database and it was totally feasible that the data persisted there could vary from hour to hour (if not more frequently). This could mean that one performance run would not be directly comparable to the next - one run may return more or less results for a particular query, for example, or have to process some of those results in a different (ie. more or less expensive) manner.&lt;/p&gt;

&lt;p&gt;This would make meaningful comparisons difficult - really, each run should return precisely the same data as the next.&lt;/p&gt;

&lt;p&gt;For this particular service, a few things were in my favour on this front; the service was read only, its job is only to deliver data for rendering on various web sites and it does not have to perform any write operations. It also only specifies a database connection in a fairly limited number of places. This allowed me to add a config option to the service that would (when in a particular test mode) create database connections that get their data from a proxy service instead of going directly to the SQL database.&lt;/p&gt;

&lt;p&gt;The proxy service can be run in either &quot;record&quot; or &quot;replay&quot; mode. First, the service that is under test should have the batch of requests that the processing performance is being measured for replayed while the database proxy service is in &quot;record&quot; mode - this allows the proxy service to populate a cache on disk that contains all of the result sets for all of the database queries performed. After this, all subsequent performance runs are made with the proxy service in &quot;replay&quot; mode - in this configuration, the service will never hit the database and will always return data from its cache. This ensures that the data retrieved during each performance run is consistent, which makes it much easier to reach useful conclusions and make meaningful comparisons.&lt;/p&gt;

&lt;p&gt;The library that I wrote for this database proxy service is called &lt;a href=&quot;https://github.com/ProductiveRage/SqlProxyAndReplay&quot;&gt;SqlProxyAndReplay&lt;/a&gt; and is available on GitHub and via NuGet (the client needs &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.SqlProxyAndReplay.Client&quot;&gt;ProductiveRage.SqlProxyAndReplay.Client&lt;/a&gt; and the server needs &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.SqlProxyAndReplay.Service&quot;&gt;ProductiveRage.SqlProxyAndReplay.Service&lt;/a&gt; and &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.SqlProxyAndReplay.Service.Example&quot;&gt;ProductiveRage.SqlProxyAndReplay.Service.Example&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;There are some caveats - under the hood, this uses a WCF (binary endpoint) service and it won&#39;t be as fast as hitting a database directly. And, as a .net library, there will be some garbage collection overhead since it will result in additional allocations. However, for testing how the &lt;em&gt;internals&lt;/em&gt; of a service (and not, say, tweaking individual SQL queries to try to eke out more performance) then this shouldn&#39;t be a huge problem since the overhead should be consistent from one run to the next. So long as you are measuring changes in performance runs &lt;em&gt;before&lt;/em&gt; you deploy an update and performance runs &lt;em&gt;after&lt;/em&gt; an update (hopefully improvements!) then the overhead of the database proxy shouldn&#39;t matter.&lt;/p&gt;

&lt;p&gt;Sometimes, of course, the database &lt;em&gt;is&lt;/em&gt; your bottle neck and so you want to capture real queries as they hit it so that you can performance tune them. There are already lot of good tools for this (you can get a long way by attaching SQL Profiler and looking for the most expensive or most frequent quite-expensive queries) but I hadn&#39;t found something useful for my use case, where I wanted to optimise what happened &lt;em&gt;after&lt;/em&gt; any database access and just wanted the database access layer to magically return consistent data time after time. At least, I couldn&#39;t find one that didn&#39;t entail significant work in writing some sort of mock / cached database access layer.&lt;/p&gt;

&lt;p&gt;While the &lt;a href=&quot;https://github.com/ProductiveRage/SqlProxyAndReplay&quot;&gt;SqlProxyAndReplay&lt;/a&gt; service / library may not be as useful if you have to test a service or application that needs to persist changes made to the backing store, I imagine that it&#39;s common for a lot of large scale applications to want to cache and optimise read operations and so this may well be useful for other people. The &lt;a href=&quot;https://github.com/ProductiveRage/SqlProxyAndReplay&quot;&gt;linked GitHub&lt;/a&gt; repo has more information in its README and there&#39;s a &quot;Tester&quot; console application to demonstrate it in action.&lt;/p&gt;
</description>
			<pubDate>Wed, 10 Aug 2016 21:01:00 GMT</pubDate>
		</item>
		<item>
			<title>Why is saving Performance Monitor (PerfMon) settings so difficult these days?!</title>
            <link>http://www.productiverage.com/why-is-saving-performance-monitor-perfmon-settings-so-difficult-these-days</link>
			<guid>http://www.productiverage.com/why-is-saving-performance-monitor-perfmon-settings-so-difficult-these-days</guid>
			<description>&lt;p&gt;I&#39;ve been measuring and optimising a busy service recently at work and PerfMon is an invaluable tool in doing things like this - the service records its own performance counters about requests/second, cache-hits-and-misses/second and many other useful metrics, while Windows and .net also report on many helpful statistics such as CPU time per process, memory usage, bytes-allocated/second and frequency of garbage collections.&lt;/p&gt;

&lt;p&gt;Performance Monitor makes it really easy to add a set of counters and format their lines so that some are bold and thick (and, so, clear at a glance) while other may be made less obtrusive, so as not to confuse the graph too much.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/PerfMon.png&quot; alt=&quot;Performance Monitor&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, over the years the interface to this tool has had some changes made to it that I&#39;m not convinced are improvements. Back on Windows Server 2003, I&#39;m pretty sure that you could configure your view how you wanted it and then simply use File/Save to write an &quot;.mmc&quot; configuration file. Whenever you wanted, you could double-click that file and all of the counters would be there, configured just as you left them, quietly capturing data and displaying it how you want it. Unfortunately, that day has gone and it&#39;s not quite so easy.&lt;/p&gt;

&lt;p&gt;Never mind, I move with the times.&lt;/p&gt;

&lt;p&gt;There are a few options available to do the same sort of thing today. The first, and most obvious, is to right-click on the graph and choose &quot;Save Settings As&quot;. This saves a web page version of the current view that uses an ActiveX plugin (and so requires IE to display it and requires you to &quot;Allow blocked content&quot;). With this plugin you can do much of what you can in PerfMon - add or remove counters, highlight the currently-selected counter, change the formatting of the current counter, etc.. This option isn&#39;t terrible but it doesn&#39;t feel quite as solid as &lt;em&gt;real&lt;/em&gt; PerfMon.&lt;/p&gt;

&lt;p&gt;The second option sounds like a pretty reasonable idea; you can copy the current configuration to the clipboard, save it and then paste it back into a fresh PerfMon instance in the future (the content saved to the clipboard is basically the same content as is written away when you use &quot;Save Settings As&quot; to create the web page version). My biggest problem with this is that it doesn&#39;t work! I&#39;ve tried on several machines now (Windows Server 2012 and Windows 8.1) and I can successfully copy the content (I can verify this by pasting it into notepad) but when I click on the paste icon in PerfMon nothing happens. No error, no nothing. Maybe I&#39;m doing something stupid here, but I don&#39;t know what.&lt;/p&gt;

&lt;p&gt;There is a third option, I think, involving the &quot;Data Collector Sets&quot; section of the PerfMon tree view. However, I tried to remember what it was earlier today by playing around with the interface and I didn&#39;t get anywhere quickly.&lt;/p&gt;

&lt;p&gt;I use a fourth option these days, which is to start PerfMon using &quot;perfmon /sys&quot; (this works from the command line or from [Win]-[R]). This starts PerfMon in a kind of streamlined interface (the treeview down the left hand side of the application is notable by its absence, for example). But the really good bit about this mode is that the File menu now has two options - &quot;Save Settings As&quot; and &quot;LoadSettings&quot;. These work with &quot;.PerfMonCfg&quot; files and essentially make simple what I used to do in the old days; configure everything just so, save to the desktop for another day, open from the desktop on that day in the future and find everything just how I want it.&lt;/p&gt;

&lt;p&gt;Success!&lt;/p&gt;

&lt;h3&gt;Another little tweak&lt;/h3&gt;

&lt;p&gt;There is one thing that still annoys me, though. There doesn&#39;t seem to be any way to manually control the split between how much space is dedicated to the lower part of the display (that contains the names of the counters) and the upper half (the graph). If you add more than a couple of counters then the interface forces a vertical scroll bar onto the lower section - if you could manually make that section taller then the scroll bar would not be necessary.. but, alas, it appears that you can not.&lt;/p&gt;

&lt;p&gt;There is one trick to make it &lt;em&gt;slightly&lt;/em&gt; better, though. If the window is too narrow to show all of the information in that lower area then the horizontal scrollbar always appears on top of the last counter. If you can make the PerfMon window wide enough that you don&#39;t need the horizontal scrollbar then you can get one more counter to fit into view before the vertical scrollbar forces its way into play. This seems to allow up to nine counters to be displayed in the lower area with no scrolling required - if you need ten or more, though, then it seems like vertical scrolling is unavoidable :(&lt;/p&gt;
</description>
			<pubDate>Thu, 14 Jul 2016 19:36:00 GMT</pubDate>
		</item>
		<item>
			<title>Creating a C# (&quot;Roslyn&quot;) Analyser - For beginners by a beginner</title>
            <link>http://www.productiverage.com/creating-a-c-sharp-roslyn-analyser-for-beginners-by-a-beginner</link>
			<guid>http://www.productiverage.com/creating-a-c-sharp-roslyn-analyser-for-beginners-by-a-beginner</guid>
			<description>&lt;p&gt;I&#39;ve been meaning to try writing a post about creating analysers for a little while now - they&#39;re a technology that I think has huge promise for improving code quality and they&#39;re something that I&#39;ve successfully played around with recently.. but I&#39;m still very much in the early phases of being proficient and they&#39;re not something that I can just sit down and bang out easily (ie. not without a lot of googling).&lt;/p&gt;

&lt;p&gt;So this won&#39;t be the post of an expert - but I&#39;m hoping to use that to my advantage since I hopefully remember the pain points all too well and can go through the sort of things that I try when I&#39;m hashing these out.&lt;/p&gt;

&lt;p&gt;Most of the analysers I&#39;ve been writing have been for libraries that work with &lt;a href=&quot;http://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt;, which introduces some of its own complications. I&#39;m hoping to talk about those problems and how to overcome them in a later post - this one will be a more general introduction.&lt;/p&gt;

&lt;h3&gt;Creating a fresh Analyser project&lt;/h3&gt;

&lt;p&gt;The easiest way to get started is to use a Microsoft template. To do this, first you need to install the Visual Studio 2016 SDK and to do &lt;em&gt;this&lt;/em&gt; you go to File / New / Project and then choose C# in the left navigation pane, click on Extensibility and then select &quot;Install the Visual Studio Extensibility Tools&quot; (you may already have it installed, it&#39;s an optional component of VS2015 - if you see no link to &quot;Install the Visual Studio Extensibility Tools&quot; then hopefully that&#39;s why). Next, from the same Extensibility section, you need to select &quot;Download the .NET Compiler Platform SDK&quot;. This will ensure that you have the project template installed that we&#39;re going to use and it installs some other helpful tools, such as the Syntax Visualizer (which we&#39;ll see in a moment).&lt;/p&gt;

&lt;p&gt;Now that you have the template and since you&#39;re already in File / New / Project / C# / Extensibility, select &quot;Analyzer with Code Fix (NuGet + VSIX)&quot; to create an example analyser solution. This will be a fully operational analyser, split into three projects - the analyser itself, a unit test library and a &quot;Vsix&quot; project. This last one would be used if you wanted to create an analyser that would be installed and applied to &lt;em&gt;all&lt;/em&gt; projects that you would ever open and &lt;em&gt;not&lt;/em&gt; apply to any specific library. What I&#39;ll be talking about here will be creating an analyser to work with a particular library (that would be distributed &lt;em&gt;with&lt;/em&gt; the library) - so that everyone consuming the library can benefit from it. As such, to keep things simple, delete the &quot;Vsix&quot; project now,&lt;/p&gt;

&lt;p&gt;The example analyser that this template installs does something very simple - it looks for class names that are not upper case and it warns about them. In terms of functionality, this is not particularly useful.. but in terms of education and illustrating how to get started it&#39;s a good jumping off point. In fact, the project includes not just an analyser but also a &quot;code fix&quot; - once a non-all-upper-case class name is identified and warned about, a quick fix will be offered in the IDE to change the name to match the upper case regime that it&#39;s pushing. Code fixes can be really helpful but I&#39;ll talk about them another day, I think that there already will be plenty to deal with in this post.&lt;/p&gt;

&lt;p&gt;The analyser class looks basically like this (I&#39;ve removed comments and replaced localisable strings with hard-coded strings, just to make it a little less to absorb all at once) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Immutable;
using System.Linq;
using Microsoft.CodeAnalysis;
using Microsoft.CodeAnalysis.Diagnostics;

namespace ExampleAnalyser
{
    [DiagnosticAnalyzer(LanguageNames.CSharp)]
    public class ExampleAnalyserAnalyzer : DiagnosticAnalyzer
    {
        public const string DiagnosticId = &quot;ExampleAnalyser&quot;;
        private const string Category = &quot;Naming&quot;;
        private static readonly LocalizableString Title
            = &quot;Type name contains lowercase letters&quot;;
        private static readonly LocalizableString MessageFormat
            = &quot;Type name &#39;{0}&#39; contains lowercase letters&quot;;
        private static readonly LocalizableString Description
            = &quot;Type names should be all uppercase.&quot;;

        private static DiagnosticDescriptor Rule = new DiagnosticDescriptor(
            DiagnosticId,
            Title,
            MessageFormat,
            Category,
            DiagnosticSeverity.Warning,
            isEnabledByDefault: true,
            description: Description
        );

        public override ImmutableArray&amp;lt;DiagnosticDescriptor&amp;gt; SupportedDiagnostics
        {
            get { return ImmutableArray.Create(Rule); }
        }

        public override void Initialize(AnalysisContext context)
        {
            context.RegisterSymbolAction(AnalyzeSymbol, SymbolKind.NamedType);
        }

        private static void AnalyzeSymbol(SymbolAnalysisContext context)
        {
            var namedTypeSymbol = (INamedTypeSymbol)context.Symbol;
            if (namedTypeSymbol.Name.ToCharArray().Any(char.IsLower))
            {
                context.ReportDiagnostic(Diagnostic.Create(
                    Rule,
                    namedTypeSymbol.Locations[0],
                    namedTypeSymbol.Name
                ));
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To summarise what&#39;s in the above code:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Every analyser needs at least one rule that it will declare&lt;/strong&gt;, where a rule has various properties such as a Diagnostic Id, Category, Title, MessageFormat, Description and Severity. The two that are most immediately interesting are Severity (make it a Warning to point out a potential mistake or make it an Error to indicate a critical problem that will prevent a build from being completed) and MessageFormat, since MessageFormat is responsible for the text that will be displayed to the user in their Error List. MessageFormat supports string replacement; in the above example, you can see that there is a &quot;{0}&quot; placeholder in the MessageFormat - when &quot;Diagnostic.Create&quot; is called, the argument &quot;namedTypeSymbol.Name&quot; is injected into that &quot;{0}&quot; placeholder.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Every analyser needs to declare a &quot;SupportedDiagnostics&quot; value that lists all of the types of rule&lt;/strong&gt; that it is possible for the analyser to raise. This is vital in order for the analyser to work correctly at runtime. (If you create an analyser that has three different types of rule that it can report but you forget to declare one of the types in the &quot;SupportedDiagnostics&quot; property, there is actually an analyser that is installed with the template that points out the mistake to you - which is a great example of how analysers can protect you at compile time from potential runtime problems!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Every analyser needs an &quot;Initialize&quot; method that registers what type of symbol (more on what this actually means in a moment) it&#39;s interested in&lt;/strong&gt; and provides a reference to a method that will perform the actual analysis&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The simple task of the class above is to look at any &quot;named type&quot; (ie. classes and structs) and inspect their name to ensure that they consist entirely of capital letters (remember, this example included in the &quot;Analyzer with Code Fix (NuGet + VSIX)&quot; template is simply for educational purposes and &lt;em&gt;not&lt;/em&gt; because it&#39;s believed that all class names should be SHOUTING_FORMAT! :) Any class that doesn&#39;t have an all-caps name will result in a warning in the Error List.&lt;/p&gt;

&lt;p&gt;To illustrate how this should work, the test project includes the following test method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[TestMethod]
public void TestMethod2()
{
    var test = @&quot;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Diagnostics;

namespace ConsoleApplication1
{
    class TypeName
    {   
    }
}&quot;;
    var expected = new DiagnosticResult
    {
        Id = &quot;ExampleAnalyser&quot;,
        Message = String.Format(&quot;Type name &#39;{0}&#39; contains lowercase letters&quot;, &quot;TypeName&quot;),
        Severity = DiagnosticSeverity.Warning,
        Locations = new[] {
            new DiagnosticResultLocation(&quot;Test0.cs&quot;, 11, 15)
        }
    };

    VerifyCSharpDiagnostic(test, expected);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This makes it clear to see precisely what sort of thing the analyser is looking for but it also gives us another immediate benefit - we can actually execute the analyser and step through it in the debugger if we want to have a poke around with exactly what is in the &lt;strong&gt;SymbolAnalysisContext&lt;/strong&gt; reference or if we want to look at the properties of a particular &lt;strong&gt;INamedTypeSymbol&lt;/strong&gt; instance. This is as easy as putting a breakpoint into the &quot;AnalyzeSymbol&quot; method in the example analyser and then going back into the test class, right-clicking within &quot;TestMethod2&quot; and selecting &quot;Debug Tests&quot;.&lt;/p&gt;

&lt;p&gt;I want to introduce one other useful technique before moving on - the use of the &quot;Syntax Visualizer&quot;. An analyser works on an in-memory tree of nodes that represent the source code of the file that you&#39;re looking at*. In the unit test above, the named symbol &quot;TypeName&quot; is a child node of the &quot;TypeName&quot; class declaration, which is a child node of the &quot;ConsoleApplication1&quot; namespace, which is a child of a top-level construct called the &quot;CompilationUnit&quot;. Understanding the various types of node will be key to writing analysers and the Syntax Visualizer makes this a little bit easier.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Although an analyser starts by examining source code in a particular file, it&#39;s also possible to look up types and values that are referenced in that code that live elsewhere - to find out what namespace a class that is referenced exists in, for example, or to determine what arguments a method that is called that exists in a different library. These lookups are more expensive than looking solely at the content in the current file, however, and so should only be done if strictly necessary. We will see how to do this shortly. When looking only at content parsed from the current file, we are looking at the &quot;syntax tree&quot;. When looking up references elsewhere in the solution we accessing the &quot;semantic model&quot;).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Having installed the &quot;.NET Compiler Platform SDK&quot; earlier, you will now have access to this tool - go to View / Other Windows / Syntax Visualizer. This shows the syntax tree for any code within your project. So, if you click on the name &quot;TestMethod2&quot; then you will see that it is an &lt;strong&gt;IdentifierToken&lt;/strong&gt; (which is the name &quot;TestMethod2&quot;) that is a child node of a &lt;strong&gt;MethodDeclaration&lt;/strong&gt; which is a child node of a &lt;strong&gt;ClassDeclaration&lt;/strong&gt; which is a child node of a &lt;strong&gt;NamespaceDeclaration&lt;/strong&gt;, which is a child node of a &lt;strong&gt;CompilationUnit&lt;/strong&gt;. You can click on any of these nodes in the Syntax Visualiser to inspect some of the properties of the node and you can open further branches to inspect more - for example, there is a &quot;Block&quot; node that will appear shortly after the &lt;strong&gt;IdentifierToken&lt;/strong&gt; that you may click to reveal the nodes that represent the statements within the method.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/SyntaxVisualizer.png&quot; alt=&quot;The Syntax Visualizer&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Writing a real analyser&lt;/h3&gt;

&lt;p&gt;I&#39;m going to walk through an analyser that I created recently - starting from scratch and, hopefully, encountering the same problems that I did last time so that I can illustrate how to find out how to solve them.&lt;/p&gt;

&lt;p&gt;The analyser is part of my &lt;a href=&quot;https://www.nuget.org/packages/Bridge.React&quot;&gt;Bridge.React&lt;/a&gt; library but you won&#39;t need to know anything about React or Bridge to follow along.&lt;/p&gt;

&lt;p&gt;The root of the problem relates to the rendering of html &quot;select&quot; elements. There are three related properties to consider when rendering a &quot;select&quot; element; &quot;Multiple&quot;, &quot;Value&quot; and &quot;Values&quot;. Multiple is a boolean that indicates whether the elements supports only single selections (false) or zero, one or more selections (true). If rendering an element with pre-selected items then the &quot;Value&quot; or &quot;Values&quot; properties must be used. &quot;Value&quot; is a string while &quot;Values&quot; is a string array. If &quot;Multiple&quot; is false and &quot;Values&quot; is set then React will display a warning at runtime and ignore the value, similarly if &quot;Multiple&quot; is true and &quot;Value&quot; is set.&lt;/p&gt;

&lt;p&gt;I wanted an analyser that handled these simple cases -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// This is fine
return DOM.Select(new SelectAttributes { Multiple = false, Value = &quot;x&quot; };

// This is fine
return DOM.Select(new SelectAttributes { Multiple = true, Values = new [] { &quot;x&quot;, &quot;y&quot; } };

// Wrong (shouldn&#39;t use &quot;Value&quot; when &quot;Multiple&quot; is true)
return DOM.Select(new SelectAttributes { Multiple = true, Value = &quot;x&quot; };

// Wrong (shouldn&#39;t use &quot;Values&quot; when &quot;Multiple&quot; is false)
return DOM.Select(new SelectAttributes { Multiple = false, Values = new [] { &quot;x&quot;, &quot;y&quot; } };

// Wrong (shouldn&#39;t use &quot;Values&quot; when &quot;Multiple&quot; defaults to false)
return DOM.Select(new SelectAttributes { Values = new [] { &quot;x&quot;, &quot;y&quot; } };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&#39;s worth mentioning that I&#39;m &lt;em&gt;only&lt;/em&gt; considering these simple cases so this analyser won&#39;t be &quot;perfect&quot;. If &quot;Multiple&quot; is set according to a variable then I&#39;m not going to try to follow all possible code paths to ensure that it is never true/false if Values/Value is set. I&#39;m also not going to cater for the technically-valid case where someone instantiates a &lt;strong&gt;SelectAttributes&lt;/strong&gt; and sets &quot;Values&quot; on it initially (but leaves &quot;Multiple&quot; as false) and then sets &quot;Multiple&quot; to true on a later line of code. While this would be valid (there would be no runtime warning), I think that it would be clearer to set &quot;Multiple&quot; &lt;em&gt;and&lt;/em&gt; &quot;Values&quot; together. In this case, I&#39;m imposing what I believe to be a best practice on the consumer of my library - some analysers do this, some don&#39;t.&lt;/p&gt;

&lt;p&gt;To keep things as simple as possible for now, instead of trying to pull in the real Bridge.React library, we&#39;ll just create another class library project in the solution to work against - call it &quot;Bridge.React&quot; and rename the &quot;Class1.cs&quot; file that is automatically created as part of a class library project to &quot;SelectAttributes.cs&quot;. Change its contents to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace Bridge.React
{
    public sealed class SelectAttributes
    {
        public bool Multiple { private get; set; }
        public string Value { private get; set; }
        public string[] Values { private get; set; }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will be enough to start writing the analyser.&lt;/p&gt;

&lt;p&gt;What I want to do is to take the example analyser from the &quot;Analyzer with Code Fix (NuGet + VSIX)&quot; and change it to ensure that &lt;strong&gt;SelectAttributes&lt;/strong&gt; properties are always configured according to the rule outlined above. Before getting started on that, though, it seems like a good time to formalise the rules by decribing them with unit tests. We get many bonuses here - writing individual tests may help guide us through fixing them up one at a time and so help us focus on individual problems that the analyser has to solve. It will also provide us with a way to exercise the analyser and step through it with the debugger (which I find invaluable when I&#39;m not very familiar with a library or object model - when I &lt;em&gt;do&lt;/em&gt; have a good grasp on code then stepping through a debugger can feel very time-consuming but it can be helpful in cases like this, as I&#39;ll demonstrate shortly). Finally, the tests will help avoid regressions creeping in if I decide to refactor the analyser or extend its functionality in the future.&lt;/p&gt;

&lt;p&gt;So, replace the contents of &quot;UnitTest.cs&quot; with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Microsoft.CodeAnalysis;
using Microsoft.CodeAnalysis.Diagnostics;
using Microsoft.VisualStudio.TestTools.UnitTesting;
using TestHelper;

namespace ExampleAnalyser.Test
{
    [TestClass]
    public class UnitTest : DiagnosticVerifier
    {
        [TestMethod]
        public void DoNotUseValueWhenMultipleIsTrue()
        {
            var testContent = @&quot;
                using Bridge.React;

                namespace TestCase
                {
                    public class Example
                    {
                        public void Go()
                        {
                            new SelectAttributes { Multiple = true, Value = &quot;&quot;1&quot;&quot; };
                        }
                    }
                }&quot;;

            var expected = new DiagnosticResult
            {
                Id = ExampleAnalyserAnalyzer.DiagnosticId,
                Message = &quot;If &#39;Multiple&#39; is true then the &#39;Values&#39; property should be used instead of &#39;Value&#39;&quot;,
                Severity = DiagnosticSeverity.Warning,
                Locations = new[]
                {
                    new DiagnosticResultLocation(&quot;Test0.cs&quot;, 10, 29)
                }
            };

            VerifyCSharpDiagnostic(testContent, expected);
        }

        [TestMethod]
        public void DoNotUseValuesWhenMultipleIsFalse()
        {
            var testContent = @&quot;
                using Bridge.React;

                namespace TestCase
                {
                    public class Example
                    {
                        public void Go()
                        {
                            new SelectAttributes { Multiple = false, Values = new[] { &quot;&quot;1&quot;&quot; } };
                        }
                    }
                }&quot;;

            var expected = new DiagnosticResult
            {
                Id = ExampleAnalyserAnalyzer.DiagnosticId,
                Message = &quot;If &#39;Multiple&#39; is false then the &#39;Value&#39; property should be used instead of &#39;Values&#39;&quot;,
                Severity = DiagnosticSeverity.Warning,
                Locations = new[]
                {
                    new DiagnosticResultLocation(&quot;Test0.cs&quot;, 10, 29)
                }
            };

            VerifyCSharpDiagnostic(testContent, expected);
        }

        [TestMethod]
        public void DoNotUseValueWhenMultipleDefaultsToFalse()
        {
            var testContent = @&quot;
                using Bridge.React;

                namespace TestCase
                {
                    public class Example
                    {
                        public void Go()
                        {
                            var x = new SelectAttributes { Values = new[] { &quot;&quot;1&quot;&quot; } };
                            x.Multiple = True;
                        }
                    }
                }&quot;;

            var expected = new DiagnosticResult
            {
                Id = ExampleAnalyserAnalyzer.DiagnosticId,
                Message = &quot;If &#39;Multiple&#39; is false then the &#39;Value&#39; property should be used instead of &#39;Values&#39;&quot;,
                Severity = DiagnosticSeverity.Warning,
                Locations = new[]
                {
                    new DiagnosticResultLocation(&quot;Test0.cs&quot;, 10, 37)
                }
            };

            VerifyCSharpDiagnostic(testContent, expected);
        }

        protected override DiagnosticAnalyzer GetCSharpDiagnosticAnalyzer()
        {
            return new ExampleAnalyserAnalyzer();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now there&#39;s one more important thing to do before actually writing the analyser. When those unit tests run, the &quot;.NET Compiler Platform&quot; (referred to as &quot;Roslyn&quot;) will parse and compile those code snippets in memory. This means that the code snippets need to actually be able to compile! Currently they won&#39;t because Roslyn won&#39;t know how to resolve the &quot;Bridge.React&quot; namespace that is referenced.&lt;/p&gt;

&lt;p&gt;This is quite easily fixed - the &lt;strong&gt;DiagnosticVerifier&lt;/strong&gt; class (which is part of the template that we started with) configures some environment options. That&#39;s why each test checks a file called &quot;Test0.cs&quot; - because Roslyn wants a filename to work with and that&#39;s what the &lt;strong&gt;DiagnosticVerifier&lt;/strong&gt; tells it to use. It also specifies what assemblies to include when building the project. So, if the code snippets referenced &quot;System&quot; or &quot;Sytem.Collections.Generic&quot; then those references will work fine. However, it doesn&#39;t initially know about the &quot;Bridge.React&quot; project, so we need to tell it to support it.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add a reference to the &quot;Bridge.React&quot; project to the &quot;ExampleAnalayser.Test&quot; project&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Edit the file &quot;Helpers/DiagnosticVerifier.Helper.cs&quot; in the &quot;ExampleAnalayser.Test&quot; project and add the following near the top, where other &lt;strong&gt;MetadataReference&lt;/strong&gt; instances are created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static readonly MetadataReference CSharpBridgeReactReference
    = MetadataReference.CreateFromFile(typeof(Bridge.React.SelectAttributes).Assembly.Location);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open all of the code regions in that file and add pass &quot;CSharpBridgeReactReference&quot; into the solution by adding an additional &quot;AddMetadataReference&quot; call. The &quot;CreateProject&quot; method should now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static Project CreateProject(string[] sources, string language = LanguageNames.CSharp)
{
    string fileNamePrefix = DefaultFilePathPrefix;
    string fileExt = language == LanguageNames.CSharp
        ? CSharpDefaultFileExt
        : VisualBasicDefaultExt;
    var projectId = ProjectId.CreateNewId(debugName: TestProjectName);
    var solution = new AdhocWorkspace()
    .CurrentSolution
        .AddProject(projectId, TestProjectName, TestProjectName, language)
        .AddMetadataReference(projectId, CorlibReference)
        .AddMetadataReference(projectId, SystemCoreReference)
        .AddMetadataReference(projectId, CSharpSymbolsReference)
        .AddMetadataReference(projectId, CodeAnalysisReference)
        .AddMetadataReference(projectId, CSharpBridgeReactReference);
    int count = 0;
    foreach (var source in sources)
    {
        var newFileName = fileNamePrefix + count + &quot;.&quot; + fileExt;
        var documentId = DocumentId.CreateNewId(projectId, debugName: newFileName);
        solution = solution.AddDocument(documentId, newFileName, SourceText.From(source));
        count++;
    }
    return solution.GetProject(projectId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;&lt;em&gt;Really&lt;/em&gt; writing the analyser&lt;/h3&gt;

&lt;p&gt;Now that the groundwork is done and we&#39;ve decided what precisely needs doing (and documented it with tests), we need to write the actual code.&lt;/p&gt;

&lt;p&gt;Although I can use the debugger to inspect the syntax tree for the code snippets in the unit tests, at this point I think even that would be information overload. To begin with, just add the following line to one of the unit test methods - it doesn&#39;t matter which one because it will be deleted very shortly, it&#39;s just to have a bit of a poke around with the Syntax Visualizer:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var x = new Bridge.React.SelectAttributes { Multiple = true, Value = &quot;x&quot; };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ensuring that the Syntax Visualizer is visible (View / Other Windows / Syntax Visualizer), clicking on &quot;Multiple&quot; shows the following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/ObjectInitializerExpression.png&quot; alt=&quot;ObjectInitializerExpression&quot;&gt;&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;IdentifierToken&lt;/strong&gt; is the &quot;Multiple&quot; property, which is part of a &lt;strong&gt;SimpleAssignment&lt;/strong&gt; (ie. &quot;Multiple = 1&quot;) which is a child of an &lt;strong&gt;ObjectInitializerExpression&lt;/strong&gt; (which is the curly brackets around the two properties being set) which is a child of an &lt;strong&gt;ObjectCreationExpression&lt;/strong&gt; (which is the entire statement that includes &quot;new Bridge.React.SelectAttributes&quot; &lt;em&gt;and&lt;/em&gt; the setting of the two properties) and that itself is part of a &lt;strong&gt;VariableDeclaration&lt;/strong&gt; (which sets &quot;x&quot; to be the result of the object creation). With the Syntax Visualizer, we could go all the way up to the top of the method and then to the class and then to the namespace and then to the top-level CompilationUnit. However, what we&#39;re most interested in is the &lt;strong&gt;ObjectInitializerExpression&lt;/strong&gt;, since that contains the properties that we want to verify.&lt;/p&gt;

&lt;p&gt;So, how do we alter the analyser class that we currently have in order to identify object initialisers such as this?&lt;/p&gt;

&lt;p&gt;Currently the example analyser class has an &quot;Initialize&quot; method that looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public override void Initialize(AnalysisContext context)
{
    context.RegisterSymbolAction(AnalyzeSymbol, SymbolKind.NamedType);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing to try would be to see what other options are in the &quot;SymbolKind&quot; enum. However, this contains things like &quot;Alias&quot;, &quot;Event&quot;, &quot;Method&quot;, &quot;NamedType&quot;, &quot;Property&quot; which don&#39;t bear much resemblance to &lt;strong&gt;ObjectInitializerExpression&lt;/strong&gt;. Without any better plan, I recommend turning to Google. If &quot;SymbolKind&quot; doesn&#39;t seem to have what we want, maybe there&#39;s something else that we can extract from the &lt;strong&gt;AnalysisContext&lt;/strong&gt; instance that the &quot;Initialize&quot; method has.&lt;/p&gt;

&lt;p&gt;Googling for &lt;a href=&quot;https://www.google.co.uk/search?q=AnalysisContext+ObjectInitializerExpression&quot;&gt;&quot;AnalysisContext ObjectInitializerExpression&quot;&lt;/a&gt; doesn&#39;t actually return that many results. However, the second one &lt;a href=&quot;https://github.com/mjsabby/RoslynClrHeapAllocationAnalyzer/blob/master/ClrHeapAllocationsAnalyzer/ExplicitAllocationAnalyzer.cs&quot;&gt;RoslynClrHeapAllocationAnalyzer/ExplicitAllocationAnalyzer.cs&lt;/a&gt; has some code that looks promising:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public override void Initialize(AnalysisContext context)
{
    var kinds = new[]
    {
        SyntaxKind.ObjectCreationExpression,
        SyntaxKind.AnonymousObjectCreationExpression,
        SyntaxKind.ArrayInitializerExpression,
        SyntaxKind.CollectionInitializerExpression,
        SyntaxKind.ComplexElementInitializerExpression,
        SyntaxKind.ObjectInitializerExpression,
        SyntaxKind.ArrayCreationExpression,
        SyntaxKind.ImplicitArrayCreationExpression,
        SyntaxKind.LetClause
    };
    context.RegisterSyntaxNodeAction(AnalyzeNode, kinds);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead of calling &quot;RegisterSymbolAction&quot; and passing a &quot;SymbolKind&quot; value, we can call &quot;RegisterSyntaxNodeAction&quot; and pass it an array of &quot;SyntaxKind&quot; values - where &quot;SyntaxKind&quot; is an enum that has an &quot;ObjectInitializerExpression&quot; value.&lt;/p&gt;

&lt;p&gt;Actually, by starting to change the &quot;Initialize&quot; method to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public override void Initialize(AnalysisContext context)
{
    context.RegisterSyntaxNodeAction(AnalyzeSymbol,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. it becomes clear that the method actually takes a params array and so it will be perfectly happy for us to specify only a single &quot;SyntaxKind&quot; value. &quot;Initialize&quot; now becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public override void Initialize(AnalysisContext context)
{
    context.RegisterSyntaxNodeAction(
        AnalyzeSymbol,
        SyntaxKind.ObjectInitializerExpression
    );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But the analyser project doesn&#39;t compile now - it complains about the type of one of the arguments of the call to &quot;SymbolAnalysisContext&quot;. It definitely takes a &quot;SyntaxKind&quot; enum as its second argument so it must be the first that is wrong. Intellisense indicates that it wants the first argument to be of type &lt;strong&gt;Action&amp;lt;SymbolAnalysisContext&amp;gt;&lt;/strong&gt; but the &quot;AnalyzeSymbol&quot; method currently takes a &lt;strong&gt;SyntaxNodeAnalysisContext&lt;/strong&gt; (and so is an &lt;strong&gt;Action&amp;lt;SymbolAnalysisContext&amp;gt;&lt;/strong&gt;, rather than an &lt;strong&gt;Action&amp;lt;SyntaxNodeAnalysisContext&amp;gt;&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;This is easily fixed by changing the argument of the &quot;AnalyzeSymbol&quot; method. Doing so, however, will mean that &lt;em&gt;it&lt;/em&gt; causes a compile error because the example code was expecting a &lt;strong&gt;SymbolAnalysisContext&lt;/strong&gt; and we want to give it a &lt;strong&gt;SyntaxNodeAnalysisContext&lt;/strong&gt;. No matter, that code doesn&#39;t do what we want anyway! So change the method argument, delete its body and - while we&#39;re making changes - rename it to something better than &quot;AnalyzeSymbol&quot;, such as &quot;LookForInvalidSelectAttributeProperties&quot; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public override void Initialize(AnalysisContext context)
{
    context.RegisterSyntaxNodeAction(
        LookForInvalidSelectAttributeProperties,
        SyntaxKind.ObjectInitializerExpression
    );
}

private static void LookForInvalidSelectAttributeProperties(SyntaxNodeAnalysisContext context)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the basic structure is there, we can start work on the new &quot;LookForInvalidSelectAttributeProperties&quot; implementation. The &quot;context&quot; reference that is passed in has a &quot;Node&quot; property and this will match the SyntaxKind value that we passed to &quot;RegisterSyntaxNodeAction&quot;. So &quot;context.Node&quot; will be a reference to a node that represents an &quot;object initialisation&quot;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sanity check: The &lt;strong&gt;SyntaxNode&lt;/strong&gt; class (which is the base node class) has a &quot;Kind()&quot; method that will return the &quot;SyntaxKind&quot; enum value that applies to the current node - so calling &quot;Kind()&quot; on &quot;context.Node&quot; here will return the &quot;ObjectInitializerExpression&quot; option from the &quot;SyntaxKind&quot; enum.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now that we have a reference to an object initialisation node, we can go one of two ways. We want to ensure that the type being initialised is the &lt;strong&gt;SelectAttributes&lt;/strong&gt; class from the &quot;Bridge.React&quot; assembly and we want to check whether any invalid property combinations are being specified. The first task will involve getting the type name and then doing a lookup in the rest of the solution to work out where that type name comes from (to ensure that it is actually the &quot;Bridge.React&quot; &lt;strong&gt;SelectAttributes&lt;/strong&gt; class and not another class that exists somewhere with the same name). The second task only requires us to look at what properties are set by code in the syntax tree that we already have. This means that the first task is more expensive to perform than the second task and so we should try to deal with &quot;step two&quot; first since we will be able to avoid &quot;step one&quot; altogether if no invalid property combinations appear.&lt;/p&gt;

&lt;p&gt;So, to look for invalid property combinations first.. The Syntax Visualizer (as seen in the last image) shows that each individual property-setting is represented by a &quot;SimpleAssignmentExpression&quot; and that each of these is a direct child of the object initialisation. The &lt;strong&gt;SyntaxNode&lt;/strong&gt; class has a ChildNodes() method that will return all of the children, which seems like a good place to start. So, we might be able to do something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// This doesn&#39;t work,SimpleAssignmentExpressionSyntax isn&#39;t a real class :(
var propertyInitialisers = context.Node.ChildNodes()
    .OfType&amp;lt;SimpleAssignmentExpressionSyntax&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. however, &quot;SimpleAssignmentExpressionSyntax&quot; is not a real type. I tried starting to type  out &quot;Simple&quot; to see if intellisense would pick up what the correct name was - but that didn&#39;t get me anywhere.&lt;/p&gt;

&lt;p&gt;Next, I resorted to deleting those last few lines (since they don&#39;t compile) and to just putting a breakpoint at the top of &quot;LookForInvalidSelectAttributeProperties&quot;. I then used Debug Tests on &quot;DoNotUseValueWhenMultipleIsTrue&quot;. The breakpoint is hit.. but I can&#39;t see the child nodes with QuickWatch because &quot;ChildNodes()&quot; is a method, not a property, and QuickWatch only shows you property values (it doesn&#39;t offter to execute methods and show you what is returned). So I go to the Immediate Window (Debug / Windows / Immediate), type the following and hit [Enter] -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;context.Node.ChildNodes().First().GetType().Name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This displays &quot;AssignmentExpressionSyntax&quot;.&lt;/p&gt;

&lt;p&gt;This clue is enough to stop the debugger and go back to trying to populate the &quot;LookForInvalidSelectAttributeProperties&quot;. It may now start with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var propertyInitialisers = context.Node.ChildNodes()
    .OfType&amp;lt;AssignmentExpressionSyntax&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using Go To Definition on &lt;strong&gt;AssignmentExpressionSyntax&lt;/strong&gt; shows that it has a &quot;Left&quot; and a &quot;Right&quot; property. These are the expressions that come either side of the operator, which is always an Equals sign when considering object property initialisations.&lt;/p&gt;

&lt;p&gt;The Syntax Visualizer shows that each &quot;SimpleAssignmentExpression&quot; has an &quot;IdentifierName&quot; on the left, so we should be able to get the property name from that.&lt;/p&gt;

&lt;p&gt;To try to work out what type &quot;IdentifierName&quot; relates to, I start typing &quot;Identifier&quot; and intellisense suggests &lt;strong&gt;IdentifierNameSyntax&lt;/strong&gt; (if it hadn&#39;t suggested anything helpful then I would have resorted to using Debug Tests again and inspecting types in the debugger). Having a poke around the &lt;strong&gt;IdentifierNameSyntax&lt;/strong&gt; class, I see that it has a property &quot;Identifier&quot; and that has a string property &quot;ValueText&quot;. This looks like the name of the property being set. Things are coming together. The start of the &quot;LookForInvalidSelectAttributeProperties&quot; can now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var propertyInitialisers = context.Node.ChildNodes()
    .OfType&amp;lt;AssignmentExpressionSyntax&amp;gt;()
    .Select(propertyInitialiser =&amp;gt; new
    {
        PropertyName = ((IdentifierNameSyntax)propertyInitialiser.Left).Identifier.ValueText,
        ValueExpression = propertyInitialiser.Right
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&#39;s worth noting that we don&#39;t have to worry about the &quot;Left&quot; property ever being anything other than a simple identifier because assignments in object initialisers are only ever allow to be simple assignments. For example, the following would not compile:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var x = new MyClass { Name.Value = &quot;Ted };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. because attempting to set nested properties in object initialisers does not compile in C#. Because it&#39;s not valid C#, we don&#39;t have to worry about it being passed through the analyser.&lt;/p&gt;

&lt;p&gt;Maybe it&#39;s worth adding another unit test around this - to ensure that invalid C# can&#39;t result in a load of edge cases that we need to be concerned about:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[TestMethod]
public void IgnoreInvalidPropertySetting()
{
    var testContent = @&quot;
        using Bridge.React;

        namespace TestCase
        {
            public class Example
            {
                public void Go()
                {
                    new SelectAttributes { Nested.Multiple = true };
                }
            }
        }&quot;;

    VerifyCSharpDiagnostic(testContent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note: Calling the &quot;VerifyCSharpDiagnostic&quot; with no &quot;expected&quot; value means that the test expects that the analyser will not report any violated rules.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now we can really move things along. We&#39;re interested in property initialisers where &quot;Multiple&quot; is clearly true or false (meaning it is set specifically to true or false &lt;em&gt;or&lt;/em&gt; it&#39;s not specified at all, leaving it with its default value of false). So, again using the Syntax Visualizer to work out how to tell whether an expression means a &quot;true&quot; constant or a &quot;false&quot; constant, I&#39;ve come up with this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var propertyInitialisers = context.Node.ChildNodes()
    .OfType&amp;lt;AssignmentExpressionSyntax&amp;gt;()
    .Select(propertyInitialiser =&amp;gt; new
    {
        PropertyName = ((IdentifierNameSyntax)propertyInitialiser.Left).Identifier.ValueText,
        ValueExpression = propertyInitialiser.Right
    });

var multiplePropertyInitialiser = propertyInitialisers.FirstOrDefault(
    propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Multiple&quot;
);
bool multiplePropertyValue;
if (multiplePropertyInitialiser == null)
    multiplePropertyValue = false; // Defaults to false if not explicitlt set
else
{
    var multiplePropertyValueKind = multiplePropertyInitialiser.ValueExpression.Kind();
    if (multiplePropertyValueKind == SyntaxKind.TrueLiteralExpression)
        multiplePropertyValue = true;
    else if (multiplePropertyValueKind == SyntaxKind.FalseLiteralExpression)
        multiplePropertyValue = false;  
    else
    {
        // Only looking for very simple cases - where explicitly set to true or to false or not set at
        // all (defaulting to false). If it&#39;s set according to a method return value or a variable then
        // give up (this is just intended to catch obvious mistakes, not to perform deep and complex
        // analysis)
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next thing to do is to look for a &quot;Value&quot; or &quot;Values&quot; property being specified that is not appropriate for the &quot;Multiple&quot; value that we&#39;ve found.&lt;/p&gt;

&lt;p&gt;From the above code, it should be fairly clear that the way to do this is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var valuePropertyIsSpecified = propertyInitialisers.Any(
    propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Value&quot;
);
var valuesPropertyIsSpecified = propertyInitialisers.Any(
    propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Values&quot;
);
if (!valuePropertyIsSpecified &amp;amp;&amp;amp; !valuesPropertyIsSpecified)
    return;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final step is to ensure that the object initialisation that we&#39;re looking at is indeed for a &lt;strong&gt;SelectAttributes&lt;/strong&gt; instance. This is the bit that requires a lookup into the &quot;SemanticModel&quot; and which is more expensive than just looking at the current syntax tree because it needs the project to compile and to then work out what references to external code there may be.&lt;/p&gt;

&lt;p&gt;Knowing that I&#39;m going to be dealing with the full semantic model, I&#39;ll start by looking through the methods available on &quot;context.SemanticModel&quot; to see what might help me. Using the intellisense / documentation, it doesn&#39;t take long to find a &quot;GetTypeInfo&quot; method that takes an &lt;strong&gt;ObjectCreationExpression&lt;/strong&gt; instance - this is ideal because we have an &lt;strong&gt;ObjectInitializerExpressionSyntax&lt;/strong&gt; and we know that an &lt;strong&gt;ObjectInitializerExpressionSyntax&lt;/strong&gt; is a child of an &lt;strong&gt;ObjectCreationExpressionSyntax&lt;/strong&gt;, so it&#39;s easy for us to get an &lt;strong&gt;ObjectCreationExpression&lt;/strong&gt; (it&#39;s just the parent of &lt;strong&gt;ObjectInitializerExpressionSyntax&lt;/strong&gt; that we have).&lt;/p&gt;

&lt;p&gt;&quot;GetTypeInfo&quot; returns a &lt;strong&gt;TypeInfo&lt;/strong&gt; instance which has two properties; &quot;Type&quot; and &quot;ConvertedType&quot;. &quot;ConvertedType&quot; is (taken from the xml summary documentation):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The type of the expression after it has undergone an implicit conversion&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;which shouldn&#39;t apply here, so we&#39;ll just look at &quot;Type&quot;. Note, though, that the documentation for &quot;Type&quot; says that:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For expressions that do not have a type, null is returned. If the type could not be determined due to an error, than an IErrorTypeSymbol is returned.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since this is an object creation expression, there should &lt;em&gt;always&lt;/em&gt; be a type returned (the type of the object being instantiated) but we do need to be careful about the error response. Here, it&#39;s fine to stop processing if there&#39;s an error - it might mean that there is a &quot;new SelectAttributes&quot; statements in the code being analysed but no &quot;Using Bridge.React;&quot; at the top of the file. We&#39;ll ignore these error cases and plan to only analyse valid code.&lt;/p&gt;

&lt;p&gt;This is the code that needs adding to ensure that the properties that we&#39;re looking at are for a Bridge.React.SelectAttributes -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var objectCreation = (ObjectCreationExpressionSyntax)context.Node.Parent;
var objectCreationTypeInfo = context.SemanticModel.GetTypeInfo(objectCreation);
if ((objectCreationTypeInfo.Type is IErrorTypeSymbol)
|| (objectCreationTypeInfo.Type.ContainingAssembly.Identity.Name != &quot;Bridge.React&quot;)
|| (objectCreationTypeInfo.Type.Name != &quot;SelectAttributes&quot;))
    return;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Having written this code, it strikes me as a good idea to add another test - one that ensures that we don&#39;t raise false positives about &quot;Multiple&quot; and &quot;Value&quot; / &quot;Values&quot; in cases where it&#39;s a different &lt;strong&gt;SelectAttributes&lt;/strong&gt; class, that is declared somewhere other than in &quot;Bridge.React&quot;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/// &amp;lt;summary&amp;gt;
/// Don&#39;t analyse a SelectAttributes initialisation that is for a different SelectAttributes class
/// (only target the SelectAttributes class that is part of the Bridge.React library)
/// &amp;lt;/summary&amp;gt;
[TestMethod]
public void OnlyTargetBridgeReactSelectAttributes()
{
    var testContent = @&quot;
        namespace TestCase
        {
            public class Example
            {
                public void Go()
                {
                    new SelectAttributes { Multiple = true, Value = &quot;&quot;x&quot;&quot; };
                }
            }

            public class SelectAttributes
            {
                public bool Multiple { get; set; }
                public string Value { get; set; }
            }
        }&quot;;

    VerifyCSharpDiagnostic(testContent);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have all of the required information to display a warning for invalid &quot;Multiple&quot; / &quot;Value&quot; / &quot;Values&quot; combinations. What we &lt;em&gt;don&#39;t&lt;/em&gt; have is appropriate message content to display - we&#39;ve only got the warning content from the example analyser in the project template.&lt;/p&gt;

&lt;p&gt;So delete all of the code at the top of the analyser - the const and static strings, the &quot;Rule&quot; reference and the &quot;SupportedDiagnostics&quot; property and replace them with this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public const string DiagnosticId = &quot;Bridge.React&quot;;
private static readonly LocalizableString Title
    = &quot;Be careful to use the appropriate &#39;Value&#39; or &#39;Values&#39; property for the &#39;Multiple&#39; setting&quot;;
private static readonly LocalizableString MultipleWithValueMessage
    = &quot;If &#39;Multiple&#39; is true then the &#39;Values&#39; property should be used instead of &#39;Value&#39;&quot;;
private static readonly LocalizableString NoMultipleWithValuesMessage
    = &quot;If &#39;Multiple&#39; is false then the &#39;Value&#39; property should be used instead of &#39;Values&#39;&quot;;
private const string Category = &quot;Configuration&quot;;

private static DiagnosticDescriptor MultipleWithValueRule = new DiagnosticDescriptor(
    DiagnosticId,
    Title,
    MultipleWithValueMessage,
    Category,
    DiagnosticSeverity.Warning,
    isEnabledByDefault: true
);
private static DiagnosticDescriptor NoMultipleWithValuesRule = new DiagnosticDescriptor(
    DiagnosticId,
    Title,
    NoMultipleWithValuesMessage,
    Category,
    DiagnosticSeverity.Warning,
    isEnabledByDefault: true
);

public override ImmutableArray&amp;lt;DiagnosticDescriptor&amp;gt; SupportedDiagnostics
{
    get { return ImmutableArray.Create(MultipleWithValueRule, NoMultipleWithValuesRule); }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final step, then, is to report rules when they are broken. The following needs adding to the end of the &quot;LookForInvalidSelectAttributeProperties&quot; method in order to complete it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if ((multiplePropertyValue == true) &amp;amp;&amp;amp; valuePropertyIsSpecified)
{
    context.ReportDiagnostic(Diagnostic.Create(
        MultipleWithValueRule,
        context.Node.GetLocation()
    ));
}
else if ((multiplePropertyValue == false) &amp;amp;&amp;amp; valuesPropertyIsSpecified)
{
    context.ReportDiagnostic(Diagnostic.Create(
        NoMultipleWithValuesRule,
        context.Node.GetLocation()
    ));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Localisation support&lt;/h3&gt;

&lt;p&gt;There&#39;s just one final thing to do now, which is more of a good practice than an essential - that is to replace the hard-coded strings in the analyser class with resources (that may potentially be translated into different languages one day). The project template includes a &quot;Resources.resx&quot; file, which is where we should move these strings to. Edit that file in Visual Studio and delete the existing entries and then add the following Name and Value pairs:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Name:&lt;/strong&gt; SelectAttributesAnalyserTitle&lt;/p&gt;
  
  &lt;p&gt;&lt;strong&gt;Value:&lt;/strong&gt; Be careful to use the appropriate &#39;Value&#39; or &#39;Values&#39; property for the &#39;Multiple&#39; setting&lt;/p&gt;
  
  &lt;p&gt;&lt;strong&gt;Name:&lt;/strong&gt; SelectAttributesAnalyserMultipleWithValueMessage&lt;/p&gt;
  
  &lt;p&gt;&lt;strong&gt;Value:&lt;/strong&gt; If &#39;Multiple&#39; is true then the &#39;Values&#39; property should be used instead of &#39;Value&#39;&lt;/p&gt;
  
  &lt;p&gt;&lt;strong&gt;Name:&lt;/strong&gt; SelectAttributesAnalyserNoMultipleWithValuesTitle&lt;/p&gt;
  
  &lt;p&gt;&lt;strong&gt;Value:&lt;/strong&gt; If &#39;Multiple&#39; is false then the &#39;Value&#39; property should be used instead of &#39;Values&#39;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To make accessing these resources a little easier, add the following method to the bottom of the analyser class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static LocalizableString GetLocalizableString(string nameOfLocalizableResource)
{
    return new LocalizableResourceString(
        nameOfLocalizableResource,
        Resources.ResourceManager,
        typeof(Resources)
    );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, replace the three hard-coded string property initialisers with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    private static readonly LocalizableString Title = GetLocalizableString(
        nameof(Resources.SelectAttributesAnalyserTitle)
    );
    private static readonly LocalizableString MultipleWithValueTitle = GetLocalizableString(
        nameof(Resources.SelectAttributesAnalyserMultipleWithValueMessage)
    );
    private static readonly LocalizableString NoMultipleWithValuesTitle = GetLocalizableString(
        nameof(Resources.SelectAttributesAnalyserNoMultipleWithValuesTitle)
    );
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Summary&lt;/h3&gt;

&lt;p&gt;That completes the analyser. I&#39;ve included the complete source code for the final implementation below - now that it&#39;s written it doesn&#39;t look like much, which hopefully illustrates how powerful and complete the Roslyn library is. And, hopefully, it&#39;s shown that this powerful library doesn&#39;t need to be daunting because there&#39;s many resources out there for helping you understand how to use it; people have written a lot about it and so Googling for terms relating to what you want to do often yields helpful results, people have answered a lot of questions about it on Stack Overflow and so you will often find example and sample code there.&lt;/p&gt;

&lt;p&gt;If you&#39;re not sure what terms to use to try to search for help then using the Syntax Visualizer to explore your code can set you on the right path, as can writing a test or two and then examining the &quot;context.Node&quot; reference in the debugger (if you do this then ensure that you are building your project in Debug mode since Release builds may prevent your breakpoints from being hit and may optimise some of the variable references away, which will mean that you won&#39;t be able to use QuickWatch on them). Finally, don&#39;t forget that there is a lot of helpful information in the xml summary documentation that&#39;s available in Visual Studio when you examine the Roslyn classes and their methods - often the names of methods are descriptive enough to help you choose the appropriate one or, at least, give you a clue as to what direction to go in.&lt;/p&gt;

&lt;p&gt;This has really only scraped the surface of what analysers are capable of, it&#39;s a technology with huge capability and potential. I might talk about other uses for analysers (or talk about how particular analysers may be implemented) another day but two topics that I definitely &lt;em&gt;will&lt;/em&gt; talk about soon are &quot;code fixes&quot; and how to get analysers to work with &lt;a href=&quot;http://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt; libraries.&lt;/p&gt;

&lt;p&gt;Code fixes are interesting because they allow you to go beyond just saying &quot;this is wrong&quot; to saying &quot;this is how it may be fixed (automatically, by the IDE)&quot;. For example, if someone changed a &lt;strong&gt;SelectAttributes&lt;/strong&gt; instantiation to enable multiple selections - eg. started with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOM.Select(
    new SelectAttributes { Value = selectedId },
    options
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. and changed it to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOM.Select(
    new SelectAttributes { Multiple = true, Value = selectedId },
    options
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then the analyser could point out that the &quot;Value&quot; property should not be used now that &quot;Multiple&quot; is true but it could also offer to fix it up to the following &lt;em&gt;automatically&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOM.Select(
    new SelectAttributes { Multiple = true, Values = new[] { selectedId } },
    options
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There will be times that the warning from an analyser will require manual intervention to correct but there will also be times where the computer could easily correct it, so it&#39;s great having the ability to explain to the computer &lt;em&gt;how&lt;/em&gt; to do so and thus make life that bit easier for the person consuming your library.&lt;/p&gt;

&lt;p&gt;The reason that I also want to spend a little bit of time talking about making analysers work with Bridge.NET libraries soon is that it&#39;s something of a special case since Bridge projects don&#39;t have references to the standard .net System, System.Collections, etc.. assemblies because they are replaced by special versions of those libraries that have JavaScript translations. This means that you can&#39;t reference a Bridge library from a project that relies on the standard .net assemblies, which is a bit of a problem when you want to write a Roslyn analyser for types in a Bridge library (since the analyser project will rely on standard .net assemblies and the analyser will want to reference the Bridge library whose rules are to be applied by the analyser). But there are ways to get around it and I&#39;ll go through that another time.&lt;/p&gt;

&lt;h3&gt;The complete analyser&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Immutable;
using System.Linq;
using System.Reflection;
using Microsoft.CodeAnalysis;
using Microsoft.CodeAnalysis.CSharp;
using Microsoft.CodeAnalysis.CSharp.Syntax;
using Microsoft.CodeAnalysis.Diagnostics;

namespace ExampleAnalyser
{
    [DiagnosticAnalyzer(LanguageNames.CSharp)]
    public sealed class ExampleAnalyserAnalyzer : DiagnosticAnalyzer
    {
        public const string DiagnosticId = &quot;Bridge.React&quot;;
        private static readonly LocalizableString Title = GetLocalizableString(
            nameof(Resources.SelectAttributesAnalyserTitle)
        );
        private static readonly LocalizableString MultipleWithValueTitle = GetLocalizableString(
            nameof(Resources.SelectAttributesAnalyserMultipleWithValueMessage)
        );
        private static readonly LocalizableString NoMultipleWithValuesTitle = GetLocalizableString(
            nameof(Resources.SelectAttributesAnalyserNoMultipleWithValuesTitle)
        );
        private const string Category = &quot;Configuration&quot;;

        private static DiagnosticDescriptor MultipleWithValueRule = new DiagnosticDescriptor(
            DiagnosticId,
            Title,
            MultipleWithValueTitle,
            Category,
            DiagnosticSeverity.Warning,
            isEnabledByDefault: true
        );
        private static DiagnosticDescriptor NoMultipleWithValuesRule = new DiagnosticDescriptor(
            DiagnosticId,
            Title,
            NoMultipleWithValuesTitle,
            Category,
            DiagnosticSeverity.Warning,
            isEnabledByDefault: true
        );

        public override ImmutableArray&amp;lt;DiagnosticDescriptor&amp;gt; SupportedDiagnostics
        {
            get { return ImmutableArray.Create(MultipleWithValueRule, NoMultipleWithValuesRule); }
        }

        public override void Initialize(AnalysisContext context)
        {
            context.RegisterSyntaxNodeAction(
                LookForInvalidSelectAttributeProperties,
                SyntaxKind.ObjectInitializerExpression
            );
        }

        private static void LookForInvalidSelectAttributeProperties(SyntaxNodeAnalysisContext context)
        {
            var propertyInitialisers = context.Node.ChildNodes()
                .OfType&amp;lt;AssignmentExpressionSyntax&amp;gt;()
                .Select(propertyInitialiser =&amp;gt; new
                {
                    PropertyName = ((IdentifierNameSyntax)propertyInitialiser.Left).Identifier.ValueText,
                    ValueExpression = propertyInitialiser.Right
                });

            var multiplePropertyInitialiser = propertyInitialisers.FirstOrDefault(
                propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Multiple&quot;
            );
            bool multiplePropertyValue;
            if (multiplePropertyInitialiser == null)
                multiplePropertyValue = false; // Defaults to false if not explicitlt set
            else
            {
                var multiplePropertyValueKind = multiplePropertyInitialiser.ValueExpression.Kind();
                if (multiplePropertyValueKind == SyntaxKind.TrueLiteralExpression)
                    multiplePropertyValue = true;
                else if (multiplePropertyValueKind == SyntaxKind.FalseLiteralExpression)
                    multiplePropertyValue = false;
                else
                {
                    // Only looking for very simple cases - where explicitly set to true or to false or
                    // not set at all (defaulting to false). If it&#39;s set according to a method return
                    // value or a variable then give up (this is just intended to catch obvious
                    // mistakes, not to perform deep and complex analysis)
                    return;
                }
            }

            var valuePropertyIsSpecified = propertyInitialisers.Any(
                propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Value&quot;
            );
            var valuesPropertyIsSpecified = propertyInitialisers.Any(
                propertyInitialiser =&amp;gt; propertyInitialiser.PropertyName == &quot;Values&quot;
            );
            if (!valuePropertyIsSpecified &amp;amp;&amp;amp; !valuesPropertyIsSpecified)
                return;

            var objectCreation = (ObjectCreationExpressionSyntax)context.Node.Parent;
            var objectCreationTypeInfo = context.SemanticModel.GetTypeInfo(objectCreation);
            if ((objectCreationTypeInfo.Type is IErrorTypeSymbol)
            || (objectCreationTypeInfo.Type.ContainingAssembly.Identity.Name != &quot;Bridge.React&quot;)
            || (objectCreationTypeInfo.Type.Name != &quot;SelectAttributes&quot;))
                return;

            if ((multiplePropertyValue == true) &amp;amp;&amp;amp; valuePropertyIsSpecified)
            {
                context.ReportDiagnostic(Diagnostic.Create(
                    MultipleWithValueRule,
                    context.Node.GetLocation()
                ));
            }
            else if ((multiplePropertyValue == false) &amp;amp;&amp;amp; valuesPropertyIsSpecified)
            {
                context.ReportDiagnostic(Diagnostic.Create(
                    NoMultipleWithValuesRule,
                    context.Node.GetLocation()
                ));
            }
        }

        private static LocalizableString GetLocalizableString(string nameOfLocalizableResource)
        {
            return new LocalizableResourceString(
                nameOfLocalizableResource,
                Resources.ResourceManager,
                typeof(Resources)
            );
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
			<pubDate>Tue, 28 Jun 2016 07:49:00 GMT</pubDate>
		</item>
		<item>
			<title>A static type system is a wonderful message to the present and future - Supplementary</title>
            <link>http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future-supplementary</link>
			<guid>http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future-supplementary</guid>
			<description>&lt;p&gt;This is an extension of my post &quot;&lt;a href=&quot;http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future&quot;&gt;A static type system is a wonderful message to the present and future&lt;/a&gt;. I initially rolled this all together into a single article but then decided to break it into two to make the first part easier to consume.&lt;/p&gt;

&lt;p&gt;So, what else did I want to say? Rather than just saying &quot;static typing is better&quot;, I want to express some more detailed &quot;for&quot; and &quot;against&quot; arguments. Spoiler alert: despite the negatives, I still believe that static typing is worth the effort.&lt;/p&gt;

&lt;h3&gt;FTW&lt;/h3&gt;

&lt;p&gt;I find that the more that I take advantage of the type system, the more reliable that my code becomes - not only in terms of how well it lasts over the years, but how likely that it is to work the first time that it compiles. Going back to some code that I wrote a few years ago, there are various parts of a particular project that deal with internationalisation - some parts want to know what language that particular content is in while some parts of more specific and want to know what language &lt;em&gt;culture&lt;/em&gt; it&#39;s in; the difference between &quot;English&quot; (the language) and &quot;English UK&quot; / &quot;en-GB&quot; (the language culture). I wish now that, for that project, I&#39;d created a type (in C#, a struct would have been the natural choice) to represent a &lt;strong&gt;LanguageKey&lt;/strong&gt; and another for a &lt;strong&gt;LanguageCultureKey&lt;/strong&gt; as I encountered several places where it was confusing which was required - some parts of the code had method arguments named &quot;language&quot; that wanted a language key while others had arguments named &quot;language&quot; that wanted a language culture key. The two parts of the project were written by different people at different times and, in both cases, it seemed natural to them to presume that &quot;language&quot; could mean a language key (since nothing more specific was required) or could mean a language culture (since they presumed that nothing &lt;em&gt;less&lt;/em&gt; specific would ever be required). This is an example of a place where better argument naming would have helped because it would have been easier to spot if a language culture key was being passed where a language key was required. However, it would have been better again if the compiler would spot the wrong key type being passed - a human might miss it if a naming convention is relied upon, but the compiler will never miss an invalid type.&lt;/p&gt;

&lt;p&gt;Another example that I&#39;ve used in the past is that of React &quot;props&quot; validation - when creating React components (which are used to render DOM elements.. or OS components, if you&#39;re using &lt;a href=&quot;http://www.reactnative.com&quot;&gt;React Native&lt;/a&gt;), you must provide specific information for the component; if it&#39;s a Label, for example, then you must provide a text string and maybe a class name string. If you&#39;re using JavaScript with React then you will probably be providing the props reference using simple object notation, so you will have to be careful that you remember that the text string is named &quot;text&quot; and not &quot;labelText&quot;. The React library includes support for a &quot;propTypes&quot; object to be defined for a component - this performs validation at runtime, ensuring that required properties have values and that they are of the correct type. If a &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;strongly-typed language (such as C#)&lt;/a&gt; was used to create and consume React components, then this additional runtime validation would not be required as the component&#39;s &quot;props&quot; class would be declared as a class and all properties would have the appropriate types specified there. These would be validated at compile time, rather than having to wait until runtime. Returning to the &quot;&lt;a href=&quot;https://m.signalvnoise.com/provide-sharp-knives-cc0a22bf7934#.yv2771vf7&quot;&gt;Sharp Knives&lt;/a&gt;&quot; quote, this may be construed as being validation written for &quot;other programmers&quot; - as in, &quot;I don&#39;t want other programmers to try to use my component incorrectly&quot; - but, again, I&#39;m very happy to be the one of the &quot;other programmers&quot; in this case, it allows the type system to work as very-welcome documentation.&lt;/p&gt;

&lt;p&gt;While we&#39;re talking about React and component props, the React library always treats the props reference for a component as being immutable. If the props data needs to change then the component needs to be re-rendered with a new props reference. If you are writing your application in JavaScript then you need to respect this convention. However, if you choose to write your React application in a strongly-typed language then you may have your props classes represented by immutable types. This enforces this convention through the type system - &lt;em&gt;you&lt;/em&gt; (and anyone reviewing your code) don&#39;t have to keep a constant vigil against accidental mutations, the compiler will tell you if this is attempted (by refusing to build and pointing out where the mistake made).&lt;/p&gt;

&lt;p&gt;The common thread, for me, in all of the reasons why static typing is a good thing is that it enforces things that I want (or that I require) to be enforced, while providing invaluable information and documentation through the types. This makes code easier to reason about and code that is easier to reason about is easier to maintain and extend.&lt;/p&gt;

&lt;h3&gt;What static typing can&#39;t solve&lt;/h3&gt;

&lt;p&gt;It&#39;s not a silver bullet. But, then, nothing is. Static typing is a valuable tool that should be used &lt;em&gt;with&lt;/em&gt; automated test in order to create a reliable product.&lt;/p&gt;

&lt;p&gt;To take a simple example that will illustrate a variety of principles, the following is a LINQ call made in C# to take a set of &lt;strong&gt;EmployeeDetails&lt;/strong&gt; instances and determine the average age (we&#39;ll assume that &lt;strong&gt;EmployeeDetails&lt;/strong&gt; is a class with an integer Age property) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var averageAge = employees.Average(employee =&amp;gt; employee.Age);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we were implementing the &quot;Average&quot; function ourselves, then we would need to populate the following -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static int Average&amp;lt;T&amp;gt;(this IEnumerable&amp;lt;T&amp;gt; source, Func&amp;lt;T, int&amp;gt; selector)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Static typing gives us a lot of clues here. It ensures that anyone calling &quot;Average&quot; has to provide a set of values that may be enumerated and they have to provide a lambda that extracts an integer from each of those values. If the caller tried to provide a lambda that extracted a string (eg. the employee&#39;s name) from the values then it wouldn&#39;t compile. The type signature documents many of the the requirements of the method.&lt;/p&gt;

&lt;p&gt;However, the type system does not ensure that the implementation of &quot;Average&quot; is correct. It would be entirely possible to write an &quot;Average&quot; function that returned the &lt;em&gt;highest&lt;/em&gt; value, rather than the &lt;a href=&quot;https://en.wikipedia.org/wiki/Arithmetic_mean&quot;&gt;mean&lt;/a&gt; value.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is what unit tests are for.&lt;/em&gt; Unit tests will ensure that the logic within a method is correct. It will ensure that 30 is returned from &quot;Average&quot; if a set of employees with ages 20, 30 and 40 are provided.&lt;/p&gt;

&lt;p&gt;The type system ensures that the code is not called with inappropriate data. If you didn&#39;t have a static type system then it would still be possible to write more unit tests around the code that called &quot;Average&quot; to ensure that it was always dealing with appropriate data - but this is an entire class of tests that are not required if you leverage static analysis*.&lt;/p&gt;

&lt;p&gt;Unfortunately, there &lt;em&gt;are&lt;/em&gt; limitations to what may be expressed in the type system. In the &quot;Average&quot; example above, there is no way (in C#) to express the fact that it&#39;s invalid for a null &quot;source&quot; or &quot;selector&quot; reference to be passed or a &quot;source&quot; reference that has zero elements (since there is no such thing as an average value if there are zero values) or a set of items where one of more of the values is null. Any of these cases of bad data will result in a runtime error. However, I believe that the solution to this is not to run away screaming from static typing because it&#39;s not perfect - in fact, I think that the answer is &lt;em&gt;more&lt;/em&gt; static analysis. &lt;a href=&quot;https://github.com/Microsoft/CodeContracts&quot;&gt;Code Contracts&lt;/a&gt; is a way to include these additional requirements in the type system; to say that &quot;source and selector may not be null&quot; and &quot;source may not be empty&quot; and &quot;source may not contain any null references&quot;. Again, this will be a way for someone consuming the code to have greater visibility of its requirements &lt;em&gt;and&lt;/em&gt; for the compiler to enforce them. I will be able to write stricter code to stop other people from making mistakes with it, and other people will be able to write stricter code to make it clearer to me how it should be used and prevent me from making mistakes or trying to use it in ways that is not supported. &lt;em&gt;I don&#39;t want the power to try to use code incorrectly&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I think that there are two other obvious ways that static typing can&#39;t help and protect you..&lt;/p&gt;

&lt;p&gt;Firstly, when dealing with an external system there may be additional rules that you can not (and would not want to, for the sake of preventing duplication) describe in your code. Perhaps you have a data store that you pass updates to in order to persist changes made by a user - say the user wants to change the name of an employee in the application, so an &lt;strong&gt;UpdateEmployeeName&lt;/strong&gt; action must be sent to the data service. This action will have an integer &quot;Key&quot; property and a string &quot;Name&quot; property. This class structure ensures that data of the appropriate form is provided but it can &lt;em&gt;not&lt;/em&gt; ensure that the Key itself is valid - only the data store will know that. The type system is not an all-seeing-all-knowing magician, so it &lt;em&gt;will&lt;/em&gt; allow some invalid states to be represented (such as an update action for an entity key that doesn&#39;t exist). But the more invalid states that may &lt;em&gt;not&lt;/em&gt; be represented (such as not letting the key, which the data service requires to be an integer, be the string &quot;abc&quot; - for example) means that there are less possible errors states to test against and the code is more reliable (making it harder to write incorrect code will make the code more correct overall and hence more reliable).&lt;/p&gt;

&lt;p&gt;Secondly, if the type system is not taken advantage to the fullest extent then it can&#39;t help you to the fullest extent. I have worked on code in the past where a single class was used in many places to represent variations on the same data. Sometimes a &quot;Hotel&quot; instance would describe the entity key, the name, the description. Sometimes the &quot;Hotel&quot; instance would contain detailed information about the rooms in the hotel, sometimes the &quot;Rooms&quot; property would be null. Sometimes it would have its &quot;Address&quot; value populated, other times it would be null. It would depend upon the type of request that the &quot;Hotel&quot; instance was returned for.  This is a poor use of the type system - different response types should have been used, it should have been clear from the returned type what data would be present. The more often we&#39;re in a &quot;sometimes this, sometimes that&quot; situation, the less reliable that the code will be as it becomes easier to forget one of &quot;sometimes&quot; cases (again, I&#39;m talking from personal experience and not just worrying about how this may or may not affect &quot;other programmers&quot;). Unfortunately, not even the potential for a strong type system can make shitty code good.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(It&#39;s probably worth stating that a static type system is one way that tooling can automatically identify mistakes for you but it&#39;s not the only way - &lt;a href=&quot;https://github.com/Microsoft/CodeContracts&quot;&gt;code contracts&lt;/a&gt; are a way to go beyond what C# can support &quot;out of the box&quot; but there are other approaches, such as what &lt;a href=&quot;http://www.gamasutra.com/view/news/128836/InDepth_Static_Code_Analysis.php&quot;&gt;John Carmark has written about static analysis of C++&lt;/a&gt; or how &lt;a href=&quot;http://flowtype.org/&quot;&gt;Facebook is analysing JavaScript without even requiring types to be explicitly declared&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt;

&lt;h3&gt;Code Reviews&lt;/h3&gt;

&lt;p&gt;Another quote that stuck out for me in the &quot;&lt;a href=&quot;https://m.signalvnoise.com/provide-sharp-knives-cc0a22bf7934#.yv2771vf7&quot;&gt;Sharp Knives&lt;/a&gt;&quot; post was that&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We enforce such good senses by convention, by nudges, and through education&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is very sensible advice. I think that one of the best ways for code quality to remain high is through developers working together - learning from each other and supporting each other. This is something that I&#39;ve found code reviews to be very effective for. If all code is reviewed, then all code is guaranteed to have been read by at least two people; the author and the reviewer. If the code is perfect, then that&#39;s where the review ends - on a high note. If the code needs work then any mistakes or improvements can be highlighted and addressed. As the recipient of a review that identifies a mistake that I&#39;ve made, I&#39;m happy! Well.. I&#39;m generally a bit annoyed with myself for making the mistake but I&#39;m glad that a colleague has identified it rather than it getting to an end user.&lt;/p&gt;

&lt;p&gt;As a code reviewer, I will be happy with code that I think requires no changes or if code needs to be rejected only once. I&#39;ve found that code that is rejected and then fixed up is much harder to re-review and that bugs more often slip through the re-review process. It&#39;s similar to the way in which you can more easily become blind to bugs in code that you&#39;ve just written than you are to someone else&#39;s code - you have a familarity with the code that you are reviewing for a second time &lt;em&gt;and&lt;/em&gt; someone has just told you that they have fixed it; I&#39;ve found that there is something psychological about that that makes it just that little bit harder to pick up on any subsequent mistakes. Thusly, I would prefer to limit the number of times that reviews bounce back and forth.&lt;/p&gt;

&lt;p&gt;I have found that a static type system encourages a stricter structure on the code and that conventions are clearer, not to mention the fact that the compiler can identify more issues - meaning that there should be fewer types of mistake that can get through to a review. There is, of course, a limit to what the type system can contribute on this front but &lt;em&gt;any&lt;/em&gt; mechanical checks that a computer could perform leave the reviewer more time (and mental capacity) to provide deeper insight; to offer guidance to a more junior developer or to suggest implementation tweaks to a peer.&lt;/p&gt;

&lt;h3&gt;A &quot;wonderful message&quot;&lt;/h3&gt;

&lt;p&gt;It&#39;s a theme that has picked up more and more weight for me over the years, that the computer should be able to help me tell it what to do - I should be able to leverage its strengths in order to multiply mine. As a developer, there is a lot of creativity required but also a huge quantity of seemingly banal details. The strength of a good abstraction comes from being able to &quot;hide away&quot; details that don&#39;t matter, leaving you with larger and more useful shapes to deal with, allowing you to think closer to the big picture. The more details that may be automatically verified, the less that you need to worry about them; freeing up more valuable mental space. Leaning on static analysis aids this, it allows the computer to do what it&#39;s good at and concentrate on the simple-and-boring rules, allowing you to become more effective. It&#39;s an incredibly powerful tool, the ability to actually limit certain things from being done allows you to do &lt;em&gt;more&lt;/em&gt; of what you should be doing.&lt;/p&gt;

&lt;p&gt;It can also be an invaluable form of documentation for people using your code (including you, in six months, when you&#39;ve forgotten the finer details). Good use of the type system allows for the requirements and the intent of code to be clearer. It&#39;s not just a way of communicating with the compiler, it&#39;s also a very helpful way to communicate with human consumers of your code.&lt;/p&gt;

&lt;p&gt;On a personal note, this marks my 100th post on this blog. The first (&lt;a href=&quot;http://www.productiverage.com/i-love-immutable-data&quot;&gt;I love Immutable Data&lt;/a&gt;) was written about five years ago and was &lt;em&gt;also&lt;/em&gt; (basically) about leveraging the type system - by defining immutable types and the benefits that they could have. I find it reassuring that, with all that I&#39;ve seen since then (and thinking back over the time since I first started writing code.. over 25 years ago) that this still feels like a good thing. In a time where it seems like everyone&#39;s crying about JavaScript fatigue (and the frequent off-the-cuff comments about React being &quot;&lt;a href=&quot;https://camo.githubusercontent.com/a85f7c2c03b36655323ec7a3250057233e82ef55/68747470733a2f2f692e696d6775722e636f6d2f695549497571622e6a7067&quot;&gt;so hot right now&lt;/a&gt;&quot;*), I&#39;m glad that there are still plenty of principles that stand the test of time.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Since I&#39;m feeling so brave and self-assured, I&#39;m going to say that I think that React *will* still be important five years from now - maybe I&#39;ll look back in 2021 and see how this statement has fared!)&lt;/em&gt;&lt;/p&gt;
</description>
			<pubDate>Tue, 31 May 2016 21:34:00 GMT</pubDate>
		</item>
		<item>
			<title>A static type system is a wonderful message to the present and future</title>
            <link>http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future</link>
			<guid>http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future</guid>
			<description>&lt;p&gt;Last week, I read the article &quot;&lt;a href=&quot;http://solnic.eu/2016/05/22/my-time-with-rails-is-up.html&quot;&gt;My time with Rails is up&lt;/a&gt;&quot; (by &lt;a href=&quot;https://twitter.com/_solnic_&quot;&gt;Piotr Solnica&lt;/a&gt;) which resulted in me reading some of &lt;a href=&quot;https://medium.com/@dhh&quot;&gt;DHH&lt;/a&gt;&#39;s latest posts and re-reading some of his  older ones.&lt;/p&gt;

&lt;p&gt;Some people write articles that I enjoy reading because they have similar ideas and feelings about development that I do, that they manage to express in a new or particularly articulate way that helps me clarify it in my own head or that helps me think about whether I really do still agree with the principle. Some people write articles that come from a completely different point of view and experience to me and these also can have a lot of benefit, in that they make me reconsider where I stand on things or inspire me to try something different to see how it feels. DHH is, almost without fail, interesting to read and I like his passion and conviction.. but he&#39;s definitely not in that first category of author. There was one thing in particular, though, that really stuck out for me in his post &quot;&lt;a href=&quot;https://m.signalvnoise.com/provide-sharp-knives-cc0a22bf7934#.yv2771vf7&quot;&gt;Provide sharp knives&lt;/a&gt;&quot; -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ruby includes a lot of sharp knives in its drawer of features.. The most famous is monkey patching: The power to change existing classes and methods. .. it offered a different and radical perspective on the role of the programmer: That they could be trusted with sharp knives. .. That’s an incredibly aspirational idea, and one that runs counter to a lot of programmer’s intuition about other programmers.&lt;/p&gt;
  
  &lt;p&gt;Because it’s always about other programmers when the value of sharp knives is contested. &lt;strong&gt;I’ve yet to hear a single programmer put up their hand and say &quot;I can’t trust myself with this power, please take it away from me!&quot;. It’s always &quot;I think other programmers would abuse this&quot;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The highlighted section of the quote is what I disagree with most - because I absolutely &lt;em&gt;do&lt;/em&gt; want to be able to write code in a way that limits how I (as well as others) may use it.&lt;/p&gt;

&lt;h3&gt;And I strongly disagree with it because..&lt;/h3&gt;

&lt;p&gt;The harsh reality is that all code is created according to a particular set of limitations and compromises that are present at the time of writing. The more complex the task that the code must perform, the more likely that there will be important assumptions that are &quot;baked into&quot; the code and that it would be beneficial for someone using the code to be aware of. A good type system can be an excellent way to communicate some of these assumptions. And, unlike documentation, convention or code review, a good type system can allow these assumptions to be &lt;em&gt;enforced&lt;/em&gt; by the computer - rather than a principle that &lt;em&gt;should be treated as unbreakable&lt;/em&gt; being allowed to be ignored. Computers are excellent at verifying simple sets of rules, which allow them to help identify common mistakes (or miscomprehensions).&lt;/p&gt;

&lt;p&gt;At the very simplest level, specifying types for a method&#39;s arguments makes it much less likely that I&#39;ll refactor my code by swapping two of the arguments and then miss one of the call sites and not find out that something now fails until runtime (the example sounds contrived but, unfortunately, it &lt;em&gt;is&lt;/em&gt; something that I&#39;ve done from time to time). Another simple example is that having descriptive classes reminds me precisely what the minimum requirements are for a method without having to poke around &lt;em&gt;inside&lt;/em&gt; the method - if there is an argument named &quot;employeeSummaries&quot; in a language without type annotations, I can presume that it&#39;s some sort of collection type.. but should each value in the collection include just the key and name of each employee or should it be key, name and some other information that the method requires such as, say, a list of reporting employees that the employee is responsible for managing? With a type system, if the argument is &lt;strong&gt;IEnumerable&amp;lt;EmployeeSummary&amp;gt;&lt;/strong&gt; then I can see what information I have to provide by looking at the &lt;strong&gt;EmployeeSummary&lt;/strong&gt; class.&lt;/p&gt;

&lt;p&gt;A more complex example might involve data that is shared across multiple threads, whether for parallel processing or just for caching. The simplest way to write this sort of code reliably is to prevent mutation of the data from occurring on multiple threads and one way to achieve that is for the data to be represented by immutable data types. If the multi-threaded code requires that the data passed in be immutable then it&#39;s hugely beneficial for the type system to be able to specify that immutable types be used, so that the internal code may be written in the simplest way - based on the requirement that the data not be mutable.&lt;/p&gt;

&lt;p&gt;I want to reinforce here that this is not just about me trying to stop other people from messing up when they use my code, &lt;em&gt;this is just as much about me&lt;/em&gt;. Being able to represent these sorts of key decisions in the type system means that I can actually be a little bit less obsessive with how much I worry about them, easing the mental burden. This, in turn, leaves me more mental space to concentrate on solving the real problem at hand. I won&#39;t be able to forget to pass data in an immutable form to methods that require it in an immutable form, because the compiler won&#39;t let me do so.&lt;/p&gt;

&lt;h3&gt;Isn&#39;t this what automated tests are for?&lt;/h3&gt;

&lt;p&gt;An obvious rebuttal is that these sorts of errors (particular the mixing-up-the-method-arguments example) can (and should) be caught by unit tests.&lt;/p&gt;

&lt;p&gt;In my opinion: no.&lt;/p&gt;

&lt;p&gt;I believe that unit tests &lt;em&gt;are&lt;/em&gt; required to test logic in an application and it &lt;em&gt;is&lt;/em&gt; possible to write unit tests that show how methods work when given the correct data and that show how they will fail when given invalid data but it&#39;s difficult (and arduous) to prove, using automated tests, that the same guarantees that a type system could enforce are not being broken anywhere in your code. The only-allow-immutable-data-types-to-be-passed-into-this-thread-safe-method example is a good one here since multi-threaded code will often appear to work fine when only executed within a single thread, meaning that errors will only surface when multiple threads are working with it simultaneously. Writing unit tests to try to detect race conditions is not fun. You could have 100% code coverage and not always pick up on all of the horrible things that can happen when multiple threads deal with mutable data. If the data passed around within those code paths is &lt;em&gt;immutable&lt;/em&gt;, though (which may be enforced through the types passed around), then these potential races are prevented.&lt;/p&gt;

&lt;p&gt;Good use of static typing means that an entire class of unit tests are not required.&lt;/p&gt;

&lt;p&gt;The fact that static typing is not enough to confirm that your code is correct, and that unit tests should be written as well, does not mean that &lt;em&gt;only&lt;/em&gt; units tests should be used.&lt;/p&gt;

&lt;p&gt;I&#39;ve kept this post deliberately short because I would love for it to have some impact and experience has taught me that it&#39;s much more difficult for that to be the case with a long format post. I&#39;ve expanded on this further at &quot;&lt;a href=&quot;http://www.productiverage.com/a-static-type-system-is-a-wonderful-message-to-the-present-and-future-supplementary&quot;&gt;A static type system is a wonderful message to the present and future - Supplementary&lt;/a&gt;&quot;. There&#39;s more about the benefits, more about the limitations, more examples of me saying &quot;I don&#39;t want the power to do try to do something that this code has been explicitly written not to have to deal with&quot; and &lt;em&gt;no more&lt;/em&gt; mentions of multi-threading because static typing&#39;s benefits are not restricted to especially complicated problem domains, applications may benefit regardless of their complexity.&lt;/p&gt;
</description>
			<pubDate>Tue, 31 May 2016 21:33:00 GMT</pubDate>
		</item>
		<item>
			<title>Using Roslyn code fixes to make the &quot;Friction-less immutable objects in Bridge&quot; even easier</title>
            <link>http://www.productiverage.com/using-roslyn-code-fixes-to-make-the-frictionless-immutable-objects-in-bridge-even-easier</link>
			<guid>http://www.productiverage.com/using-roslyn-code-fixes-to-make-the-frictionless-immutable-objects-in-bridge-even-easier</guid>
			<description>&lt;p&gt;This is going to be a short post about a Roslyn (or &quot;The .NET Compiler Platform&quot;, if you&#39;re from Microsoft) analyser and code fix that I&#39;ve added to a library. I&#39;m not going to try to take you through the steps required to create an analyser nor how the Roslyn object model describes the code that you&#39;ve written in the IDE* but I want to talk about the analyser itself because it&#39;s going to be very useful if you&#39;re one of the few people using my &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt; library. Also, I feel like the inclusion of analysers with libraries is something that&#39;s going to become increasingly common (and I want to be able to have something to refer back to if I get the chance to say &quot;told you!&quot; in the future).&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(This is largely because I&#39;m still struggling with it a bit myself; my current process is to start with &lt;a href=&quot;https://msdn.microsoft.com/en-gb/magazine/dn879356.aspx&quot;&gt;Use Roslyn to Write a Live Code Analyzer for Your API&lt;/a&gt; and the &quot;Analyzer with Code Fix (NuGet + VSIX)&quot; Visual Studio template. I then tinker around a bit and try running what I&#39;ve got so far, so that I can use the &quot;Syntax Visualizer&quot; in the Visual Studio instance that is being debugged. Then I tend to do a lot of Google searches when I feel like I&#39;m getting close to something useful.. how do I tell if a &lt;strong&gt;FieldDeclarationSyntax&lt;/strong&gt; is for a readonly field or not? Oh, good, someone else has already written some code doing something like what  I want to do - I look at the &quot;Modifiers&quot; property on the &lt;strong&gt;FieldDeclarationSyntax&lt;/strong&gt; instance).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As new .net libraries get written, some of them will have guidelines and rules that can&#39;t easily be described through the type system. In the past, the only option for such rules would be to try to ensure that the documentation (whether this be the project README and / or more in-depth online docs and / or the xml summary comment documentation for the types, methods, properties and fields that intellisense can bring to your attention in the IDE). The support that Visual Studio 2015 introduced for customs analysers* allows these rules to be communicated in a different manner.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(I&#39;m being English and stubborn, hence my use of &quot;analysers&quot; rather than &quot;analyzers&quot;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In short, they allow these library-specific guidelines and rules to be higlighted in the Visual Studio Error List, just like any error or warning raised by Visual Studio itself (even refusing to allow the project to be built, if an error-level message is recorded).&lt;/p&gt;

&lt;p&gt;An excellent example that I&#39;ve seen recently was encountered when I was writing some of my own analyser code. To do this, you can start with the &quot;Analyzer with Code Fix (NuGet + VSIX)&quot; template, which pulls in a range of NuGet packages and includes some template code of its own. You then need to write a class that is derived from &lt;strong&gt;DiagnosticAnalyzer&lt;/strong&gt;. Your class will declare one of more &lt;strong&gt;DiagnosticDescriptor&lt;/strong&gt; instances - each will be a particular rule that is checked. You then override an &quot;Initialize&quot; method, which allows your code to register for syntax changes and to raise any rules that have been broken. You must also override a &quot;SupportedDiagnostics&quot; property and return the set of &lt;strong&gt;DiagnosticDescriptor&lt;/strong&gt; instances (ie. rules) that your analyser will cover. If the code that the &quot;Initialize&quot; method hooks up tries to raise a rule that &quot;SupportedDiagnostics&quot; did not declare, the rule will be ignored by the analysis engine. This would be a kind of (silent) runtime failure and it&#39;s something that is documented - but it&#39;s still a very easy mistake to make; you might create a new &lt;strong&gt;DiagnosticDescriptor&lt;/strong&gt; instance and raise it from your &quot;Initialize&quot; method but forget to add it to the &quot;SupportedDiagnostics&quot; set.. whoops. In the past, you may not realise until runtime that you&#39;d made a mistake and, as a silent failure, you might end up getting very frustrated and be stuck wondering what had gone wrong. But, mercifully (and I say this as I made this very mistake), there is an analyser in the &quot;Microsoft.CodeAnalysis.CSharp&quot; NuGet package that brings this error immediately to your attention with the message:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;RS1005 ReportDiagnostic invoked with an unsupported DiagnosticDescriptor&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The entry in the Error List links straight to the code that called &quot;context.ReportDiagnostic&quot; with the unexpected rule. This is fantastic - instead of suffering a runtime failure, you are informed at compile time precisely what the problem is. Compile time is &lt;em&gt;always&lt;/em&gt; better than run time (for many reasons - it&#39;s more immediate, so you don&#39;t have to &lt;em&gt;wait&lt;/em&gt; until runtime, and it&#39;s more thorough; a runtime failure may only happen if a particular code path is followed, but static analysis such as this is like having &lt;em&gt;every possible&lt;/em&gt; code path tested).&lt;/p&gt;

&lt;h3&gt;The analysers already in ProductiveRage.Immutable&lt;/h3&gt;

&lt;p&gt;The ProductiveRage uber-fans (who, surely exist.. yes? ..no? :D) may be thinking &quot;doesn&#39;t the ProductiveRage.Immutable library already have some analysers built into it?&quot;&lt;/p&gt;

&lt;p&gt;And they would be correct, for some time now it has included a few analysers that try to prevent some simple mistakes. As a quick reminder, the premise of the library is that it will make creating immutable types in &lt;a href=&quot;http://www.bridge.net&quot;&gt;Bridge.NET&lt;/a&gt; easier.&lt;/p&gt;

&lt;p&gt;Instead of writing something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class EmployeeDetails
{
  public EmployeeDetails(PersonId id, NameDetails name)
  {
    if (id == null)
      throw new ArgumentNullException(&quot;id&quot;);
    if (name == null)
      throw new ArgumentNullException(&quot;name&quot;);

    Id = id;
    Name = name;
  }

  /// &amp;lt;summary&amp;gt;
  /// This will never be null
  /// &amp;lt;/summary&amp;gt;
  public PersonId Id { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// This will never be null
  /// &amp;lt;/summary&amp;gt;
  public NameDetails Name { get; private set; }

  public EmployeeDetails WithId(PersonId id)
  {
    return Id.Equals(id) ? this : return new EmployeeDetails(id, Name);
  }
  public EmployeeDetails WithName(NameDetails name)
  {
    return Name.Equals(name) ? this : return new EmployeeDetails(Id, name);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. you can express it just as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class EmployeeDetails : IAmImmutable
{
  public EmployeeDetails(PersonId id, NameDetails name)
  {
    this.CtorSet(_ =&amp;gt; _.Id, id);
    this.CtorSet(_ =&amp;gt; _.Name, name);
  }
  public PersonId Id { get; private set; }
  public NameDetails Name { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The if-null-then-throw validation is encapsulated in the CtorSet call (since the library takes the view that no value should ever be null - it introduces an &lt;strong&gt;Optional&lt;/strong&gt; struct so that you can identify properties that may be without a value). And it saves you from having to write &quot;With&quot; methods for the updates as &lt;strong&gt;IAmImmutable&lt;/strong&gt; implementations may use the &quot;With&quot; extension method whenever you want to create a new instance with an altered property - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var updatedEmployee = employee.With(_ =&amp;gt; _.Name, newName);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The library can only work if certain conditions are met. For example, every property must have a getter and a setter - otherwise, the &quot;CtorSet&quot; extension method won&#39;t know how to actually set the value &quot;under the hood&quot; when populating the initial instance (nor would the &quot;With&quot; method know how to set the value on the new instance that it would create).&lt;/p&gt;

&lt;p&gt;If you forgot this and wrote the following (note that the &quot;Name&quot; property now has no setter) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class EmployeeDetails : IAmImmutable
{
  public EmployeeDetails(PersonId id, NameDetails name)
  {
    this.CtorSet(_ =&amp;gt; _.Id, id);
    this.CtorSet(_ =&amp;gt; _.Name, name);
  }
  public PersonId Id { get; private set; }
  public NameDetails Name { get; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then you would see the following errors reported by Visual Studio (presuming you are using 2015 or later) -&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/ProductiveRageImmutableAnalyserError1.png&quot; alt=&quot;Example analyser errors raised by the ProductiveRage.Immutable library&quot;&gt;&lt;/p&gt;

&lt;p&gt;.. which is one of the &quot;common IAmImmutable mistakes&quot; analysers identifying the problem for you.&lt;/p&gt;

&lt;h3&gt;Getting Visual Studio to write code for you, using code fixes&lt;/h3&gt;

&lt;p&gt;I&#39;ve been writing more code with this library and I&#39;m still, largely, happy with it. Making the move to assuming never-allow-null (which is baked into the &quot;CtorSet&quot; and &quot;With&quot; calls) means that the classes that I&#39;m writing are a lot shorter and that type signatures are more descriptive. (I wrote about all this in my post at the end of last year &quot;&lt;a href=&quot;http://www.productiverage.com/frictionless-immutable-objects-in-bridge-c-sharp-javascript-applications&quot;&gt;Friction-less immutable objects in Bridge (C# / JavaScript) applications&lt;/a&gt;&quot; if you&#39;re curious for more details).&lt;/p&gt;

&lt;p&gt;However.. I &lt;em&gt;still&lt;/em&gt; don&#39;t really like typing out as much code for each class as I have to. Each class has to repeat the property names four times - once in the constructor, twice in the &quot;CtorSet&quot; call and a fourth time in the public property. Similarly, the type name has to be repeated twice - once in the constructor and once in the property.&lt;/p&gt;

&lt;p&gt;This is better than the obvious alternative, which is to not bother with immutable types. I will gladly take the extra lines of code (and the effort required to write them) to get the additional confidence that a &quot;stronger&quot; type system offers - I wrote about this recently in my &quot;&lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;Writing React with Bridge.NET - The Dan Way&lt;/a&gt;&quot; posts; I think that it&#39;s really worthwhile to bake assumptions into the type system where possible. For example, the Props types of React components are assumed, by the React library, to be immutable - so having them defined as immutable types represents this requirement in the type system. If the Props types are &lt;em&gt;mutable&lt;/em&gt; then it would be possible to write code that tries to change that data and then bad things could happen (you&#39;re doing something that library expects not to happen). If the Props types are &lt;em&gt;immutable&lt;/em&gt; then it&#39;s not even possible to write this particular kind of bad-things-might-happen code, which is a positive thing.&lt;/p&gt;

&lt;p&gt;But &lt;em&gt;still&lt;/em&gt; I get a niggling feeling that things could be better. And now they are! With Roslyn, you can not only identify particular patterns but you can also offer automatic fixes for them. So, if you were to start writing the &lt;strong&gt;EmployeeDetails&lt;/strong&gt; class from scratch and got this far:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public sealed class EmployeeDetails : IAmImmutable
{
  public EmployeeDetails(PersonId id, NameDetails name)
  {
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then an analyser could identify that you were writing an &lt;strong&gt;IAmImmutable&lt;/strong&gt; implementation and that you have an empty constructor - it could then offer to fix that for you by filling in the rest of the class.&lt;/p&gt;

&lt;p&gt;The latest version of the ProductiveRage.Immutable library (1.7.0) does just that. The empty constructor will not only be identified with a warning but a light bulb will also appear alongside the code. Clicking this (or pressing [Ctrl]-[.] while within the empty constructor, for fellow keyboard junkies) will present an option to &quot;Populate class from constructor&quot; -&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/ProductiveRageImmutableAnalyserCodeFix1.png&quot; alt=&quot;Screenshot showing the analyser identifying an empty constructor on an IAmImmutable implementation&quot;&gt;&lt;/p&gt;

&lt;p&gt;Selecting the &quot;Populate class from constructor&quot; option -&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.productiverage.com/Content/Images/Posts/ProductiveRageImmutableAnalyserCodeFix2.png&quot; alt=&quot;Screenshot showing the code fix that may auto-populate the incomplete IAmImmutable implementation&quot;&gt;&lt;/p&gt;

&lt;p&gt;.. will take the constructor arguments and generate the &quot;CtorSet&quot; calls and the public properties automatically. Now you can have all of the safety of the immutable type with no more typing effort than the mutable version!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// This is what you have to type of the immutable version,
// then the code fix will expand it for you
public sealed class EmployeeDetails : IAmImmutable
{
  public EmployeeDetails(PersonId id, NameDetails name)
  {
  }
}

// This is what you would have typed if you were feeling
// lazy and creating mutable types because you couldn&#39;t
// be bothered with the typing overhead of immutability
public sealed class EmployeeDetails
{
  public PersonId Id;
  public NameDetails name;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;To summarise&lt;/h3&gt;

&lt;p&gt;If you&#39;re already using the library, then all you need to do to start taking advantage of this code fix is update your NuGet reference* (presuming that you&#39;re using VS 2015 - analysers weren&#39;t supported in previous versions of Visual Studio).&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Sometimes you have to restart Visual Studio after updating, you will know that this is the case if you get a warning in the Error List about Visual Studio not being able to load the Productive.Immutable analyser)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If you&#39;re writing your own library that has any guidelines or common gotchas that you have to describe in documentation somewhere (that the users of your library may well not read unless they have a problem - at which point they may even abandon the library, if they&#39;re only having an investigative play around with it) then I highly recommend that you consider using analysers to surface some of these assumptions and best practices. While I&#39;m aware that I&#39;ve not offered much concrete advice on &lt;em&gt;how&lt;/em&gt; to write these analysers, the reason is that I&#39;m still very much a beginner at it - but that puts me in a good position to be able to say that it really is fairly easy if you read a few articles about it (such as &lt;a href=&quot;https://msdn.microsoft.com/en-gb/magazine/dn879356.aspx&quot;&gt;Use Roslyn to Write a Live Code Analyzer for Your API&lt;/a&gt;) and then just get stuck in. With some judicious Google&#39;ing, you&#39;ll be making progress in no time!&lt;/p&gt;

&lt;p&gt;I guess that only time will tell whether library-specific analysers become as prevelant as I imagine. It&#39;s very possible that I&#39;m biased because I&#39;m such a believer in static analysis. Let&#39;s wait and see*!&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;Unless YOU are a library writer that this might apply to - in which case, make it happen rather than just sitting back to see what MIGHT happen! :)&lt;/em&gt;&lt;/p&gt;
</description>
			<pubDate>Wed, 04 May 2016 22:33:00 GMT</pubDate>
		</item>
		<item>
			<title>Writing React apps using Bridge.NET - The Dan Way (Part Three)</title>
            <link>http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-three</link>
			<guid>http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-three</guid>
			<description>&lt;p&gt;In parts &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;One&lt;/a&gt; and &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-two&quot;&gt;Two&lt;/a&gt;, I described how to create a simple application using React and a Flux-like architecture, written in &lt;a href=&quot;http://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt; - it covered where and how to deal with validation, how to integrate with a persistence layer, how to deal with asynchronous interactions (and how they don&#39;t need to be scary) and how the approach made the code easy to test and easy to reason about.&lt;/p&gt;

&lt;p&gt;The components created using the &lt;a href=&quot;https://www.nuget.org/packages/Bridge.React&quot;&gt;React / Bridge bindings&lt;/a&gt; have their requirements / dependencies described in a strongly-typed manner since each component&#39;s &quot;props&quot; reference is a nested class with properties for each value or reference that will be needed in order for it to render.&lt;/p&gt;

&lt;p&gt;This combination of technologies has the potential to be really powerful for writing client-side / browser-based applications, particularly with the ability to leverage C#&#39;s proven strength in allowing the writing of large and reliable systems. However, I&#39;m not happy with the example application yet. Although the way that it&#39;s written makes a lot of it easy to understand and, hopefully, makes the &lt;em&gt;intent&lt;/em&gt; of the code clear, it still could be &lt;em&gt;even easier&lt;/em&gt; to understand and the intent and the requirements &lt;em&gt;even clearer&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;People often like to talk as if a language is dynamically-typed (or &quot;non-typed&quot; or &quot;uni-typed&quot;, depending upon the language, their vocabulary and their knowledge and opinion of the language) or statically-typed; as if it is a binary choice. Really, it is a sliding scale. C# definitely sits on the &quot;statically-typed &lt;em&gt;side&lt;/em&gt;&quot;, but the way that you write C# dictates how far along the scale that &lt;em&gt;your C#&lt;/em&gt; is.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(C# can also be written to act as a dynamically-typed language, particularly if you use the &quot;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/dd264741.aspx&quot;&gt;dynamic&lt;/a&gt;&quot; keyword - but it&#39;s principally a statically-typed language).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I&#39;m going to describe some ways to improve the example application and, in doing so, extrapolate some rules as to how to make the code clearer (and, &lt;em&gt;again&lt;/em&gt;, easier to reason about, write and maintain - since these are extremely important qualities of code to me, that I strive for when developing and that appealed to me when I first encountered React). These will be my opinions (based upon my experiences) and you might disagree with them - but this is where we really get into &quot;The Dan Way&quot; of working with Bridge and React. If you &lt;em&gt;do&lt;/em&gt; choose to disagree, then hopefully parts &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;One&lt;/a&gt; and &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-two&quot;&gt;Two&lt;/a&gt; will continue to be useful (but I&#39;m afraid we can never be friends*).&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Only joking**)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;** &lt;em&gt;(I&#39;m not)&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Clarification through a richer type system&lt;/h3&gt;

&lt;p&gt;Let&#39;s jump straight in with a simple example. We have a &lt;strong&gt;TextInput&lt;/strong&gt; component that renders a text input element and passes up any requests by the user that the input&#39;s content be changed. The main primary purpose of this class is to provide a simple interface. Many of the html attributes that &lt;em&gt;may&lt;/em&gt; be applied to a text input are not relevant (this exposes only the basics, such as &quot;ClassName&quot;). Similarly, the &quot;OnChange&quot; that a text input raises has a relatively complicated event reference (it allows you to identify the element that changed and then get the requested &quot;new value&quot; from it, but I want a &lt;strong&gt;TextInput&lt;/strong&gt;&#39;s &quot;OnChange&quot; event to simply provide the new string and nothing else).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.Html5;
using Bridge.React;

namespace BridgeReactTutorial.Components
{
  public class TextInput : StatelessComponent&amp;lt;TextInput.Props&amp;gt;
  {
    public TextInput(Props props) : base(props) { }

    public override ReactElement Render()
    {
      return DOM.Input(new InputAttributes
      {
        Type = InputType.Text,
        ClassName = props.ClassName,
        Disabled = props.Disabled,
        Value = props.Content,
        OnChange = e =&amp;gt; props.OnChange(e.CurrentTarget.Value)
      });
    }

    public class Props
    {
      public string ClassName;
      public bool Disabled;
      public string Content;
      public Action&amp;lt;string&amp;gt; OnChange;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the context of this small class, looking at the code, I would say that it&#39;s fairly clear what each line of code does and what each of the properties of the &lt;strong&gt;Props&lt;/strong&gt; class is required for and how it will be used. However, even within such a small class, there are several implicit assumptions that are being made - eg.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ClassName is optional, it may be null.. or it may be blank - React will actually treat these two cases differently, do we really want that? If it&#39;s null then no &quot;class&quot; attribute will be present on the input element, but if it&#39;s blank then a &quot;class&quot; attribute &lt;em&gt;will&lt;/em&gt; be added (but with no value).&lt;/li&gt;
&lt;li&gt;Content is treated in the same way but probably shouldn&#39;t be - does it really make sense for Content to potentially be null? Blank, yes; if there&#39;s no user-entered content. But null? Probably not.&lt;/li&gt;
&lt;li&gt;OnChange is &lt;em&gt;not&lt;/em&gt; optional - if it&#39;s null then a null reference exception is going to be thrown when the user attempts to change the value in the input box (because &quot;props.OnChange&quot; will be called like a function, which will fail if it&#39;s null).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First off, I don&#39;t like the should-or-shouldn&#39;t-be-allowed-to-be-null confusion around the &quot;ClassName&quot; and &quot;Content&quot; values. Secondly, I don&#39;t like the fact that, as it stands, you need to read (or already be familiar with) the code inside the &lt;strong&gt;TextInput&lt;/strong&gt; component. One way to try to address these issues would be to consider using summary comments on the &lt;strong&gt;Props&lt;/strong&gt; class - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  /// &amp;lt;summary&amp;gt;
  /// This is optional and so may be null (if non-null, then it should be a valid class
  /// name - ie. non-blank)
  /// &amp;lt;/summary&amp;gt;
  public string ClassName;

  public bool Disabled;

  /// &amp;lt;summary&amp;gt;
  /// An input may not always have a value and so this may be blank (but it should never
  /// be null)
  /// &amp;lt;/summary&amp;gt;
  public string Content;

  /// &amp;lt;summary&amp;gt;
  /// This is mandatory and may never be null
  /// &amp;lt;/summary&amp;gt;
  public Action&amp;lt;string&amp;gt; OnChange;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem with this approach is that, if the comments are ignored, runtime problems will occur at some point and it may not be very easy to trace them back to where they originated. If the &quot;OnChange&quot; value is null, for example, then the problem won&#39;t be noticed until the user interacts with the input box - and the code that raises the exception (the &quot;props.OnChange&quot; call with &lt;strong&gt;TextInput&lt;/strong&gt;&#39;s &quot;Render&quot; method) will be completely removed from the code that incorrectly set the null value (the code that instantiated and populated &lt;strong&gt;Props&lt;/strong&gt; instance).&lt;/p&gt;

&lt;p&gt;So another alternative would be to combine these comments with some validation - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  private string _className, _content;
  private Action&amp;lt;string&amp;gt; _onChange;

  /// &amp;lt;summary&amp;gt;
  /// This is optional and so may be null (if non-null, then it should be a valid class
  /// name - ie. non-blank)
  /// &amp;lt;/summary&amp;gt;
  public string ClassName
  {
    get { return _className; }
    set
    {
      if (value == &quot;&quot;)
        throw new ArgumentException(&quot;ClassName should not be set to a blank string&quot;);
      _className = value;
    }
  }

  public bool Disabled { get; set; }

  /// &amp;lt;summary&amp;gt;
  /// An input may not always have a value and so this may be blank (but it should never
  /// be null)
  /// &amp;lt;/summary&amp;gt;
  public string Content
  {
    get { return _content; }
    set
    {
      if (value == null)
        throw new ArgumentNullException(&quot;Content should not be set to null&quot;);
      _content = value;
    }
  }

  /// &amp;lt;summary&amp;gt;
  /// This is mandatory and may never be null
  /// &amp;lt;/summary&amp;gt;
  public Action&amp;lt;string&amp;gt; OnChange
  {
    get { return _onChange; }
    set
    {
      if (value == null)
        throw new ArgumentNullException(&quot;OnChange should not be set to null&quot;);
      _onChange = value;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This way, it would not be possible to explicitly set &quot;OnChange&quot; to null - if this was attempted then an exception would be thrown immediately, right at the point in the code that was attempting to assign this invalid value. This is much better than it failing later on, at some point that depends upon how the user does or doesn&#39;t interact with the UI component. This is potentially the sort of mistake that goes unnoticed for some time. For cases that are clearly a &quot;programmer error&quot; bug like this, I much prefer to &quot;fail fast&quot;.&lt;/p&gt;

&lt;p&gt;There&#39;s still a problem, though, because the initial state of the &lt;strong&gt;Props&lt;/strong&gt; class is invalid, since &quot;OnChange&quot; will start as null. If the initialisation code explicitly tries to set it to null then it will fail fast, but if it doesn&#39;t set it at all then it remain null and we&#39;ll be back to where we started in terms of where and when the exception is raised compared to where the programming mistake was made.&lt;/p&gt;

&lt;p&gt;Attempt three could be to set appropriate defaults - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  private string _className = null;
  private string _content = &quot;&quot;;
  private Action&amp;lt;string&amp;gt; _onChange = newValue =&amp;gt; { };

  /// &amp;lt;summary&amp;gt;
  /// This is optional and so may be null (if non-null, then it should be a valid class
  /// name - ie. non-blank)
  /// &amp;lt;/summary&amp;gt;
  public string ClassName
  {
    get { return _className; }
    set
    {
      if (value == &quot;&quot;)
        throw new ArgumentException(&quot;ClassName should not be set to a blank string&quot;);
      _className = value;
    }
  }

  public bool Disabled { get; set; }

  /// &amp;lt;summary&amp;gt;
  /// An input may not always have a value and so this may be blank (but it should never
  /// be null)
  /// &amp;lt;/summary&amp;gt;
  public string Content
  {
    get { return _content; }
    set
    {
      if (value == null)
        throw new ArgumentNullException(&quot;Content should not be set to null&quot;);
      _content = value;
    }
  }

  /// &amp;lt;summary&amp;gt;
  /// This is mandatory and may never be null
  /// &amp;lt;/summary&amp;gt;
  public Action&amp;lt;string&amp;gt; OnChange
  {
    get { return _onChange; }
    set
    {
      if (value == null)
        throw new ArgumentNullException(&quot;OnChange should not be set to null&quot;);
      _onChange = value;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now it&#39;s &lt;em&gt;not&lt;/em&gt; possible for &quot;OnChange&quot; to be null, so a null reference exception can &lt;em&gt;not&lt;/em&gt; be thrown when the user tries to interact with the component.&lt;/p&gt;

&lt;p&gt;This still isn&#39;t fantastic, though. Is it really likely that there&#39;s ever a time where no &quot;OnChange&quot; value should have been set? Changes are that, in that case, there is still a programmer error (a &lt;strong&gt;TextInput&lt;/strong&gt; is useless without an &quot;OnChange&quot; callback and so one &lt;em&gt;should&lt;/em&gt; be set).. but now the error is being silently swallowed.&lt;/p&gt;

&lt;p&gt;So, maybe most properties should &lt;em&gt;have&lt;/em&gt; to be specified in order to get a new &lt;strong&gt;Props&lt;/strong&gt; instance. Since values have to be provided at the point of initialisation, they may as well be validated at that point. This is a very good argument for making the &lt;strong&gt;Props&lt;/strong&gt; class immutable - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  public Props(string className, string content, bool disabled, Action&amp;lt;string&amp;gt; onChange)
  {
    if (className == &quot;&quot;)
      throw new ArgumentException(&quot;className should not be set to a blank string&quot;);
    if (content == null)
      throw new ArgumentNullException(&quot;content&quot;);
    if (onChange == null)
      throw new ArgumentNullException(&quot;onChange&quot;);

    ClassName = className;
    Content = content;
    Disabled = disabled;
    OnChange = onChange;
  }

  /// &amp;lt;summary&amp;gt;
  /// This is optional and so may be null (if non-null, then it will never be blank)
  /// &amp;lt;/summary&amp;gt;
  public string ClassName { get; private set; }

  public bool Disabled { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// An input may not always have a value and so this may be blank (but it should never
  /// be null)
  /// &amp;lt;/summary&amp;gt;
  public string Content { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// This is mandatory and will never be null
  /// &amp;lt;/summary&amp;gt;
  public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;(Note: Since Bridge does not yet support C# 6 syntax, the new readonly auto-property syntax can&#39;t be used, hence the use of &quot;get; private set;&quot;).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Two nice benefits arise from this. Firstly, the comments may be tighted up - so &quot;OnChange&quot; is no longer described as&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is mandatory and should never be null&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;now it is&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is mandatory and will never be null&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It&#39;s a seemingly small change, but I&#39;m looking for confidence in the code and this is a positive step from &quot;hopefully this won&#39;t happen&quot; to &quot;this can not happen (because an ArgumentNullException would have been instantly thrown if an attempt was made to create a &lt;strong&gt;Props&lt;/strong&gt; instance in this manner)&quot;.&lt;/p&gt;

&lt;p&gt;The second benefit is that the &lt;strong&gt;Props&lt;/strong&gt; class now communicates one of the React guidelines - the React documentation states that props data should be considered immutable; once a component has a props reference, it should not try to change its data, nor should it expect any other code to be able to change it. Now, that commandment is baked into the code - this is a great example of what I mean when I talk about using a &quot;richer type system&quot;, there&#39;s more information that may be encoded than just &quot;this class has a property that is of type string&quot;.&lt;/p&gt;

&lt;p&gt;One final tweak to this sort of approach is to enable optional values to truly be optional. In this example, I&#39;m talking about &quot;className&quot;. The constructor may be changed from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Props(string className, string content, bool disabled, Action&amp;lt;string&amp;gt; onChange)
{
  if (className == &quot;&quot;)
    throw new ArgumentException(&quot;className should not be set to a blank string&quot;);
  if (content == null)
    throw new ArgumentNullException(&quot;content&quot;);
  if (onChange == null)
    throw new ArgumentNullException(&quot;onChange&quot;);

  ClassName = className;
  Content = content;
  Disabled = disabled;
  OnChange = onChange;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Props(
  string content,
  bool disabled,
  Action&amp;lt;string&amp;gt; onChange,
  string className = &quot;&quot;)
{
  if (content == null)
    throw new ArgumentNullException(&quot;content&quot;);
  if (onChange == null)
    throw new ArgumentNullException(&quot;onChange&quot;);
  if (className == &quot;&quot;)
    throw new ArgumentException(&quot;className should not be set to a blank string&quot;);

  Content = content;
  Disabled = disabled;
  OnChange = onChange;
  ClassName = className;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This means that an instance of &lt;strong&gt;TextInput.Props&lt;/strong&gt; may be created, if no class name is required, like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(title, isSaveInProgress, onTitleChange)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, if a class name &lt;em&gt;is&lt;/em&gt; required:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(title, isSaveInProgress, onTitleChange, &quot;title&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Personally, I like to use named constructor arguments when creating &lt;strong&gt;Props&lt;/strong&gt; instances, so I would probably write:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(
  className: &quot;title&quot;,
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I think that this makes the code easier to read (I don&#39;t need to resort to looking at the &lt;strong&gt;Props&lt;/strong&gt; constructor to see that &quot;title&quot; is a class name and not an ID or any other use for a string) &lt;em&gt;and&lt;/em&gt; means that it doesn&#39;t matter that the &quot;className&quot; argument moved from the start of the constructor argument list to the end, since the position of arguments doesn&#39;t matter when their names are used. (As an added benefit, this makes the code slightly more similar to the React component initialisation code that you might see in non-Bridge/C# projects, where JSON objects are used to set properties - but, here, we have the added benefit that&#39;s it all typed).&lt;/p&gt;

&lt;p&gt;This is a big step forward in terms of including additional information in the type system (and in terms of catching errors quickly - and as close to the root cause of the error as possible), meaning that I can more reliably use a component without having to know everything about how it works (which, in a lot of ways, is like the idea of coding against an interface - you want to know about how to communicate with an interface to get the desired result without having to know all of the details of its implementation).&lt;/p&gt;

&lt;p&gt;I&#39;m not completely happy with the code at this point, though. It feels like the &lt;strong&gt;Props&lt;/strong&gt; class has ballooned considerably from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  public string ClassName;
  public bool Disabled;
  public string Content;
  public Action&amp;lt;string&amp;gt; OnChange;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props
{
  public Props(
    string content,
    bool disabled,
    Action&amp;lt;string&amp;gt; onChange,
    string className = &quot;&quot;)
  {
    if (content == null)
      throw new ArgumentNullException(&quot;content&quot;);
    if (onChange == null)
      throw new ArgumentNullException(&quot;onChange&quot;);
    if (className == &quot;&quot;)
      throw new ArgumentException(&quot;className should not be set to a blank string&quot;);

    Content = content;
    Disabled = disabled;
    OnChange = onChange;
    ClassName = className;
  }

  /// &amp;lt;summary&amp;gt;
  /// This is optional and so may be null (if non-null, then it will never be blank)
  /// &amp;lt;/summary&amp;gt;
  public string ClassName { get; private set; }

  public bool Disabled { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// An input may not always have a value and so this may be blank (but it should never
  /// be null)
  /// &amp;lt;/summary&amp;gt;
  public string Content { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// This is mandatory and will never be null
  /// &amp;lt;/summary&amp;gt;
  public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While I am willing to make a certain trade-off between the cost of writing the code to begin with against the long term benefits of it being easier to quickly understand and then reason about*, I don&#39;t want to have to write any more of this monotonous form of code than absolutely necessary - in particular, I think I would get bored of writing &quot;This is mandatory and will never be null&quot; over and over again on different properties on different classes**.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Since &quot;&lt;a href=&quot;https://blogs.msdn.microsoft.com/oldnewthing/20070406-00/?p=27343&quot;&gt;Code is read much more often than it is written, so plan accordingly&lt;/a&gt;&quot;, I strongly believe that a little extra writing effort is worth it to reduce the more-often-incurred reading effort).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;** &lt;em&gt;(I have personally written a lot of code that uses immutable, always-valid types and that was littered with these sorts of comments - while I definitely think it was worth it, I definitely HAVE gotten bored with writing &quot;This will never be null&quot; time after time after time).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But what alternative is there?&lt;/p&gt;

&lt;h3&gt;Working on the basis that null is &lt;em&gt;never&lt;/em&gt; allowed&lt;/h3&gt;

&lt;p&gt;Since this whole series is about &quot;The Dan Way&quot;, I think that it is entirely reasonable to introduce a library that I&#39;ve written at this point. It&#39;s a NuGet package for Bridge that makes it easier to write immutable types, such as the &lt;strong&gt;Props&lt;/strong&gt; class above: &quot;&lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt;&quot;.&lt;/p&gt;

&lt;p&gt;If a class implements an empty interface &lt;strong&gt;IAmImmutable&lt;/strong&gt; then it may access extension methods that make the constructor easier to write. Something along the lines of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props : IAmImmutable
{
  public Props(
    string content,
    bool disabled,
    Action&amp;lt;string&amp;gt; onChange,
    string className = &quot;&quot;)
  {
    this.CtorSet(_ =&amp;gt; _.Content, content);
    this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
    this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
    this.CtorSet(_ =&amp;gt; _.ClassName, className);
  }
  public string ClassName { get; private set; }
  public bool Disabled { get; private set; }
  public string Content { get; private set; }
  public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The extension method is &quot;CtorSet&quot; and it takes a lambda that specifies a property on the class and it takes a new value for that property. The type of the property and the type of the new value must be consistent - so, although there&#39;s apparently a little magic involved, we&#39;re not sacrificing any type safety.&lt;/p&gt;

&lt;p&gt;One interesting feature of &quot;CtorSet&quot; is that it will never allow a null value. This means the comments from the &lt;strong&gt;Props&lt;/strong&gt; class along the lines of &quot;This will never be null&quot; are unnecessary because an &lt;strong&gt;IAmImmutable&lt;/strong&gt;-implementing class that sets all of its properties in its constructor will never have any null property values.&lt;/p&gt;

&lt;p&gt;This actually doesn&#39;t work for the &lt;strong&gt;Props&lt;/strong&gt; class we&#39;re looking at here since we want &quot;ClassName&quot; to be allowed to be null. To enable that, the library comes with a new struct - &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt;. Any time that you want to have a constructor argument be null, you have to wrap its type in this struct - ie.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props : IAmImmutable
{
  public Props(
    string content,
    bool disabled,
    Action&amp;lt;string&amp;gt; onChange,
    Optional&amp;lt;string&amp;gt; className = new Optional&amp;lt;string&amp;gt;())
  {
    this.CtorSet(_ =&amp;gt; _.Content, content);
    this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
    this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
    this.CtorSet(_ =&amp;gt; _.ClassName, className);
  }
  public Optional&amp;lt;string&amp;gt; ClassName { get; private set; }
  public bool Disabled { get; private set; }
  public string Content { get; private set; }
  public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, we&#39;ve made a step forward to encoding additional information in the class itself. In terms of being able to more easily reason about the code, this is a great win - classes such as these will never have null values to worry about; any property that may or may not have a value will be of type &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt;, which has properties &quot;IsDefined&quot; (a boolean indicating whether or not it has a value) and &quot;Value&quot; (which is the value itself, so long as &quot;IsDefined&quot; is true).&lt;/p&gt;

&lt;p&gt;If you were in an argumentative mood, then you might say that &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; can&#39;t save you from nulls in all cases since any code that deals with them could choose not to check &quot;IsDefined&quot; and to just try to access &quot;className.Value&quot; in all cases. This is true, but this faulty style of calling code had to be explicitly written to &quot;work around&quot; the &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; wrapper. If the person who wrote it had sufficiently little interest to try to understand why &lt;strong&gt;Optional&amp;lt;T&amp;gt;&lt;/strong&gt; was used then they may need some help in getting back on to the right path in their programming. This wrapper type acts as a sign post at each point where a null may be encountered, if the sign posts are ignored then that&#39;s unfortunate (but the benefit remains that there &lt;em&gt;is&lt;/em&gt; a sign post for every potentially-null value whereas, in normal C# code, you need to be wary that nulls may leap out at you at any point, without warning).&lt;/p&gt;

&lt;p&gt;This change doesn&#39;t affect how you call the constructor if you used the named arguments approach from above, so the following works fine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(
  className: &quot;title&quot;,
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;as does:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you wanted to really deliberately indicate that a &lt;strong&gt;TextInput&lt;/strong&gt; should have no title then you could use any of the following three -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// The explicit way
new TextInput.Props(
  className: Optional&amp;lt;string&amp;gt;.Missing,
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)

// The implicit way (there is an implicit cast from T to Optional&amp;lt;T&amp;gt;, which is why passing
// the string &quot;title&quot; in the earlier example works, because the &quot;title&quot; string is implicitly
// cast to an Optional&amp;lt;string&amp;gt; with value &quot;title&quot; - similarly null is implicitly cast to
// an Optional&amp;lt;string&amp;gt; with value null, which is the same as Optional&amp;lt;string&amp;gt;.Missing)
new TextInput.Props(
  className: null,
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)

// Using the struct&#39;s constructor - the most verbose and least-prefered way. Note that this
// is the only way that a &quot;Missing&quot; value may be specified as a constructor argument&#39;s
// default value, as may be seen in the Props constructor above (this is because default
// argument values must be compile time constants, which a new instance of a struct is but
// the static &quot;Missing&quot; property is not. Null can&#39;t be used as a constructor argument&#39;s
// default value for an Optional as the implicit cast is a runtime operation and so is
// not available at compile time).
new TextInput.Props(
  className: new Optional&amp;lt;string&amp;gt;(),
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&#39;m &lt;em&gt;still&lt;/em&gt; not happy with this, though. I talked earlier about the ambiguity between null and blank string - for the &quot;Value&quot; property, this is solved since it can never be null now. It&#39;s valid for it to be a blank string (if there is no content in the input box) but it&#39;s not valid for it to be null (an &lt;strong&gt;ArgumentNullException&lt;/strong&gt; will be raised in the constructor for a null &quot;value&quot;). Problem solved. However, the &quot;ClassName&quot; property can be &quot;&lt;strong&gt;Optional&amp;lt;string&amp;gt;&lt;/strong&gt;.Missing&quot; (which is similar to null) or it can be a value that is a blank string. It would be much better to say that &quot;ClassName&quot; is &quot;Missing&quot; (meaning that it has no value and that the DOM element should have a &quot;class&quot; attribute at all) &lt;em&gt;or&lt;/em&gt; that it has a value that is not blank.&lt;/p&gt;

&lt;p&gt;One way to try to address this would be with &lt;em&gt;another&lt;/em&gt; type -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class NonBlankTrimmedString
{
  public NonBlankTrimmedString(string value)
  {
    if (string.IsNullOrWhiteSpace(value))
      throw new ArgumentException(&quot;Null, blank or whitespace-only value specified&quot;);
    Value = value.Trim();
  }

  /// &amp;lt;summary&amp;gt;
  /// This will never be null, blank or have any leading or trailing whitespace
  /// &amp;lt;/summary&amp;gt;
  public string Value { get; private set; }

  /// &amp;lt;summary&amp;gt;
  /// It&#39;s convenient to be able to pass a NonBlankTrimmedString instance as any argument
  /// that requires a string
  /// &amp;lt;/summary&amp;gt;
  public static implicit operator string(NonBlankTrimmedString value)
  {
    if (value == null)
      throw new ArgumentNullException(&quot;value&quot;);
    return value.Value;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I said that I wasn&#39;t keen on writing out more of this type of &quot;This will never be null..&quot; summary comment if I could avoid it, but the idea with this class it that it will be applicable in multiple places. So I have had to type &quot;This will never be null, blank or have any leading or trailing whitespace&quot; &lt;em&gt;once again&lt;/em&gt; but I will take advantage of this one comment over and over again throughout my code.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Now&lt;/em&gt; the &lt;strong&gt;TextInput.Props&lt;/strong&gt; class becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Props : IAmImmutable
{
  public Props(
    string content,
    bool disabled,
    Action&amp;lt;string&amp;gt; onChange,
    Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
  {
    this.CtorSet(_ =&amp;gt; _.Content, content);
    this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
    this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
    this.CtorSet(_ =&amp;gt; _.ClassName, className);
  }
  public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
  public bool Disabled { get; private set; }
  public string Content { get; private set; }
  public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you wanted to instantiate one then you would need to change the calling code slightly - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput.Props(
  className: new NonBlankTrimmedString(&quot;title&quot;),
  value: title,
  disabled: isSaveInProgress,
  onChange: onTitleChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;em&gt;does&lt;/em&gt; make this code a little more verbose. But we have the benefit that the &lt;strong&gt;Props&lt;/strong&gt; class contains more information about what is and isn&#39;t acceptable for its property values. Also, making the calling code more explicit like this forces the writer to consider whether an appropriate value will always be passed to it - they should be careful to pass null or &quot;&lt;strong&gt;Optional&amp;lt;NonBlankTrimmedString&amp;gt;&lt;/strong&gt;.Missing&quot; if they don&#39;t want to set a class name and to provide a populated, non-blank string if they &lt;em&gt;do&lt;/em&gt; want a class name.&lt;/p&gt;

&lt;p&gt;At this point, I&#39;m finally satisifed with the &lt;strong&gt;TextInput.Props&lt;/strong&gt; class!&lt;/p&gt;

&lt;p&gt;Note: This is probably the most controversial part of my recommended approach - if you&#39;re happy to consider making your classes immutable like this, for the reasons I outlined above (which, by the way, can be applied to &lt;em&gt;all&lt;/em&gt; classes in your code, not just props types for React components) and you&#39;re willing to consider the benefits and trade-offs of building up a more detailed type system (such as using &lt;strong&gt;Optional&amp;lt;NonBlankOrTrimmedString&amp;gt;&lt;/strong&gt; instead of just &quot;string&quot; and only using &quot;string&quot; to mean &quot;non-nullable string&quot;) then I think that you&#39;ll enjoy the rest of what I&#39;ve got to say.&lt;/p&gt;

&lt;p&gt;I want to extend this ostracising of nulls to the &lt;strong&gt;TextInput&lt;/strong&gt; class itself, though. At the end of &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-two&quot;&gt;Part Two&lt;/a&gt;, the component looked like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.Html5;
using Bridge.React;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class TextInput : StatelessComponent&amp;lt;TextInput.Props&amp;gt;
  {
    public TextInput(Props props) : base(props) { }

    public override ReactElement Render()
    {
      return DOM.Input(new InputAttributes
      {
        Type = InputType.Text,
        ClassName = props.ClassName,
        Disabled = props.Disabled,
        Value = props.Content,
        OnChange = e =&amp;gt; props.OnChange(e.CurrentTarget.Value)
      });
    }

    public class Props : IAmImmutable
    {
      public string ClassName;
      public bool Disabled;
      public string Content;
      public Action&amp;lt;string&amp;gt; OnChange;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My problem with this is that it&#39;s possible to call the constructor with a null &quot;props&quot; value - but, if you do so, then the &quot;Render&quot; method will throw a null reference exception. Unfortunately, it&#39;s not possible to check for a null &quot;props&quot; value in the component&#39;s constructor due to the way that the Bridge / React bindings work with the React library; the constructor is never actually executed and so a null-check in there would never run. What I suggest is that the &lt;strong&gt;Props&lt;/strong&gt; constructor arguments be repeated in the component&#39;s constructor -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.Html5;
using Bridge.React;
using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class TextInput : StatelessComponent&amp;lt;TextInput.Props&amp;gt;
  {
    public TextInput(
      string content,
      bool disabled,
      Action&amp;lt;string&amp;gt; onChange,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(content, disabled, onChange, className)) { }

    public override ReactElement Render()
    {
      return DOM.Input(new InputAttributes
      {
        Type = InputType.Text,
        ClassName = props.ClassName.IsDefined ? props.ClassName.Value : null,
        Disabled = props.Disabled,
        Value = props.Content,
        OnChange = e =&amp;gt; props.OnChange(e.CurrentTarget.Value)
      });
    }

    public class Props : IAmImmutable
    {
      public Props(
        string content,
        bool disabled,
        Action&amp;lt;string&amp;gt; onChange,
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className)
      {
        this.CtorSet(_ =&amp;gt; _.Content, content);
        this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public bool Disabled { get; private set; }
      public string Content { get; private set; }
      public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, this &lt;em&gt;has&lt;/em&gt; expanded the amount of code that is required within the component class. But the real effect is magnified by the line-wrapping that I use on my blog post code samples - in Visual Studio, I would likely have the constructor arguments all on one line.&lt;/p&gt;

&lt;p&gt;If we can get past the cost of additional code within the component then we get two benefits. The first is that it&#39;s no longer possible for the &lt;strong&gt;TextInput&lt;/strong&gt; to ever have a null &quot;props&quot; reference as a &lt;strong&gt;Props&lt;/strong&gt; reference is no longer passed in, but is created in the call to the base constructor by using the individual arguments passed to the &lt;strong&gt;TextInput&lt;/strong&gt; constructor. The second benefit is more marginal, but still nice (especially since it partially offsets the additional code added above) - the way that a new &lt;strong&gt;TextInput&lt;/strong&gt; was declared previously required duplication of the word &quot;&lt;strong&gt;TextInput&lt;/strong&gt;&quot; (with &quot;new &lt;strong&gt;TextInput&lt;/strong&gt;&quot; and &quot;new &lt;strong&gt;TextInput.Props&lt;/strong&gt;&quot;) -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput(new TextInput.Props
{
  ClassName = &quot;title&quot;
  Disabled = props.Disabled,
  Content = props.Content,
  OnChange = props.OnChange
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the updated &lt;strong&gt;TextInput&lt;/strong&gt; implementation, this duplication is avoided -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new TextInput(
  className: new NonBlankTrimmedString(&quot;title&quot;),
  disabled: props.Disabled,
  content: props.Content,
  onChange: props.OnChange
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even without this (admittedly minor) second benefit, I would still be much happier with the new version of &lt;strong&gt;TextInput&lt;/strong&gt;. The additional code (the final version is definitely somewhat longer than the previous version) pays for itself in what it communicates to someone who wishes to consume that component. However, one of the themes that I&#39;ve been pushing in this series is that components should be dumb and that the real logic of the application should be outside of any UI classes; in the application code that will deal with the complications of the business logic and how to deal with user interactions.. if there is a way to move some of the syntactic noise around component creation away from the complicated library code and into the dumb components, then that seems a sensible trade-off. And that&#39;s what has been done here!&lt;/p&gt;

&lt;p&gt;There&#39;s actually a &lt;em&gt;third&lt;/em&gt; benefit to using this &quot;&lt;strong&gt;IAmImmutable&lt;/strong&gt; style&quot; for writing these data types, when it comes to passing events from the simple components all the way up to the top of the component tree, where each &quot;OnChange&quot; (or whatever) adds increasing detail on the way up - but I&#39;ll come to that later on, first I want to address a burning question:&lt;/p&gt;

&lt;h3&gt;If it&#39;s so effective to work on the basis that null should not be allowed anywhere in components and their Props, why not use this approach elsewhere in the application?&lt;/h3&gt;

&lt;p&gt;Trick question! I am convinced that it &lt;em&gt;does&lt;/em&gt; make sense to use &lt;strong&gt;IAmImmutable&lt;/strong&gt; for data types &lt;em&gt;throughout&lt;/em&gt; the application and to make null arguments and properties unacceptable in &lt;em&gt;all&lt;/em&gt; places.&lt;/p&gt;

&lt;p&gt;One obvious example is in the &quot;SaveMessage&quot; method in the &lt;strong&gt;MessageApi&lt;/strong&gt; class. Currently, it starts like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private RequestId SaveMessage(MessageDetails message, Action optionalSaveCompletedCallback)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);
  if (string.IsNullOrWhiteSpace(message.Title))
    throw new ArgumentException(&quot;A title value must be provided&quot;);
  if (string.IsNullOrWhiteSpace(message.Content))
    throw new ArgumentException(&quot;A content value must be provided&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not accepting a null &lt;strong&gt;MessageDetails&lt;/strong&gt; instance is good - if someone tried to call this method with a null &quot;message&quot; argument then it should be rejected immediately. However, it feels wrong that it&#39;s necesary to then check the &quot;Title&quot; and &quot;Content&quot; properties - should there ever be a case where a &lt;strong&gt;MessageDetails&lt;/strong&gt; instance exists &lt;em&gt;without&lt;/em&gt; these values being populated? In this application, the answer is no - the &lt;strong&gt;MessageEditor&lt;/strong&gt; component only allows a new message to be saved if both its Title and Content have values.&lt;/p&gt;

&lt;p&gt;This is another opportunity to encode this additional information into the type system. Instead of &lt;strong&gt;MessageDetails&lt;/strong&gt; being implemented like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace BridgeReactTutorial.ViewModels
{
  public class MessageDetails
  {
    public string Title;
    public string Content;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It should be rewritten thusly:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.ViewModels
{
  public class MessageDetails : IAmImmutable
  {
    public MessageDetails(NonBlankTrimmedString title, NonBlankTrimmedString content)
    {
      this.CtorSet(_ =&amp;gt; _.Title, title);
      this.CtorSet(_ =&amp;gt; _.Content, content);
    }
    public NonBlankTrimmedString Title { get; private set; }
    public NonBlankTrimmedString Content { get; private set; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, the &quot;SaveMessage&quot; validation is much simpler - all that is required is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private RequestId SaveMessage(MessageDetails message, Action optionalSaveCompletedCallback)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since a &lt;strong&gt;MessageDetails&lt;/strong&gt; instance may no longer exist with missing Title or Content values, the property validation in &quot;SaveMessage&quot; is unnecessary. This has the benefit that there is less code at the point at which data is retrieved from a &lt;strong&gt;MessageDetails&lt;/strong&gt; instance, which goes some way to offsetting the additional code required in defining the type. The real benefit, though, to removing that code is not just reducing line count but in removing potential duplication (the property validation code may have appeared elsewhere in the application if there were other methods that processed &lt;strong&gt;MessageDetails&lt;/strong&gt; instances) &lt;em&gt;and&lt;/em&gt; baking assumptions into the type system, rather than leaving them be implicit. Before, it was probably safe to assume that Title and Content would always have values since the code that would create a &lt;strong&gt;MessageDetails&lt;/strong&gt; instance would always give them values - however, that was &lt;em&gt;only&lt;/em&gt; an assumption and you would have had to have read all of the code that created &lt;strong&gt;MessageDetails&lt;/strong&gt; instances to be confident. With this arrangement, you &lt;em&gt;know&lt;/em&gt; that a &lt;strong&gt;MessageDetails&lt;/strong&gt; has both Title and Content values at all times, since it&#39;s not possible for an instance to be created that doesn&#39;t!&lt;/p&gt;

&lt;p&gt;When I talk about code being easy to reason about, it&#39;s not usually in terms of the dozen or so lines of code that are directly in front of you, it&#39;s how the objects and methods that you&#39;re dealing with may interact with the rest of the system and what assumptions are being made. Knowing that a &lt;strong&gt;MessageDetails&lt;/strong&gt; instance will always be valid is extremely helpful. Knowing that any code that attempts to create a &lt;strong&gt;MessageDetails&lt;/strong&gt; with invalid data will fail immeditely, rather than cause an error later on (when the instance is presumed to be valid but turns out not to be) is extremely helpful. Knowing that a type is immutable and that it won&#39;t be changed &quot;behind the scenes&quot; when you pass it off to another method is extremely helpful - when types are mutable and you pass an instance to another method to read, you can&#39;t be sure whether the method will &lt;em&gt;only&lt;/em&gt; read it or whether it will manipulate it; there&#39;s no way to tell from the method signature. Making mutations explicit by making types immutable is another big win for being able to reason about code.&lt;/p&gt;

&lt;p&gt;Speaking of dealing with mutation brings me smoothly onto the third benefit of &lt;strong&gt;IAmImmutable&lt;/strong&gt; that I hinted at earlier. Currently, the &lt;strong&gt;MessageEditor&lt;/strong&gt; component in our example app looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.React;
using BridgeReactTutorial.ViewModels;

namespace BridgeReactTutorial.Components
{
  public class MessageEditor : StatelessComponent&amp;lt;MessageEditor.Props&amp;gt;
  {
    public MessageEditor(Props props) : base(props) { }

    public override ReactElement Render()
    {
      var formIsInvalid =
        !string.IsNullOrWhiteSpace(props.Message.Title.ValidationError) ||
        !string.IsNullOrWhiteSpace(props.Message.Content.ValidationError);

      return DOM.FieldSet(new FieldSetAttributes { ClassName = props.ClassName },
        DOM.Legend(null, props.Message.Caption),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Title&quot;),
        new ValidatedTextInput(new ValidatedTextInput.Props
        {
          ClassName = &quot;title&quot;,
          Disabled = props.Message.IsSaveInProgress,
          Content = props.Message.Title.Text,
          OnChange = newTitle =&amp;gt; props.OnChange(new MessageEditState
          {
            Title = new TextEditState { Text = newTitle },
            Content = props.Message.Content
          }),
          ValidationMessage = props.Message.Title.ValidationError
        }),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Content&quot;),
        new ValidatedTextInput(new ValidatedTextInput.Props
        {
          ClassName = &quot;content&quot;,
          Disabled = props.Message.IsSaveInProgress,
          Content = props.Message.Content.Text,
          OnChange = newContent =&amp;gt; props.OnChange(new MessageEditState
          {
            Title = props.Message.Title,
            Content = new TextEditState { Text = newContent },
          }),
          ValidationMessage = props.Message.Content.ValidationError
        }),
        DOM.Button(
        new ButtonAttributes
        {
          Disabled = formIsInvalid || props.Message.IsSaveInProgress,
          OnClick = e =&amp;gt; props.OnSave()
        },
        &quot;Save&quot;
        )
      );
    }

    public class Props
    {
      public string ClassName;
      public MessageEditState Message;
      public Action&amp;lt;MessageEditState&amp;gt; OnChange;
      public Action OnSave;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing I&#39;m going to do is change the &lt;strong&gt;Props&lt;/strong&gt; type and the component&#39;s constructor in the same way as I did for the &lt;strong&gt;TextInput&lt;/strong&gt; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.React;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class MessageEditor : StatelessComponent&amp;lt;MessageEditor.Props&amp;gt;
  {
    public MessageEditor(
      MessageEditState message,
      Action&amp;lt;MessageEditState&amp;gt; onChange,
      Action onSave,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, message, onChange, onSave)) { }

    public override ReactElement Render()
    {
      var formIsInvalid =
        !string.IsNullOrWhiteSpace(props.Message.Title.ValidationError) ||
        !string.IsNullOrWhiteSpace(props.Message.Content.ValidationError);

      return DOM.FieldSet(
        new FieldSetAttributes {
          ClassName = props.ClassName.IsDefined ? props.ClassName.Value : null
        },
        DOM.Legend(null, props.Message.Caption),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Title&quot;),
        new ValidatedTextInput(new ValidatedTextInput.Props
        {
          ClassName = &quot;title&quot;,
          Disabled = props.Message.IsSaveInProgress,
          Content = props.Message.Title.Text,
          OnChange = newTitle =&amp;gt; props.OnChange(new MessageEditState
          {
            Title = new TextEditState { Text = newTitle },
            Content = props.Message.Content
          }),
          ValidationMessage = props.Message.Title.ValidationError
        }),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Content&quot;),
        new ValidatedTextInput(new ValidatedTextInput.Props
        {
          ClassName = &quot;content&quot;,
          Disabled = props.Message.IsSaveInProgress,
          Content = props.Message.Content.Text,
          OnChange = newContent =&amp;gt; props.OnChange(new MessageEditState
          {
            Title = props.Message.Title,
            Content = new TextEditState { Text = newContent },
          }),
          ValidationMessage = props.Message.Content.ValidationError
        }),
        DOM.Button(
        new ButtonAttributes
        {
          Disabled = formIsInvalid || props.Message.IsSaveInProgress,
          OnClick = e =&amp;gt; props.OnSave()
        },
        &quot;Save&quot;
        )
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        MessageEditState message,
        Action&amp;lt;MessageEditState&amp;gt; onChange,
        Action onSave)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Message, message);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.OnSave, onSave);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public MessageEditState Message { get; private set; }
      public Action&amp;lt;MessageEditState&amp;gt; OnChange { get; private set; }
      public Action OnSave { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This means that the &lt;strong&gt;MessageEditor&lt;/strong&gt; instantiation code changes slightly from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new MessageEditor(new MessageEditor.Props
{
  ClassName = &quot;message&quot;,
  Message = state.Message,
  OnChange = newState =&amp;gt; props.Dispatcher.HandleViewAction(
    UserEditRequested.For(newState)
  ),
  OnSave = () =&amp;gt; props.Dispatcher.HandleViewAction(
    SaveRequested.For(
      new MessageDetails(
        new NonBlankTrimmedString(state.Message.Title.Text),
        new NonBlankTrimmedString(state.Message.Content.Text)
      )
    )
  )
}),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new MessageEditor(
  className: new NonBlankTrimmedString(&quot;message&quot;),
  message:  state.Message,
  onChange: newState =&amp;gt; props.Dispatcher.HandleViewAction(
    UserEditRequested.For(newState)
  ),
  onSave: () =&amp;gt; props.Dispatcher.HandleViewAction(
    SaveRequested.For(
      new MessageDetails(
        new NonBlankTrimmedString(state.Message.Title.Text),
        new NonBlankTrimmedString(state.Message.Content.Text)
      )
    )
  )
),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are several steps that need following now until I can reveal my point,  so bear with me. I&#39;m going to change the &lt;strong&gt;MessageEditState&lt;/strong&gt; data type, in the same way as I did the &lt;strong&gt;MessageDetails&lt;/strong&gt; - from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace BridgeReactTutorial.ViewModels
{
  public class MessageEditState
  {
    public string Caption;
    public TextEditState Title;
    public TextEditState Content;
    public bool IsSaveInProgress;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.ViewModels
{
  public class MessageEditState : IAmImmutable
  {
    public MessageEditState(
      NonBlankTrimmedString caption,
      TextEditState title,
      TextEditState content,
      bool isSaveInProgress)
    {
      this.CtorSet(_ =&amp;gt; _.Caption, caption);
      this.CtorSet(_ =&amp;gt; _.Title, title);
      this.CtorSet(_ =&amp;gt; _.Content, content);
      this.CtorSet(_ =&amp;gt; _.IsSaveInProgress, isSaveInProgress);
    }
    public NonBlankTrimmedString Caption { get; private set; }
    public TextEditState Title { get; private set; }
    public TextEditState Content { get; private set; }
    public bool IsSaveInProgress { get; private set; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And do the same with &lt;strong&gt;TextEditState&lt;/strong&gt;, from -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace BridgeReactTutorial.ViewModels
{
    public class TextEditState
    {
        public string Text;
        public string ValidationError;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.ViewModels
{
  public class TextEditState : IAmImmutable
  {
    public TextEditState(
      string text,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; validationError = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
    {
      this.CtorSet(_ =&amp;gt; _.Text, text);
      this.CtorSet(_ =&amp;gt; _.ValidationError, validationError);
    }
    public string Text { get; private set; }
    public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ValidationError { get; private set; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&#39;m going to change the &lt;strong&gt;ValidatedTextInput&lt;/strong&gt; to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.React;
using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class ValidatedTextInput : StatelessComponent&amp;lt;ValidatedTextInput.Props&amp;gt;
  {
    public ValidatedTextInput(
      bool disabled,
      string content,
      Action&amp;lt;string&amp;gt; onChange,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; validationMessage,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, disabled, content, onChange, validationMessage)) { }

    public override ReactElement Render()
    {
      var className = props.ClassName;
      if (props.ValidationMessage.IsDefined)
        className = className.Add(&quot; &quot;, new NonBlankTrimmedString(&quot;invalid&quot;));
      return DOM.Span(new Attributes { ClassName = className.ToStringIfDefined() },
        new TextInput(
          className: props.ClassName,
          disabled: props.Disabled,
          content: props.Content,
          onChange: props.OnChange
        ),
        props.ValidationMessage.IsDefined
        ? DOM.Span(
          new Attributes { ClassName = &quot;validation-message&quot; },
          props.ValidationMessage.ToStringIfDefined()
        )
        : null
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        bool disabled,
        string content,
        Action&amp;lt;string&amp;gt; onChange,
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; validationMessage)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Disabled, disabled);
        this.CtorSet(_ =&amp;gt; _.Content, content);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.ValidationMessage, validationMessage);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public bool Disabled { get; private set; }
      public string Content { get; private set; }
      public Action&amp;lt;string&amp;gt; OnChange { get; private set; }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ValidationMessage { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. which requires a new class be added to the &quot;API&quot; folder with some extension methods to make dealing with &lt;strong&gt;Optional&amp;lt;NonBlankTrimmedString&amp;gt;&lt;/strong&gt; a little nicer -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.API
{
  public static class OptionalNonBlankTrimmedStringExtensions
  {
    /// &amp;lt;summary&amp;gt;
    /// If the Optional NonBlankTrimmedString has a value then it will be unwrapped directly
    /// into a string - if not, the null will be returned (this is one of the few places
    /// where null will be an acceptable value in the app and it should be only used when
    /// integrating with code that expects nulls - such as when setting attributes via
    /// React html element factories)
    /// &amp;lt;/summary&amp;gt;
    public static string ToStringIfDefined(this Optional&amp;lt;NonBlankTrimmedString&amp;gt; source)
    {
      return source.IsDefined ? source.Value : null;
    }

    /// &amp;lt;summary&amp;gt;
    /// This will join two Optional NonBlankTrimmedString with a specified delimiter if
    /// they both have values. If only one of them has a value then this will be returned
    /// unaltered. If neither of them have a value then a Missing value will be returned.
    /// &amp;lt;/summary&amp;gt;
    public static Optional&amp;lt;NonBlankTrimmedString&amp;gt; Add(
      this Optional&amp;lt;NonBlankTrimmedString&amp;gt; source,
      string delimiter,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; other)
    {
      if (delimiter == null)
        throw new ArgumentNullException(&quot;delimiter&quot;);

      if (!source.IsDefined &amp;amp;&amp;amp; !other.IsDefined)
        return Optional&amp;lt;NonBlankTrimmedString&amp;gt;.Missing;
      else if (!source.IsDefined)
        return other;
      else if (!other.IsDefined)
        return source;

      return new NonBlankTrimmedString(source.Value.Value + delimiter + other.Value.Value);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and a further implicit operator adding to the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// It&#39;s convenient to be able to pass a NonBlankTrimmedString instance as any argument
    /// that requires a ReactElement-or-string, such as for the children array of the React
    /// DOM component factories
    /// &amp;lt;/summary&amp;gt;
    public static implicit operator Any&amp;lt;ReactElement, string&amp;gt;(NonBlankTrimmedString value)
    {
        if (value == null)
            throw new ArgumentNullException(&quot;value&quot;);
        return value.Value;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, now I&#39;m finally able to demonstrate this mysterious third benefit. The &quot;OnChange&quot; lambdas which were provided as &lt;strong&gt;ValidatedTextInput.Props&lt;/strong&gt; values by the &lt;strong&gt;MessageEditor&lt;/strong&gt;&#39;s &quot;Render&quot; method were previously specified like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnChange = newTitle =&amp;gt; props.OnChange(new MessageEditState
{
  Title = new TextEditState { Text = newTitle },
  Content = props.Message.Content
})

OnChange = newContent =&amp;gt; props.OnChange(new MessageEditState
{
  Title = props.Message.Title,
  Content = new TextEditState { Text = newContent },
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Within each &quot;OnChange&quot;, we want to create a new &lt;strong&gt;MessageEditState&lt;/strong&gt; instance with one of the properties changed. However, it get arduous having to repeat &lt;em&gt;all&lt;/em&gt; of the property names each time that you want to change a single property - here it&#39;s not &lt;em&gt;that&lt;/em&gt; bad because there are only two properties (&quot;Title&quot; and &quot;Content&quot;), but on classes with more properties this is annoying and, worse, error-prone.&lt;/p&gt;

&lt;p&gt;Now that &lt;strong&gt;MessageEditState&lt;/strong&gt; implements &lt;strong&gt;IAmImmutable&lt;/strong&gt;, we can take advantage of another extension method available; &quot;With&quot;. This takes an argument that specifies the property to change and it takes an argument for the new property value. This means that&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnChange = newTitle =&amp;gt; props.OnChange(new MessageEditState
{
  Title = new TextEditState { Text = newTitle },
  Content = props.Message.Content
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is replaced with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnChange = newTitle =&amp;gt; props.OnChange(
   props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnChange = newContent =&amp;gt; props.OnChange(new MessageEditState
{
  Title = props.Message.Title,
  Content = new TextEditState { Text = newContent }
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is replaced with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnChange = newContent =&amp;gt; props.OnChange(
  props.Message.With(_ =&amp;gt; _.Content, new TextEditState(newContent))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;(Again, I&#39;m only wrapping these lines for the sake of the formatting on my blog - if I was writing this code in Visual Studio then I would make those a single line each).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The &quot;With&quot; function takes an instance of an &lt;strong&gt;IAmImmutable&lt;/strong&gt;-implementing class, clones it but changes the specified property value - unless the new value is the same as the old value, in which case it returns the original instance unaltered.&lt;/p&gt;

&lt;p&gt;All of these changes combined mean that the &lt;strong&gt;MessageEditor&lt;/strong&gt; component now becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.React;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class MessageEditor : StatelessComponent&amp;lt;MessageEditor.Props&amp;gt;
  {
    public MessageEditor(
      MessageEditState message,
      Action&amp;lt;MessageEditState&amp;gt; onChange,
      Action onSave,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, message, onChange, onSave)) { }

    public override ReactElement Render()
    {
      var formIsInvalid =
        props.Message.Title.ValidationError.IsDefined ||
        props.Message.Content.ValidationError.IsDefined;

      return DOM.FieldSet(
        new FieldSetAttributes { ClassName = props.ClassName.ToStringIfDefined() },
        DOM.Legend(null, props.Message.Caption),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Title&quot;),
        new ValidatedTextInput(
          className: new NonBlankTrimmedString(&quot;title&quot;),
          disabled: props.Message.IsSaveInProgress,
          content: props.Message.Title.Text,
          onChange: newTitle =&amp;gt; props.OnChange(
            props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle))
          ),
          validationMessage: props.Message.Title.ValidationError
        ),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Content&quot;),
        new ValidatedTextInput(
          className: new NonBlankTrimmedString(&quot;content&quot;),
          disabled: props.Message.IsSaveInProgress,
          content: props.Message.Content.Text,
          onChange: newContent =&amp;gt; props.OnChange(
            props.Message.With(_ =&amp;gt; _.Content, new TextEditState(newContent))
          ),
          validationMessage: props.Message.Content.ValidationError
        ),
        DOM.Button(
        new ButtonAttributes
        {
          Disabled = formIsInvalid || props.Message.IsSaveInProgress,
          OnClick = e =&amp;gt; props.OnSave()
        },
        &quot;Save&quot;
        )
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        MessageEditState message,
        Action&amp;lt;MessageEditState&amp;gt; onChange,
        Action onSave)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Message, message);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.OnSave, onSave);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public MessageEditState Message { get; private set; }
      public Action&amp;lt;MessageEditState&amp;gt; OnChange { get; private set; }
      public Action OnSave { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;One more example&lt;/h3&gt;

&lt;p&gt;Before moving on, I want to apply these changes to one more component to really drive the point home.&lt;/p&gt;

&lt;p&gt;This is the &lt;strong&gt;MessageHistory&lt;/strong&gt; component as it currently stands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using System.Linq;
using Bridge.React;
using BridgeReactTutorial.ViewModels;

namespace BridgeReactTutorial.Components
{
  public class MessageHistory : StatelessComponent&amp;lt;MessageHistory.Props&amp;gt;
  {
    public MessageHistory(Props props) : base(props) { }

    public override ReactElement Render()
    {
      var className = props.ClassName;
      if (!props.Messages.Any())
        className = (className + &quot; zero-messages&quot;).Trim();

      // Any time a set of child components is dynamically-created (meaning that the
      // numbers of items may vary from one render to another), each must have a unique
      // &quot;Key&quot; property set (this may be a int or a string). Here, this is simple as
      // each message tuple is a unique ID and the contents of that message.
      var messageElements = props.Messages
        .Select(idAndMessage =&amp;gt; DOM.Div(new Attributes { Key = idAndMessage.Item1 },
        DOM.Span(new Attributes { ClassName = &quot;title&quot; }, idAndMessage.Item2.Title),
        DOM.Span(new Attributes { ClassName = &quot;content&quot; }, idAndMessage.Item2.Content)
      ));

      // When child components are specified (as they are through the second argument of
      // DOM.Div), the argument is of type Any&amp;lt;ReactElement, string&amp;gt;[] (meaning that each
      // element may be another component or it may be a simple text value)
      // - The React bindings have an extension method that transforms an IEnumerable set
      //   of components (such as &quot;messageElements&quot;) into an Any&amp;lt;ReactElement, string&amp;gt;[]
      return DOM.FieldSet(new FieldSetAttributes { ClassName = className },
        DOM.Legend(null, &quot;Message History&quot;),
        DOM.Div(null, messageElements.ToChildComponentArray())
      );
    }

    public class Props
    {
      public string ClassName;
      public IEnumerable&amp;lt;Tuple&amp;lt;int, MessageDetails&amp;gt;&amp;gt; Messages;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Despite this appearing very simple at first glance, there are various implicit assumptions that you should be aware of. Firstly, it is assumed that &quot;props&quot; will never be null (&quot;Render&quot; will throw an exception if this is not the case). It is also assumed that &quot;props.ClassName&quot; &lt;em&gt;may&lt;/em&gt; be null (and, technically, it may also be a blank string, though this is not desirable) while &quot;props.Messages&quot; should &lt;em&gt;not&lt;/em&gt; null. Nor should &quot;props.Messages&quot; contain any tuples with a null &lt;strong&gt;MessageDetails&lt;/strong&gt; instance. But these assumptions are neither documented nor enforced.&lt;/p&gt;

&lt;p&gt;By this point, we&#39;ve seen several examples of how to prevent &quot;props&quot; being null (ie. require that the props constructor arguments be passed as the component&#39;s constructor arguments) and we&#39;ve seen how to better represent &lt;strong&gt;Props&lt;/strong&gt; to allow &quot;ClassName&quot; to be optional but for &quot;Messages&quot; to not be (&quot;ClassName&quot; should be an &lt;strong&gt;Optional&amp;lt;NonBlankTrimmedString&amp;gt;&lt;/strong&gt;). But there are two further tricks we can use for the &lt;strong&gt;MessageHistory.Props&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Firstly, &lt;strong&gt;IEnumerable&lt;/strong&gt; is too loose for my liking - technically, there are no guarantees that an &lt;strong&gt;IEnumerable&lt;/strong&gt; will report the same information if enumerated multiple times and there are definitely no guarantees that it won&#39;t contain any null references. I want consistency and I want a life free from null. The &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt; library contains another handy class for this sort of thing; &lt;strong&gt;Set&amp;lt;T&amp;gt;&lt;/strong&gt;. This is essentially an ordered list of items of type &quot;T&quot; that is immutable and that will never contain any null values. If you want a set of items that may or may not have values of type &quot;T&quot; then you need the list type to be &lt;strong&gt;Set&amp;lt;Optional&amp;lt;T&amp;gt;&amp;gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(I will confess that this may not be the most-well-named of all classes, since some mathematical circles like a &quot;Set&quot; to be a group of unique items that are likely not ordered.. but I wanted a convenient short name and &lt;strong&gt;List&amp;lt;T&amp;gt;&lt;/strong&gt; already has a well-understood definition - &lt;strong&gt;NonNullImmutableList&amp;lt;T&amp;gt;&lt;/strong&gt; was in the running, but I ideally wanted something shorter).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The second tweak that I want to make is to replace the &lt;strong&gt;Tuple&amp;lt;int, MessageDetails&amp;gt;&lt;/strong&gt; - in part, again, because there is no guarantee that the second item in the pair will not be null but also because I don&#39;t like the &quot;Item1&quot; and &quot;Item2&quot; property names. I think it&#39;s just one more thing to mentally translate (&quot;Oh yes, Item1 means Key and Item2 means Message&quot;). So I&#39;m going to extend the type system again.&lt;/p&gt;

&lt;p&gt;When considering a simple API, the common actions are &quot;Create&quot;, &quot;Read&quot;, &quot;Update&quot;, &quot;Delete&quot;. When creating a new item (like when we save a new message in our example application), we don&#39;t have a unique key for the new message - that will be generated by the persistence layer as part of the save process. When we read values (to display existing messages in the &lt;strong&gt;MessageHistory&lt;/strong&gt;, for example), we &lt;em&gt;will&lt;/em&gt; have access to unique keys - the persistence layer will be reading data from wherever the data is stored and it will be able to draw the keys out along with the data. When updating an existing record, we should know what its key is, since we will have performed a read action in order to get the currently-persisted state for the record. Similarly, when requesting a delete, we will have the key from a previous read action, in order to know what record to remove.&lt;/p&gt;

&lt;p&gt;I&#39;ve seen object models before which try to have a single data type to use in all of the Create, Read and Update cases. This would be like our &lt;strong&gt;MessageDetails&lt;/strong&gt; having a &quot;Key&quot;, &quot;Title&quot; and &quot;Content&quot;. However, sometimes the &quot;Key&quot; would be null because it would be unknown (when generating a brand new &lt;strong&gt;MessageDetails&lt;/strong&gt; instance to pass to &quot;SaveMessage&quot;, for example). I don&#39;t like this. The sometimes-Key-is-null-and-sometimes-it-isn&#39;t is an unnecessary complication and it means that there are places where we require a Key but can&#39;t guarantee (through the type system) that the reference that we have will have a non-null Key value. I think it&#39;s much better to have &lt;em&gt;two&lt;/em&gt; data types; one for a record that has been persisted at some point (and thus has a non-null Key) and another type for a record that may or may not have been persisted. Currently, our &lt;strong&gt;MessageDetails&lt;/strong&gt; class (which has only &quot;Title&quot; and &quot;Content&quot; properties) represents a message that may or may not have been persisted - when a new one is passed to &quot;SaveMessage&quot; when the user attempts to save a new message then we know that it hasn&#39;t been persisted yet, but it&#39;s not difficult to imagine that there could be other code that we add to the application in the future that wants to deal with some message data, but that doesn&#39;t care whether it&#39;s been persisted or not yet; it only wants access to its &quot;Title&quot; and / or &quot;Content&quot; values, it doesn&#39;t need the &quot;Key&quot; for anything.&lt;/p&gt;

&lt;p&gt;So, instead of the &lt;strong&gt;MessageHistory&lt;/strong&gt; using the generic &lt;strong&gt;Tuple&lt;/strong&gt; class to represent a &lt;strong&gt;MessageDetails&lt;/strong&gt;-plus-persisted-Key, I&#39;m going to introduce something new. Create a new file under the &quot;API&quot; folder, &quot;Saved.cs&quot; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using ProductiveRage.Immutable;

namespace BridgeReactTutorial.API
{
  public class Saved&amp;lt;TKey, TValue&amp;gt; : IAmImmutable
  {
    public Saved(TKey key, TValue value)
    {
      this.CtorSet(_ =&amp;gt; _.Key, key);
      this.CtorSet(_ =&amp;gt; _.Value, value);
    }
    public TKey Key { get; private set; }
    public TValue Value { get; private set; }
  }

  public static class Saved
  {
    /// &amp;lt;summary&amp;gt;
    /// This generic method makes code that creates generic Saved instances more succinct
    /// by relying upon type inference (based upon the key and value argument types), so
    /// that the calling code does not have to explicitly declare TKey and TValue
    /// &amp;lt;/summary&amp;gt;
    public static Saved&amp;lt;TKey, TValue&amp;gt; For&amp;lt;TKey, TValue&amp;gt;(TKey key, TValue value)
    {
      return new Saved&amp;lt;TKey, TValue&amp;gt;(key, value);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;strong&gt;Saved&lt;/strong&gt; class makes differentiating between record-that-has-a-persistence-id and record-that-may-or-may-not-have-a-persistence-id simple. If the message has been persisted, then it may be represented as a &lt;strong&gt;Saved&amp;lt;int, MessageDetails&amp;gt;&lt;/strong&gt;. If it&#39;s &lt;em&gt;just&lt;/em&gt; the message data, with no persisted-or-not-persisted state associated with it then it will be simply a &lt;strong&gt;MessageDetails&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I&#39;m &lt;em&gt;still&lt;/em&gt; not happy, though. I think that &lt;strong&gt;Saved&amp;lt;int, MessageDetails&amp;gt;&lt;/strong&gt; could still be more descriptive. This value represents a message with a unique persistence key for that message. Even if the underlying data store is a database which uses an integer column (in our example app, it&#39;s a simple in-browser-memory store, but a database on a server is likely much more common) that doesn&#39;t mean that we have to use such a vague term as &quot;an integer&quot; in our application&#39;s object model. I recommend strongly-typed ID representations. We need to add a new file &quot;MessageId.cs&quot; to the &quot;API&quot; folder:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespace BridgeReactTutorial.API
{
  public struct MessageId
  {
    public int Value { get; private set; }

    public static explicit operator MessageId(int value)
    {
      return new MessageId { Value = value };
    }

    public static implicit operator int(MessageId id)
    {
      return id.Value;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the final step in the move away from &lt;strong&gt;IEnumerable&amp;lt;Tuple&amp;lt;int, MessageDetails&amp;gt;&amp;gt;&lt;/strong&gt;, we will now represent this data with the type &lt;strong&gt;Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;&lt;/strong&gt;. This set will never contain any null &quot;Saved&quot; instances and a &quot;Saved&quot; instance will never contain a null message. This set of messages will never vary, which is another way that React&#39;s &quot;consider props to be immutable&quot; guidelines is described and enforced in the type system.&lt;/p&gt;

&lt;p&gt;Not only do I believe that having strongly-typed IDs makes the code clearer in cases like this but it can also avoid silly mistakes that have a nasty tendency to crop up from time to time - if you&#39;re writing code and having a bad day, then it&#39;s easy to accidentally pass the wrong ID around. For example, if I have a function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void RecordMessageAsHavingBeenReadBy(int messageId, int userId)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then it&#39;s possible in the calling code to mix up the IDs if you&#39;re having a bad day (this isn&#39;t &lt;em&gt;too&lt;/em&gt; contrived an example, I &lt;em&gt;have&lt;/em&gt; done something like this in the past!) - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RecordMessageAsHavingBeenReadBy(user.Id, message.id); // Whoops!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the IDs were strongly-typed, meaning that the method signature would be..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void RecordMessageAsHavingBeenReadBy3(MessageId messageId, UserId userId)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then that mishap would result in a compile error, rather than runtime confusion that may not get noticed immediately.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Note: These changes to how messages are represented will require changes to the &lt;strong&gt;MesageApi&lt;/strong&gt;, which I&#39;ll cover shortly - nothing very complicated, though).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;These changes lead the &lt;strong&gt;MessageHistory&lt;/strong&gt; component&#39;s code to now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Linq;
using Bridge.React;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class MessageHistory : StatelessComponent&amp;lt;MessageHistory.Props&amp;gt;
  {
    public MessageHistory(
      Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; messages,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, messages)) { }

    public override ReactElement Render()
    {
      var className = props.ClassName;
      if (!props.Messages.Any())
        className = className.Add(&quot; &quot;, new NonBlankTrimmedString(&quot;zero-messages&quot;));

      // Any time a set of child components is dynamically-created (meaning that the
      // numbers of items may vary from one render to another), each must have a unique
      // &quot;Key&quot; property set (this may be a int or a string)
      var messageElements = props.Messages
        .Select(savedMessage =&amp;gt; DOM.Div(new Attributes { Key = (int)savedMessage.Key },
        DOM.Span(new Attributes { ClassName = &quot;title&quot; }, savedMessage.Value.Title),
        DOM.Span(new Attributes { ClassName = &quot;content&quot; }, savedMessage.Value.Content)
        ));

      // When child components are specified (as they are through the second argument of
      // DOM.Div), the argument is of type Any&amp;lt;ReactElement, string&amp;gt;[] (meaning that each
      // element may be another component or it may be a simple text value)
      // - The React bindings have an extension method that transforms an IEnumerable set
      //   of components (such as &quot;messageElements&quot;) into an Any&amp;lt;ReactElement, string&amp;gt;[]
      return DOM.FieldSet(
        new FieldSetAttributes { ClassName = className.ToStringIfDefined() },
        DOM.Legend(null, &quot;Message History&quot;),
        DOM.Div(null, messageElements.ToChildComponentArray())
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; messages)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Messages, messages);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; Messages { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of those implicit assumptions are now explicitly described in the type system. This makes me feel much better. &lt;/p&gt;

&lt;h3&gt;So, EVERYWHERE?&lt;/h3&gt;

&lt;p&gt;I introduced the use of &lt;strong&gt;IAmImmutable&lt;/strong&gt; in terms of a component&#39;s &lt;strong&gt;Props&lt;/strong&gt; class. But I subsequently used it to tighten up the &lt;strong&gt;MessageDetails&lt;/strong&gt; class and then again when the &lt;strong&gt;Saved&lt;/strong&gt; class was added.&lt;/p&gt;

&lt;p&gt;One option in incorporating &lt;strong&gt;IAmImmutable&lt;/strong&gt; and this no-value-or-property-may-be-null behaviour into applications would be to say that any class that implements &lt;strong&gt;IAmImmutable&lt;/strong&gt; will not allow null anywhere. As I&#39;ve already hinted, I strongly suggest going further than that, however, and writing &lt;em&gt;all&lt;/em&gt; code like this. Frankly, I can see no good reason why any public data type should be mutable. I can imagine that, in some special cases, it may be desirable to have some private mutable data structures for convenience, or &lt;em&gt;maybe&lt;/em&gt; performance (in some &lt;em&gt;very&lt;/em&gt; specialised cases) but where the data is shared with other classes, data types being immutable makes the code much easier to reason about. Transformations are explicit and do not occur &quot;in place&quot; for any references. Meaning that a reference that describes some data when a function starts will always describe the same data when the function ends.&lt;/p&gt;

&lt;p&gt;It&#39;s actually worth remembering that JavaScript in the browser is single-threaded. A lot of the time that people talk about the benefits of immutability, they talk about the safety of being able to share references between multiple threads and not having to worry about corruption because one thread can&#39;t manipulate data in a way that another thread doesn&#39;t expect, with unfortunate (and often non-deterministic) results. Here, we are not concerned about multi-threading, I recommend the use of immutable structures solely because they make the code that accesses them and passes them around easier to reason about.&lt;/p&gt;

&lt;p&gt;The largest downside in my eyes, as may have struck you after reading all of the above, is that changing code that doesn&#39;t use &lt;strong&gt;IAmImmutable&lt;/strong&gt; into code that &lt;em&gt;does&lt;/em&gt; use it requires changes not only to that particular class but, in many cases, to code that accesses or initialises that class and then to code that accesses or initialises &lt;em&gt;that&lt;/em&gt; code (the changes to the &lt;strong&gt;MessageEditor&lt;/strong&gt; and &lt;strong&gt;MessageHistory&lt;/strong&gt; components required changes to the &lt;strong&gt;MessageDetails&lt;/strong&gt; and &lt;strong&gt;MessageEditState&lt;/strong&gt; classes and still require more changes to the &lt;strong&gt;AppContainer&lt;/strong&gt;, the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; and the &lt;strong&gt;MessageApi&lt;/strong&gt;). It&#39;s much better to bake this in from the start. The big benefit is that, if you do so, you&#39;ll rarely have to worry about &quot;could this value be null&quot;* and &quot;could this data be changed if I pass it into another function&quot;.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(There will still be some places where you have to be alert about potential nulls, but these should largely arise from interacting with other libraries - the &quot;ToStringIfDefined&quot; extension method we saw earlier is an example of a place where nulls may be returned, but it is clearly documented as such and the return value is only intended to be passed to a React element factory method).&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Filling in more gaps&lt;/h3&gt;

&lt;p&gt;If you&#39;ve been following along and creating your own project with the code in this series, you will be all too aware that it doesn&#39;t build at the moment. Let&#39;s go through and fix everything up. Much of the required alterations will be similar to what is presented above, but there are a few other tips and tricks to consider along the way.&lt;/p&gt;

&lt;p&gt;Let&#39;s start with the &lt;strong&gt;AppContainer&lt;/strong&gt;. Last we saw it, it looked like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.ViewModels;
using BridgeReactTutorial.Stores;
using BridgeReactTutorial.API;

namespace BridgeReactTutorial.Components
{
  public class AppContainer : Component&amp;lt;AppContainer.Props, AppContainer.State&amp;gt;
  {
    public AppContainer(AppContainer.Props props) : base(props) { }

    protected override void ComponentDidMount()
    {
      props.Store.Change += StoreChanged;
    }
    protected override void ComponentWillUnmount()
    {
      props.Store.Change -= StoreChanged;
    }
    private void StoreChanged()
    {
      SetState(new State
      {
        Message = props.Store.Message,
        MessageHistory = props.Store.MessageHistory
      });
    }

    public override ReactElement Render()
    {
      if (state == null)
        return null;

      return DOM.Div(null,
        new MessageEditor(
          className: new NonBlankTrimmedString(&quot;message&quot;),
          message:  state.Message,
          onChange: newState =&amp;gt; props.Dispatcher.HandleViewAction(
            UserEditRequested.For(newState)
          ),
          onSave: () =&amp;gt; props.Dispatcher.HandleViewAction(
            SaveRequested.For(
              new MessageDetails(
                new NonBlankTrimmedString(state.Message.Title.Text),
                new NonBlankTrimmedString(state.Message.Content.Text)
              )
            )
          )
        ),
        new MessageHistory(new MessageHistory.Props
        {
          ClassName = &quot;history&quot;,
          Messages = state.MessageHistory
        })
      );
    }

    public class Props
    {
      public AppDispatcher Dispatcher;
      public MessageWriterStore Store;
    }

    public class State
    {
      public MessageEditState Message;
      public IEnumerable&amp;lt;Tuple&amp;lt;int, MessageDetails&amp;gt;&amp;gt; MessageHistory;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&#39;s nice and simple since we moved nearly all of the logic that it contained in &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-from-first-principles&quot;&gt;Part One&lt;/a&gt; into the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; in &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-two&quot;&gt;Part Two&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The obvious thing to do, based on what I&#39;ve been talking about today, is to change its &lt;strong&gt;Props&lt;/strong&gt; and &lt;strong&gt;State&lt;/strong&gt; classes to implement &lt;strong&gt;IAmImmutable&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;After that, there is one difference between this component and the other components we&#39;ve already looked at - this is stateful and they were state-&lt;em&gt;less&lt;/em&gt;. That means that they only had &quot;props&quot; to think about, while the &lt;strong&gt;AppContainer&lt;/strong&gt; has both &quot;props&quot; and &quot;state&quot;. As with the stateless components, it is presumed that the &quot;props&quot; reference may never be null. This can be enforced by using the same trick as we did for the others - mirror the &lt;strong&gt;Props&lt;/strong&gt; constructor arguments in the &lt;strong&gt;AppContainer&lt;/strong&gt;&#39;s constructor arguments and generate a &lt;strong&gt;Props&lt;/strong&gt; instance from them. However, the &quot;state&quot; reference &lt;em&gt;may&lt;/em&gt; be null some times, as can be seen at the very start of the &quot;Render&quot; method. This means that the &quot;state&quot; type should be &lt;strong&gt;Optional&amp;lt;State&amp;gt;&lt;/strong&gt;, rather than just &lt;strong&gt;State&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;These changes result in this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.API;
using BridgeReactTutorial.Stores;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class AppContainer : Component&amp;lt;AppContainer.Props, Optional&amp;lt;AppContainer.State&amp;gt;&amp;gt;
  {
    public AppContainer(AppDispatcher dispatcher, MessageWriterStore store)
      : base(new Props(dispatcher, store)) { }

    protected override void ComponentDidMount()
    {
      props.Store.Change += StoreChanged;
    }
    protected override void ComponentWillUnmount()
    {
      props.Store.Change -= StoreChanged;
    }
    private void StoreChanged()
    {
      SetState(new State(
        message: props.Store.Message,
        messageHistory: props.Store.MessageHistory
      ));
    }

    public override ReactElement Render()
    {
      if (!state.IsDefined)
        return null;

      return DOM.Div(null,
        new MessageEditor(
          className: new NonBlankTrimmedString(&quot;message&quot;),
          message:  state.Value.Message,
          onChange: newState =&amp;gt; props.Dispatcher.HandleViewAction(
            UserEditRequested.For(newState)
          ),
          onSave: () =&amp;gt; props.Dispatcher.HandleViewAction(
            SaveRequested.For(
              new MessageDetails(
                new NonBlankTrimmedString(state.Value.Message.Title.Text),
                new NonBlankTrimmedString(state.Value.Message.Content.Text)
              )
            )
          )
        ),
        new MessageHistory(
          className: new NonBlankTrimmedString(&quot;history&quot;),
          messages: state.Value.MessageHistory
        )
      );
    }

    public class Props : IAmImmutable
    {
      public Props(AppDispatcher dispatcher, MessageWriterStore store)
      {
        this.CtorSet(_ =&amp;gt; _.Dispatcher, dispatcher);
        this.CtorSet(_ =&amp;gt; _.Store, store);
      }
      public AppDispatcher Dispatcher { get; private set; }
      public MessageWriterStore Store { get; private set; }
    }

    public class State : IAmImmutable
    {
      public State(
        MessageEditState message,
        Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; messageHistory)
      {
        this.CtorSet(_ =&amp;gt; _.Message, message);
        this.CtorSet(_ =&amp;gt; _.MessageHistory, messageHistory);
      }
      public MessageEditState Message { get; private set; }
      public Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; MessageHistory { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That transformation should have felt quite run-of-the-mill and predictable by this point - seen one component-tightening-up, seen them all. Let&#39;s move on to the &lt;strong&gt;MessageWriterStore&lt;/strong&gt;. This is what deals with the events from the application, both from user-initiated events from DOM elements and from new-messages-data-available events from the &lt;strong&gt;MessageApi&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;At the bare minimum, it will need some changes since it was written when the &lt;strong&gt;MessageEditState&lt;/strong&gt; type was mutable and so the &quot;ValidateMessage&quot; method was able to mutate it (such as setting or clearing validation warning messages) in-place. I&#39;ve moved away from that so that mutations are &lt;em&gt;always&lt;/em&gt; explicit - there will no longer be a method that may or may not mutate a reference, if a method needs to set values on something then it will take the initial reference as an input and return a new one as its return value. But there are more of those sneaky &quot;implicit assumptions&quot; tucked away in the store that we should address. In the last post, we left it implemented like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;

namespace BridgeReactTutorial.Stores
{
  public class MessageWriterStore
  {
    private RequestId _saveActionRequestId, _lastDataUpdatedRequestId;
    public MessageWriterStore(IReadAndWriteMessages messageApi, AppDispatcher dispatcher)
    {
      if (messageApi == null)
        throw new ArgumentNullException(&quot;messageApi&quot;);
      if (dispatcher == null)
        throw new ArgumentNullException(&quot;dispatcher&quot;);

      Message = GetInitialMessageEditState();
      MessageHistory = new Tuple&amp;lt;int, MessageDetails&amp;gt;[0];

      dispatcher.Register(message =&amp;gt;
      {
        message
          .If&amp;lt;StoreInitialised&amp;gt;(
            condition: action =&amp;gt; (action.Store == this),
            work: action =&amp;gt; { }
          )
          .Else&amp;lt;MessageEditStateChanged&amp;gt;(action =&amp;gt;
          {
            Message = action.NewState;
            ValidateMessage(Message);
          })
          .Else&amp;lt;MessageSaveRequested&amp;gt;(action =&amp;gt;
          {
            _saveActionRequestId = messageApi.SaveMessage(action.Message);
            Message.IsSaveInProgress = true;
          })
          .Else&amp;lt;MessageSaveSucceeded&amp;gt;(
            condition: action =&amp;gt; (action.RequestId == _saveActionRequestId),
            work: action =&amp;gt;
            {
              _saveActionRequestId = null;
              Message = GetInitialMessageEditState();
              _lastDataUpdatedRequestId = messageApi.GetMessages();
            }
          )
          .Else&amp;lt;MessageHistoryUpdated&amp;gt;(
            condition: action =&amp;gt;
              action.RequestId.IsEqualToOrComesAfter(_lastDataUpdatedRequestId),
            work: action =&amp;gt;
            {
              _lastDataUpdatedRequestId = action.RequestId;
              MessageHistory = action.Messages;
            }
          )
          .IfAnyMatched(OnChange);
      });
    }

    public event Action Change;
    public MessageEditState Message;
    public IEnumerable&amp;lt;Tuple&amp;lt;int, MessageDetails&amp;gt;&amp;gt; MessageHistory;

    private MessageEditState GetInitialMessageEditState()
    {
      // Note: By using the ValidateMessage here, we don&#39;t need to duplicate the &quot;Untitled&quot;
      // string that should be used for the Caption value when the UI is first rendered
      // or when the user has entered some Title content but then deleted it again.
      // Similarly, we avoid having to repeat the validation messages that should be
      // displayed when the form is empty, since they will be set by ValidateMessage.
      var blankMessage = new MessageEditState
      {
        Caption = &quot;&quot;,
        Title = new TextEditState { Text = &quot;&quot; },
        Content = new TextEditState { Text = &quot;&quot; },
        IsSaveInProgress = false
      };
      ValidateMessage(blankMessage);
      return blankMessage;
    }

    private void ValidateMessage(MessageEditState message)
    {
      if (message == null)
        throw new ArgumentNullException(&quot;message&quot;);

      message.Caption = string.IsNullOrWhiteSpace(message.Title.Text)
        ? &quot;Untitled&quot;
        : message.Title.Text.Trim();
      message.Title.ValidationError = string.IsNullOrWhiteSpace(message.Title.Text)
        ? &quot;Must enter a title&quot;
        : null;
      message.Content.ValidationError = string.IsNullOrWhiteSpace(message.Content.Text)
        ? &quot;Must enter message content&quot;
        : null;
    }

    private void OnChange()
    {
      if (Change != null)
        Change();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three things jump out at me here. Firstly, the &quot;&lt;em&gt;saveActionRequestId&quot; and &quot;&lt;/em&gt;lastDataUpdatedRequestId&quot; references may not always be populated. If there is no save action in progress that we&#39;re waiting to complete, for example, then &quot;_saveActionRequestId&quot; won&#39;t have a value. Let&#39;s explicitly describe this in the type system by changing the type of these two values from &lt;strong&gt;RequestId&lt;/strong&gt; to &lt;strong&gt;Optional&amp;lt;RequestId&amp;gt;&lt;/strong&gt; (even though these values aren&#39;t part of a public API of the store class, there&#39;s still a benefit to indicating what may and may not have a value, for the sake of code clarity).&lt;/p&gt;

&lt;p&gt;The second thing is that the &quot;Message&quot; and &quot;MessageHistory&quot; properties are only intended to be written to internally. They are available for reading by other classes (like the &lt;strong&gt;AppContainer&lt;/strong&gt; component), but not for updating by other classes. It makes sense to change these from being public fields to being properties with public getters and private setters. This wasn&#39;t done originally because I wanted to start from the simplest possible implementations and only stray from that when there was a clear benefit. Today, we&#39;re dealing with the clear benefit of increased code clarity through the reduction of implicit assumptions. Moving to private-setter properties allows the compiler to enforce what was only &lt;em&gt;presumed&lt;/em&gt; to be true before (instead of working on the assumption that no-one would try to update these references, now we can sleep safe that no-one other than the &lt;strong&gt;MessageWriteStore&lt;/strong&gt; itself &lt;em&gt;can&lt;/em&gt; change the references).&lt;/p&gt;

&lt;p&gt;The third thing is that &quot;Change&quot; is an event and so may be null if no-one has subscribed to it. That&#39;s just the way that events work in C#. We could either come up with a new way to represent events or we could accept that a null check is required (and that we can&#39;t use an &lt;strong&gt;Optional&lt;/strong&gt; type to represent it). I think that the pragmatic thing to do is to just accept it - this is basically how events have worked in C# from day one and I don&#39;t think that there would be any improvement to code clarity by trying to shy away from this accepted practice.&lt;/p&gt;

&lt;p&gt;What is really going to be the most interesting part in updating the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; is, I think, how we change the validation / &lt;strong&gt;MessageEditState&lt;/strong&gt;-mutating code -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  message.Caption = string.IsNullOrWhiteSpace(message.Title.Text)
    ? &quot;Untitled&quot;
    : message.Title.Text.Trim();
  message.Title.ValidationError = string.IsNullOrWhiteSpace(message.Title.Text)
    ? &quot;Must enter a title&quot;
    : null;
  message.Content.ValidationError = string.IsNullOrWhiteSpace(message.Content.Text)
    ? &quot;Must enter message content&quot;
    : null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Probably the absolute simplest thing that we could do would be to rewrite it like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private MessageEditState ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  if (string.IsNullOrWhiteSpace(message.Title.Text))
    message = message.With(_ =&amp;gt; _.Caption, new NonBlankTrimmedString(&quot;Untitled&quot;));
  else
    message = message.With(_ =&amp;gt; _.Caption, new NonBlankTrimmedString(message.Title.Text));

  if (string.IsNullOrWhiteSpace(message.Title.Text))
    message = message.With(_ =&amp;gt; _.Title, SetValidationMessage(message.Title, new NonBlankTrimmedString(&quot;Must enter a title&quot;)));
  else
    message = message.With(_ =&amp;gt; _.Title, SetValidationMessage(message.Title, null));

  if (string.IsNullOrWhiteSpace(message.Content.Text))
    message = message.With(_ =&amp;gt; _.Content, SetValidationMessage(message.Content, new NonBlankTrimmedString(&quot;Must enter message content&quot;)));
  else
    message = message.With(_ =&amp;gt; _.Content, SetValidationMessage(message.Content, null));

  return message;
}

private TextEditState SetValidationMessage(
  TextEditState textEditState,
  Optional&amp;lt;NonBlankTrimmedString&amp;gt; message)
{
  if (textEditState == null)
    throw new ArgumentNullException(&quot;textEditState&quot;);

  return textEditState.With(_ =&amp;gt; _.ValidationError, message);
}   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That is.. more verbose, I think would be a polite way to describe it. I would normally have wrapped some of the lines in order to fit the horizontal scrolling budget I allow on code samples on my blog but I wanted to give this arrangement the best change at looking succint that it could. And it&#39;s still not looking very good.&lt;/p&gt;

&lt;p&gt;What&#39;s much worse, though, is that I don&#39;t think that this code is very easy to read. I think that there&#39;s quite a lot of noise that masks the actual intent. It&#39;s not complicated, by a long shot, but I think that the actual logic that it&#39;s trying to apply is drowning a little bit in all the code that&#39;s required. The verbosity itself, is not the biggest problem for me - I will take code that is slightly longer if it&#39;s clearer (I&#39;m not just talking about descriptive variable and method names and I&#39;m don&#39;t mean avoiding compact &quot;clever&quot; code, I mean like the changes from mutable classes to &lt;strong&gt;IAmImmutable&lt;/strong&gt; implementations; they are more verbose but they are much more expressive).&lt;/p&gt;

&lt;p&gt;One alternative would be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private MessageEditState ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  var caption = string.IsNullOrWhiteSpace(message.Title.Text)
    ? new NonBlankTrimmedString(&quot;Untitled&quot;)
    : new NonBlankTrimmedString(message.Title.Text);
  var titleEditState = string.IsNullOrWhiteSpace(message.Title.Text)
    ? SetValidationMessage(message.Title, new NonBlankTrimmedString(&quot;Must enter a title&quot;))
    : null;
  var contentEditState = string.IsNullOrWhiteSpace(message.Content.Text)
    ? SetValidationMessage(message.Content, new NonBlankTrimmedString(&quot;Must enter message content&quot;))
    : null;

  return message
    .With(_ =&amp;gt; _.Caption, caption)
    .With(_ =&amp;gt; _.Title, titleEditState)
    .With(_ =&amp;gt; _.Content, contentEditState);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is much improved. The code &lt;em&gt;looks&lt;/em&gt; cleaner at a glance and, crucially, it&#39;s much clearer in its intent.&lt;/p&gt;

&lt;p&gt;However.. the way that we&#39;ve reduced the syntactic noise is by separating the &quot;what should the new values be&quot; from the &quot;set these new values&quot;. This isn&#39;t too bad with only three properties, but if the object being validated was more complex then the new-value-determining code would drift further from the new-value-setting code, which would be a pity since they are intrinsicially linked concepts (and it would be nice - meaning that the code should be easier to understand at a glance - if the two types of code were linked again for each property, with each new-value-determiner being present alongside the new-value-setter).&lt;/p&gt;

&lt;p&gt;Instead of splitting the code up for clarity, we can try to make it clearer by using abstractions.&lt;/p&gt;

&lt;p&gt;Let&#39;s start by introducing a method to abstract the setting-or-removing of validation messages from &lt;strong&gt;TextEditState&lt;/strong&gt; instances -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private TextEditState Validate(
  TextEditState textEditState,
  Predicate&amp;lt;TextEditState&amp;gt; validIf,
  NonBlankTrimmedString messageIfInvalid)
{
  if (textEditState == null)
    throw new ArgumentNullException(&quot;textEditState&quot;);
  if (validIf == null)
    throw new ArgumentNullException(&quot;validIf&quot;);
  if (messageIfInvalid == null)
    throw new ArgumentNullException(&quot;messageIfInvalid&quot;);

  return textEditState.With(_ =&amp;gt; _.ValidationError, validIf(textEditState)
    ? null
    : messageIfInvalid);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will take a &lt;strong&gt;TextEditState&lt;/strong&gt;, a rule that determines whether or not its &quot;Text&quot; value should be considered valid and a message to set if the value is &lt;em&gt;not&lt;/em&gt; valid (if it &lt;em&gt;is&lt;/em&gt; valid then the message will be cleared).&lt;/p&gt;

&lt;p&gt;This would allow us to set (or remove) the validation message on the &quot;Title&quot; property with code such as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message = message.With(
  _ =&amp;gt; _.Title,
  Validate(
    message.Title,
    textEditState =&amp;gt; string.IsNullOrWhiteSpace(textEditState.Text),
    new NonBlankTrimmedString(&quot;Must enter a title&quot;)
  )
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since the validation logic for both &quot;Title&quot; and &quot;Content&quot; is the same and &quot;textEditState =&gt; string.IsNullOrWhiteSpace(textEditState.Text)&quot; is quite long and going to be responsible for a lot of the &quot;syntactic noise&quot; that I want to avoid, this could also be abstracted by defining another method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private bool MustHaveValue(TextEditState textEditState)
{
  if (textEditState == null)
    throw new ArgumentNullException(&quot;textEditState&quot;);

  return !string.IsNullOrWhiteSpace(textEditState.Text);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we also move the constant messages (the two validation warnings and the &quot;Untitled&quot; caption string) into static class members -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private readonly static NonBlankTrimmedString _defaultCaption
  = new NonBlankTrimmedString(&quot;Untitled&quot;);

private readonly static NonBlankTrimmedString _noTitleWarning
  = new NonBlankTrimmedString(&quot;Must enter a title&quot;);

private readonly static NonBlankTrimmedString _noContentWarning
  = new NonBlankTrimmedString(&quot;Must enter message content&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then we can make the &quot;Title&quot; validation-message-setting/unsetting much clearer:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message = message
  .With(_ =&amp;gt; _.Title, Validate(message.Title, MustHaveValue, _noTitleWarning));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we add a final helper method to make the setting of the &quot;Caption&quot; property simpler -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private NonBlankTrimmedString ToNonBlankTrimmedString(
  TextEditState textEditState,
  NonBlankTrimmedString fallback)
{
  if (textEditState == null)
    throw new ArgumentNullException(&quot;textEditState&quot;);
  if (fallback == null)
    throw new ArgumentNullException(&quot;fallback&quot;);

  return (textEditState.Text.Trim() == &quot;&quot;)
    ? fallback
    : new NonBlankTrimmedString(textEditState.Text);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. then the &quot;ValidateMessage&quot; can be reduced to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private MessageEditState ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  return message
    .With(_ =&amp;gt; _.Caption, ToNonBlankTrimmedString(message.Title, fallback: _defaultCaption))
    .With(_ =&amp;gt; _.Title, Validate(message.Title, MustHaveValue, _noTitleWarning))
    .With(_ =&amp;gt; _.Content, Validate(message.Content, MustHaveValue, _noContentWarning));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I really think that we have the best of every world. The actual code in &quot;ValidateMessage&quot; is short and to the point. While there are more lines of code in total (when you also consider the &quot;ToNonBlankTrimmedString&quot;, &quot;Validate&quot; and &quot;MustHaveValue&quot; methods), each method is more focused and very easy to fully comprehend at a glance. This is the crux of the matter for me - these changes are all about (say it with, because I&#39;m sure that you know what&#39;s coming by this point): making code easier to reason about and hence easier to read, maintain and extend.&lt;/p&gt;

&lt;h3&gt;Sidebar: Pure functions&lt;/h3&gt;

&lt;p&gt;In the past, I&#39;ve had a tendency to interchange the words &quot;method&quot; and &quot;function&quot;. For the last year or so (and definitely in this series of posts, I hope!) I&#39;ve been more careful not to use &quot;function&quot; when I mean &quot;method&quot;. Having read around, it seems like the accepted difference between the two is (to quote an excellent example from a &lt;a href=&quot;http://stackoverflow.com/a/155655&quot;&gt;StackOverflow answer&lt;/a&gt;) -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A function is a piece of code that is called by name. It can be passed data to operate on (ie. the parameters) and can optionally return data (the return value).&lt;/p&gt;
  
  &lt;p&gt;All data that is passed to a function is explicitly passed.&lt;/p&gt;
  
  &lt;p&gt;A method is a piece of code that is called by name that is associated with an object. In most respects it is identical to a function except for two key differences.&lt;/p&gt;
  
  &lt;p&gt;It is implicitly passed the object on which it was called.
  It is able to operate on data that is contained within the class (remembering that an object is an instance of a class - the class is the definition, the object is an instance of that data).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That means that C# only has methods since every method is associated with an object. Even static methods are, technically, since they have access to anything else that is static within the type that declares the static method.&lt;/p&gt;

&lt;p&gt;A function will &lt;em&gt;only&lt;/em&gt; consider data passed explicitly in arguments, which is not a concept that is possible to represent with C#.&lt;/p&gt;

&lt;p&gt;The key difference, then, being that a function is absolutely guaranteed to always retun the same value given the same argument(s). Parallels are often drawn to mathematical functions. If you think about the need to &quot;calculate the square root of x&quot;, this is a good example of a function as it will always return the same result for any value of &quot;x&quot;. &quot;x&quot; is the &lt;em&gt;only&lt;/em&gt; thing that matters.&lt;/p&gt;

&lt;p&gt;With C#, you can get no such guarantees. Just to really drive the point home, here are three example - first, an instance method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Adder
{
  private readonly int _amountToIncrement;
  public Adder(int amountToIncrement)
  {
    _amountToIncrement = amountToIncrement;
  }

  public int AddTo(int value)
  {
    return value + _amountToIncrement;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obviously, the return value from &quot;AddTo&quot; depends on more than the argument passed in - it also depends upon the &quot;_amountToIncrement&quot; that the &lt;strong&gt;Adder&lt;/strong&gt; instance has.&lt;/p&gt;

&lt;p&gt;And a couple of static examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class Adder
{
  private static int _amountToIncrement = 0;

  public static int AddTo(int value)
  {
    _amountToIncrement++;
    return value + _amountToIncrement;
  }
}

public static class DayNameRetriever
{
  public static string GetDayNameForDateThisMonth(int date)
  {
    var today = DateTime.Now;
    var firstDayOfMonth = today.AddDays(-today.Day).AddDays(date);
    return firstDayOfMonth.ToString(&quot;dddd&quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Granted, theses examples are clearly contrived to illustrate a point and are not genuinely useful code. But they are also not totally unlike code that exists in the real world. The point is that, because C# only has methods, the mental burden in fully comprehending any method is increased because you have to be aware of anything else that the method might have access to.&lt;/p&gt;

&lt;p&gt;Which is a pity, because the &quot;ToNonBlankTrimmedString&quot;, &quot;Validate&quot; and &quot;MustHaveValue&quot; methods are perfect examples of genuine &lt;em&gt;functions&lt;/em&gt; - they &lt;em&gt;only&lt;/em&gt; operate on their arguments. The &quot;ValidateMessage&quot; only strays outside of its arguments to access the &quot;default caption&quot;, &quot;missing-title validation message&quot; and &quot;missing-content validation message&quot; values, but since there are effectively constants (since they are static readonly instances of immutable types) then &quot;ValidateMessage&quot; could also be considered to be a true function (in particular, we know that it will always return the same data given the same arguments).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Interestingly, there is a &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/system.diagnostics.contracts.pureattribute(v=vs.110).aspx&quot;&gt;[Pure]&lt;/a&gt; attribute in the .net framework, which is intended to indicate that a method is a &quot;pure function&quot; (where the phrase &quot;pure function&quot; is effectively consistent with the description of a &quot;function&quot; that I gave above). This seems like a nice idea, but it&#39;s not actually enforced by the compiler and so it&#39;s more of a suggestion, which greatly reduces my enthusiasm. The reason that I want to use immutable types to represent data that should not change (like React components&#39; props types) is that it encodes the &quot;this data is immutable&quot; information into the type system and results in any code that tries to break this requirement (by trying to set a value on an immutable type, for example) as being identified as an error by the compiler. The [Pure] attribute will, alas, not result in any compiler warnings or errors.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The closest that we can get to indicating that a method should be considered a &quot;function&quot;  is by making it static. As I showed above, this does &lt;em&gt;not&lt;/em&gt; mean that the method is truly &quot;pure&quot; (at least, there is no provision for the compiler to confirm that this is so) but making a function static does, at least, mean that it can not access any instance fields, properties or methods and so there is still less to consider when reading one of these methods. If you know that a method is static, then there is less mental burden in reading it since you know that there is less code that you need to consider that may possibly affect the current method.&lt;/p&gt;

&lt;p&gt;What I&#39;m trying to get at is that the &quot;ValidateMessage&quot;, &quot;ToNonBlankTrimmedString&quot;, &quot;Validate&quot; and &quot;MustHaveValue&quot; methods should all be made static and, to go further, it&#39;s worth writing &lt;em&gt;all&lt;/em&gt; methods as static unless you have a compelling reason not to. For a lot of methods, it&#39;s obvious that they have to be instance methods - the &quot;Render&quot; methods on the React component classes have to be instance methods, obviously, because they depend upon the &quot;props&quot; data for that component instance. But, in the final &lt;strong&gt;MessageWriterStore&lt;/strong&gt; implementation (see below), if we pull the &quot;OnChange&quot; method into a lambda then there is no need for &lt;em&gt;any&lt;/em&gt; of the methods to not be static.&lt;/p&gt;

&lt;p&gt;It seems, in general, that people write methods as instance methods by default and then make them static if they encounter a good reason to do so. I suggest that methods be written as static by default and only made into instance methods if there is a good reason to do so.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(To be honest, this is still something that I&#39;m trying to consistently apply to my own work - it&#39;s very easy to unconsciously write instance methods by default by omitting the &quot;static&quot; keyword; old habits die hard!)&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Collections.Generic;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Stores
{
  public class MessageWriterStore
  {
    private Optional&amp;lt;RequestId&amp;gt; _saveActionRequestId, _lastDataUpdatedRequestId;
    public MessageWriterStore(IReadAndWriteMessages messageApi, AppDispatcher dispatcher)
    {
      if (messageApi == null)
        throw new ArgumentNullException(&quot;messageApi&quot;);
      if (dispatcher == null)
        throw new ArgumentNullException(&quot;dispatcher&quot;);

      Message = GetInitialMessageEditState();
      MessageHistory = Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;.Empty;

      dispatcher.Register(message =&amp;gt;
      {
        message
          .If&amp;lt;StoreInitialised&amp;gt;(
            condition: action =&amp;gt; (action.Store == this),
            work: action =&amp;gt; { }
          )
          .Else&amp;lt;UserEditRequested&amp;lt;MessageEditState&amp;gt;&amp;gt;(action =&amp;gt;
            Message = ValidateMessage(action.NewState)
          )
          .Else&amp;lt;SaveRequested&amp;lt;MessageDetails&amp;gt;&amp;gt;(action =&amp;gt;
          {
            _saveActionRequestId = messageApi.SaveMessage(action.Data);
            Message = Message.With(_ =&amp;gt; _.IsSaveInProgress, true);
          })
          .Else&amp;lt;SaveSucceeded&amp;gt;(
            condition: action =&amp;gt; (action.RequestId == _saveActionRequestId),
            work: action =&amp;gt;
            {
              _saveActionRequestId = null;
              Message = GetInitialMessageEditState();
              _lastDataUpdatedRequestId = messageApi.GetMessages();
            }
          )
          .Else&amp;lt;DataUpdated&amp;lt;Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;&amp;gt;&amp;gt;(
            condition:
              action =&amp;gt; action.RequestId.IsEqualToOrComesAfter(_lastDataUpdatedRequestId),
            work: action =&amp;gt;
            {
              _lastDataUpdatedRequestId = action.RequestId;
              MessageHistory = action.Data;
            }
          )
          .IfAnyMatched(() =&amp;gt; { if (Change != null) Change(); });
      });
    }

    public event Action Change;
    public MessageEditState Message { get; private set; }
    public Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; MessageHistory { get; private set; }

    private readonly static NonBlankTrimmedString _defaultCaption
      = new NonBlankTrimmedString(&quot;Untitled&quot;);
    private readonly static NonBlankTrimmedString _noTitleWarning
      = new NonBlankTrimmedString(&quot;Must enter a title&quot;);
    private readonly static NonBlankTrimmedString _noContentWarning
      = new NonBlankTrimmedString(&quot;Must enter message content&quot;);

    private static MessageEditState GetInitialMessageEditState()
    {
      return new MessageEditState(
        caption: _defaultCaption,
        title: new TextEditState(&quot;&quot;, _noTitleWarning),
        content: new TextEditState(&quot;&quot;, _noContentWarning),
        isSaveInProgress: false
      );
    }

    private static MessageEditState ValidateMessage(MessageEditState message)
    {
      if (message == null)
        throw new ArgumentNullException(&quot;message&quot;);

      return message
        .With(_ =&amp;gt; _.Caption, ToNonBlankTrimmedString(message.Title, _defaultCaption))
        .With(_ =&amp;gt; _.Title, Validate(message.Title, MustHaveValue, _noTitleWarning))
        .With(_ =&amp;gt; _.Content, Validate(message.Content, MustHaveValue, _noContentWarning));
    }

    private static NonBlankTrimmedString ToNonBlankTrimmedString(
      TextEditState textEditState,
      NonBlankTrimmedString fallback)
    {
      if (textEditState == null)
        throw new ArgumentNullException(&quot;textEditState&quot;);
      if (fallback == null)
        throw new ArgumentNullException(&quot;fallback&quot;);

      return (textEditState.Text.Trim() == &quot;&quot;)
        ? fallback
        : new NonBlankTrimmedString(textEditState.Text);
    }

    private static TextEditState Validate(
      TextEditState textEditState,
      Predicate&amp;lt;TextEditState&amp;gt; validIf,
      NonBlankTrimmedString messageIfInvalid)
    {
      if (textEditState == null)
        throw new ArgumentNullException(&quot;textEditState&quot;);
      if (validIf == null)
        throw new ArgumentNullException(&quot;validIf&quot;);
      if (messageIfInvalid == null)
        throw new ArgumentNullException(&quot;messageIfInvalid&quot;);

      return textEditState.With(_ =&amp;gt; _.ValidationError, validIf(textEditState)
        ? null
        : messageIfInvalid);
    }

    private static bool MustHaveValue(TextEditState textEditState)
    {
      if (textEditState == null)
        throw new ArgumentNullException(&quot;textEditState&quot;);

      return !string.IsNullOrWhiteSpace(textEditState.Text);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that, since the &lt;strong&gt;RequestId&lt;/strong&gt; values are now &lt;strong&gt;Optional&amp;lt;RequestId&amp;gt;&lt;/strong&gt; instances, we need to change the &quot;IsEqualToOrComesAfter&quot; extension method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.API
{
  public static class RequestIdExtensions
  {
    public static bool IsEqualToOrComesAfter(
      this RequestId source,
      Optional&amp;lt;RequestId&amp;gt; other)
    {
      if (source == null)
        throw new ArgumentNullException(&quot;source&quot;);

      // If the &quot;other&quot; reference is no-RequestId then the &quot;source&quot; may be considered to
      // come after it
      if (!other.IsDefined)
        return true;

      return (source == other.Value) || source.ComesAfter(other.Value);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;The rest of the gaps&lt;/h3&gt;

&lt;p&gt;There&#39;s been a lot of theory covered so far. To really put it into practice, though, we need to fix the rest of the compile errors in the example application.&lt;/p&gt;

&lt;p&gt;Changing the &lt;strong&gt;MessageEditor&lt;/strong&gt;, &lt;strong&gt;MessageHistory&lt;/strong&gt;, &lt;strong&gt;AppContainer&lt;/strong&gt; and &lt;strong&gt;MessageWriteStore&lt;/strong&gt; to use the new immutable types (the now-immutable &lt;strong&gt;MessageDetails&lt;/strong&gt; and the &lt;strong&gt;Set&lt;/strong&gt; type from &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt;) require further changes to the &lt;strong&gt;MessageApi&lt;/strong&gt; and the &lt;strong&gt;App&lt;/strong&gt; file that initialises the application.&lt;/p&gt;

&lt;p&gt;And, while we&#39;re making everything immutable, let&#39;s change the action classes. Currently, we have actions such as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Bridge.React;
using BridgeReactTutorial.API;

namespace BridgeReactTutorial.Actions
{
  public class DataUpdated&amp;lt;T&amp;gt; : IDispatcherAction
  {
    public RequestId RequestId;
    public T Data;
  }
  public static class DataUpdated
  {
    public static DataUpdated&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(RequestId requestId, T data)
    {
      return new DataUpdated&amp;lt;T&amp;gt; { RequestId = requestId, Data = data };
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Bridge.React;
using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Actions
{
  public class DataUpdated&amp;lt;T&amp;gt; : IDispatcherAction, IAmImmutable
  {
    public DataUpdated(RequestId requestId, T data)
    {
      this.CtorSet(_ =&amp;gt; _.RequestId, requestId);
      this.CtorSet(_ =&amp;gt; _.Data, data);
    }
    public RequestId RequestId { get; private set; }
    public T Data { get; private set; }
  }
  public static class DataUpdated
  {
    public static DataUpdated&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(RequestId requestId, T data)
    {
      return new DataUpdated&amp;lt;T&amp;gt;(requestId, data);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The others require similar changes -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Bridge.React;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Actions
{
  public class SaveRequested&amp;lt;T&amp;gt; : IDispatcherAction, IAmImmutable
  {
    public SaveRequested(T data)
    {
      this.CtorSet(_ =&amp;gt; _.Data, data);
    }
    public T Data { get; private set; }
  }
  public static class SaveRequested
  {
    public static SaveRequested&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(T data)
    {
      return new SaveRequested&amp;lt;T&amp;gt;(data);
    }
  }
}

using Bridge.React;
using BridgeReactTutorial.API;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Actions
{
  public class SaveSucceeded : IDispatcherAction, IAmImmutable
  {
    public SaveSucceeded(RequestId requestId)
    {
      this.CtorSet(_ =&amp;gt; _.RequestId, requestId);
    }
    public RequestId RequestId { get; private set; }
  }
}

using Bridge.React;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Actions
{
  public class StoreInitialised : IDispatcherAction, IAmImmutable
  {
    public StoreInitialised(object store)
    {
      this.CtorSet(_ =&amp;gt; _.Store, store);
    }
    public object Store { get; private set; }
  }
}

using Bridge.React;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Actions
{
  public class UserEditRequested&amp;lt;T&amp;gt; : IDispatcherAction, IAmImmutable
  {
    public UserEditRequested(T newState)
    {
      this.CtorSet(_ =&amp;gt; _.NewState, newState);
    }
    public T NewState { get; private set; }
  }
  public static class UserEditRequested
  {
    public static UserEditRequested&amp;lt;T&amp;gt; For&amp;lt;T&amp;gt;(T newState)
    {
      return new UserEditRequested&amp;lt;T&amp;gt;(newState);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;strong&gt;App&lt;/strong&gt; class requires only minor tweaks, from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Linq;
using Bridge.Html5;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.API;
using BridgeReactTutorial.Components;
using BridgeReactTutorial.Stores;

namespace BridgeReactTutorial
{
  public class App
  {
    [Ready]
    public static void Go()
    {
      var container = Document.GetElementById(&quot;main&quot;);
      container.ClassName = string.Join(
        &quot; &quot;,
        container.ClassName.Split().Where(c =&amp;gt; c != &quot;loading&quot;)
      );

      var dispatcher = new AppDispatcher();
      var messageApi = new MessageApi(dispatcher);
      var store = new MessageWriterStore(messageApi, dispatcher);
      React.Render(
        new AppContainer(new AppContainer.Props
        {
          Dispatcher = dispatcher,
          Store = store
        }),
        container
      );
      dispatcher.HandleViewAction(new StoreInitialised { Store = store });
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Linq;
using Bridge.Html5;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.API;
using BridgeReactTutorial.Components;
using BridgeReactTutorial.Stores;

namespace BridgeReactTutorial
{
  public class App
  {
    [Ready]
    public static void Go()
    {
      var container = Document.GetElementById(&quot;main&quot;);
      container.ClassName = string.Join(
        &quot; &quot;,
        container.ClassName.Split().Where(c =&amp;gt; c != &quot;loading&quot;)
      );

      var dispatcher = new AppDispatcher();
      var messageApi = new MessageApi(dispatcher);
      var store = new MessageWriterStore(messageApi, dispatcher);
      React.Render(
        new AppContainer(dispatcher, store),
        container
      );
      dispatcher.HandleViewAction(new StoreInitialised(store));
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the &lt;strong&gt;MessageApi&lt;/strong&gt; needs various alterations to deal with the fact that all data types (such as the &lt;strong&gt;MessageDetails&lt;/strong&gt;, the message history and the action classes) are immutable -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge;
using Bridge.Html5;
using Bridge.React;
using BridgeReactTutorial.Actions;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.API
{
  public class MessageApi : IReadAndWriteMessages
  {
    private readonly AppDispatcher _dispatcher;
    private Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; _messages;
    public MessageApi(AppDispatcher dispatcher)
    {
      if (dispatcher == null)
        throw new ArgumentException(&quot;dispatcher&quot;);

      _dispatcher = dispatcher;
      _messages = Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;.Empty;

      // To further mimic a server-based API (where other people may be recording messages
      // of their own), after a 10s delay a periodic task will be executed to retrieve a
      // new message
      Window.SetTimeout(
        () =&amp;gt; Window.SetInterval(GetChuckNorrisFact, 5000),
        10000
      );
    }

    public RequestId SaveMessage(MessageDetails message)
    {
      return SaveMessage(message, optionalSaveCompletedCallback: null);
    }

    private RequestId SaveMessage(
      MessageDetails message,
      Action optionalSaveCompletedCallback)
    {
      if (message == null)
        throw new ArgumentNullException(&quot;message&quot;);

      var requestId = new RequestId();
      Window.SetTimeout(
        () =&amp;gt;
        {
          _messages = _messages.Add(Saved.For(
            (MessageId)(int)_messages.Count,
            message
          ));
          _dispatcher.HandleServerAction(new SaveSucceeded(requestId));
          if (optionalSaveCompletedCallback != null)
            optionalSaveCompletedCallback();
        },
        1000 // Simulate a roundtrip to the server
      );
      return requestId;
    }

    public RequestId GetMessages()
    {
      var requestId = new RequestId();
      Window.SetTimeout(
        () =&amp;gt; _dispatcher.HandleServerAction(DataUpdated.For(requestId, _messages)),
        1000 // Simulate a roundtrip to the server
      );
      return requestId;
    }

    private void GetChuckNorrisFact()
    {
      var request = new XMLHttpRequest();
      request.ResponseType = XMLHttpRequestResponseType.Json;
      request.OnReadyStateChange = () =&amp;gt;
      {
        if (request.ReadyState != AjaxReadyState.Done)
          return;

        if ((request.Status == 200) || (request.Status == 304))
        {
          try
          {
            var apiResponse = (ChuckNorrisFactApiResponse)request.Response;
            if ((apiResponse.Type == &quot;success&quot;)
            &amp;amp;&amp;amp; (apiResponse.Value != null)
            &amp;amp;&amp;amp; !string.IsNullOrWhiteSpace(apiResponse.Value.Joke))
            {
              // The Chuck Norris Facts API (http://www.icndb.com/api/) returns strings
              // html-encoded, so they need decoding before be wrapped up in a
              // MessageDetails instance
              // - Note: After the save has been processed, GetMessages is called so
              //   that a MessageHistoryUpdate action is dispatched
              SaveMessage(
                new MessageDetails(
                  title: new NonBlankTrimmedString(&quot;Fact&quot;),
                  content: new NonBlankTrimmedString(HtmlDecode(apiResponse.Value.Joke))
                ),
                () =&amp;gt; GetMessages()
              );
              return;
            }
          }
          catch
          {
            // Ignore any error and drop through to the fallback message-generator below
          }
        }
        SaveMessage(new MessageDetails(
          title: new NonBlankTrimmedString(&quot;Fact&quot;),
          content: new NonBlankTrimmedString(&quot;API call failed when polling for content :(&quot;)
        ));
      };
      request.Open(&quot;GET&quot;, &quot;http://api.icndb.com/jokes/random&quot;);
      request.Send();
    }

    private string HtmlDecode(string value)
    {
      if (value == null)
        throw new ArgumentNullException(&quot;value&quot;);

      var wrapper = Document.CreateElement(&quot;div&quot;);
      wrapper.InnerHTML = value;
      return wrapper.TextContent;
    }

    [IgnoreCast]
    private class ChuckNorrisFactApiResponse
    {
      public extern string Type { [Template(&quot;type&quot;)] get; }
      public extern FactDetails Value { [Template(&quot;value&quot;)] get; }

      [IgnoreCast]
      public class FactDetails
      {
        public extern int Id { [Template(&quot;id&quot;)] get; }
        public extern string Joke { [Template(&quot;joke&quot;)]get; }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One pleasant change was the removal of code that was previously in the &lt;strong&gt;MessageApi&lt;/strong&gt; with the following comment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ToArray is used to return a clone of the message set - otherwise, the caller would
// end up with a list that is updated when the internal reference within this class
// is updated (which sounds convenient but it&#39;s not the behaviour that would be
// exhibited if this was really persisting messages to a server somewhere)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since the message set is described by an immutable structure, there is no way that a particular reference&#39;s data could change. There is no way that a component could have a reference to this data type and then find that the data in that reference had changed by the time that an event bubbled up to that component from one of its child components. Similarly, when the &lt;strong&gt;MessageApi&lt;/strong&gt; passes its message history data out, there is no action that may be performed by any code that receives the message history reference that could &quot;pollute&quot; the data that the &lt;strong&gt;MessageApi&lt;/strong&gt; stores internally.&lt;/p&gt;

&lt;p&gt;Previously, when the &lt;strong&gt;MessageApi&lt;/strong&gt; wanted to share its message history data, we had two options - we could hope that the mutable list of mutable &lt;strong&gt;MessageDetails&lt;/strong&gt; would never be manipulated when it was passed out from the &lt;strong&gt;MessageApi&lt;/strong&gt; or we could try to make it impossible for other code to pollute the &lt;strong&gt;MessageApi&lt;/strong&gt;&#39;s copy of the data, which is what the &quot;ToArray&quot; call went some way towards (note that this wouldn&#39;t have saved us from code that received the mutable message history and then changed one of the fields on any of the individual mutable &lt;strong&gt;MessageDetails&lt;/strong&gt; instances - this &lt;em&gt;would&lt;/em&gt; have polluted to &lt;strong&gt;MessageApi&lt;/strong&gt;&#39;s internal data).&lt;/p&gt;

&lt;p&gt;This is a nice example of how immutable structures can actually aid performance &lt;em&gt;as well&lt;/em&gt; as aiding code clarity. Before, we were using a defensive &quot;ToArray&quot; call to try to avoid any silly mistakes polluting the &lt;strong&gt;MessageApi&lt;/strong&gt;&#39;s internal data. This was only a partial solution anyway, since, to really protect ourselves, we would have needed to clone the entire list - cloning each individual &lt;strong&gt;MessageDetails&lt;/strong&gt; instance, as well as the list itself. Now that the data is immutable, such cloning (which can be very expensive in some case) is not necessary. I maintain, though, that the biggest benefit is to code clarity rather than performance - it is now &lt;em&gt;impossible&lt;/em&gt; to make the &quot;silly mistake&quot; of mutating shared data, because the previously-implicit behaviour guideline of &quot;do not try to mutate this data, please&quot; is now encapsulated in the type sytem.&lt;/p&gt;

&lt;p&gt;It&#39;s not uncommon to hear people claim that using immutable types incur a performance cost. I believe that this is only really true at a highly localised level. For example, if you have an array and you want to change the element at index 5, that is an incredibly cheap operation and it is not possible to have an &quot;immutable array&quot; that has a method that will give you a new immutable array instance with a different value at index 5 as cheaply. At this level, mutable structures can perform operations more quickly. However, immutable structures can allow techniques that provide performance benefits at a higher level, such as described above, where expensive cloning operations may be avoided entirely (general-case cloning operations can be expensive in CPU &lt;em&gt;and&lt;/em&gt; in memory, since a clone will duplicate the entire data structure, whereas mature immutable-type libraries leverage clever &quot;persistent structures&quot; to reuse data between instances).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(It has become less common to hear this argument against immutable data structures since they are being much more widely used these days - React is an excellent example in that it leverages immutability to allow for fantastic performance, rather than immutability being a cost that the React library has to pay).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;While performance is not my number one goal (which is not to say that I don&#39;t think it&#39;s an &lt;em&gt;important&lt;/em&gt; target, I&#39;m just saying that I value code clarity more highly), this topic of conversation leads me nicely on to the next topic.&lt;/p&gt;

&lt;h3&gt;Pure Components&lt;/h3&gt;

&lt;p&gt;If a &quot;pure function&quot; is one that returns a value based solely upon its arguments, then a &quot;pure component&quot; is a parallel concept - it generates content based solely upon its &quot;props&quot; data.&lt;/p&gt;

&lt;p&gt;To recall what our example application looks like -&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Message Editor and Message History&quot; src=&quot;http://www.productiverage.com/Content/Images/Posts/ReactTutorial1.png&quot; class=&quot;NoBorder AlwaysFullWidth&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are basically two parts to it; the Message Editor and the Message History. The Message Editor part changes after one of any of the following occurs -&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;While the entry form is enabled, the user changes the content in one of the text inputs&lt;/li&gt;
&lt;li&gt;While the entry form is enabled and both text inputs have values, the user clicks Save&lt;/li&gt;
&lt;li&gt;A save request is completed and the form changes back from disabled to enabled&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Message History part changes only when the &lt;strong&gt;MessageApi&lt;/strong&gt; sends a message to say that there is new message data to display.&lt;/p&gt;

&lt;p&gt;What happens in our application is that &lt;em&gt;every&lt;/em&gt; change results in a full React re-render. React is very efficient and its Virtual DOM minimises (and can batch) changes to the slow browser DOM, so this is rarely something to worry about. However, it might lead you to think -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If I know that a particular event will only result in changes to the Message Editor, isn&#39;t it wasteful to React to re-render the entire Message History content in its Virtual DOM - &lt;em&gt;particularly&lt;/em&gt; if it does this only to discover that no changes to the browser DOM need to be applied?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is an entirely reasonable question. If there are a hundred messages in the Message History, does that component &lt;em&gt;really&lt;/em&gt; have to re-render them all in the Virtual DOM every time that the user presses a button to change the value in the &quot;Title&quot; text input in the Message Editor? What if there 1000 messages in the history? Or what if this was a much more complicated application with many, many editable inputs and lists of results all over the page - do I really want the entirety of this complicated UI to be re-rendered by the Virtual DOM every time that the user edits a single field?&lt;/p&gt;

&lt;p&gt;If we were using mutable structures to represent the data that the React component hierarchy has to render, we would have a few options. One would be to change the component structure such that there were more stateful components in order to try to only update branches of the hierarchy that need to change according to particular changes. In our example, the &lt;strong&gt;MessageEditor&lt;/strong&gt; could be made stateful in a bid to limit changes to the text inputs from resulting in re-renders of the &lt;strong&gt;MessageHistory&lt;/strong&gt; (which would also have to become a stateful component, so that it could update itself when the message history data changes). This would require the &lt;strong&gt;MessageWriteStore&lt;/strong&gt; to be changed as well. On the surface of it, this doesn&#39;t necessarily sound like a terrible idea, but stateful components will &lt;em&gt;always&lt;/em&gt; require more thought and planning than stateless components and so this would be a move back towards more complicated component models. This would be an unfortunate step back from where we are now, where the complications are minimised and most components are stateless. We would no longer have a render-down and pass-events-up model, we would have a sort of branched version of it.&lt;/p&gt;

&lt;p&gt;Another option would be to try to have components make use of React&#39;s &quot;&lt;a href=&quot;https://facebook.github.io/react/docs/component-specs.html#updating-shouldcomponentupdate&quot;&gt;shouldComponentUpdate&lt;/a&gt;&quot; method. This is a method that may optionally be implemented on components, that is called before a component&#39;s &quot;Render&quot; method is called, so long as that component has been rendered at least once before. It will be given two &quot;props&quot; values - one is the props data from the last render and the second is the new props data that has been specified for the re-render. If this method returns true then the component is re-rendered (to the Virtual DOM) as normal. If it returns false then the component&#39;s &quot;Render&quot; method is &lt;em&gt;not&lt;/em&gt; called. This would mean that none of its child components would be re-rendered either, since those re-renders are only triggered by code in their parent&#39;s component&#39;s &quot;Render&quot; method. If it was possible for the &lt;strong&gt;MessageHistory&lt;/strong&gt; to look at its last props and its next props and see that they describe the same data, then the entire re-render work could be avoided. The problem comes in working that out, though - for the cases where the old and new messages data &lt;em&gt;was&lt;/em&gt; the same and when we had an &lt;strong&gt;IEnumerable&lt;/strong&gt; set of mutable &lt;strong&gt;MessageDetails&lt;/strong&gt; instances, we would have had to have enumerated through every value in the set and compared the &quot;Title&quot; and &quot;Content&quot; values on each message. If they all matched then the old and new data would have been proven to have been the same and the re-render would not be required. But was all that comparison work really much cheaper than just letting the Virtual DOM do its magic?&lt;/p&gt;

&lt;p&gt;One of the good thing about immutable structures is that data can safely be shared and reused. Now that the &lt;strong&gt;MessageHistory&lt;/strong&gt; component takes an immutable &lt;strong&gt;Set&lt;/strong&gt; of immutable &lt;strong&gt;MessageDetails&lt;/strong&gt; instances, if the data hasn&#39;t changed then the same &lt;strong&gt;Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;&lt;/strong&gt; reference will be passed to the &lt;strong&gt;MessageHistory.Props&lt;/strong&gt; instance - but if the data &lt;em&gt;has&lt;/em&gt; changed then, by necessity, a new &lt;strong&gt;Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt;&lt;/strong&gt; reference will be provided. This would make a &quot;shouldComponentUpdate&quot; implementation very simple - just look at each property on the old and new props references and use reference equality comparisons to see if anything&#39;s changed.&lt;/p&gt;

&lt;p&gt;The bad news is that the &lt;strong&gt;StatelessComponent&lt;/strong&gt; base class in the Bridge / React bindings doesn&#39;t support &quot;shouldComponentUpdate&quot;. So you can&#39;t try to take advantage of it to reduce the work that the Virtual DOM does - only the &lt;strong&gt;Component&lt;/strong&gt; (which is the full stateful component) base class supports it. The good news is that you don&#39;t need to implement it manually. If you&#39;re creating stateless components whose props classes have properties that are all primitive values (such as bool, int, string, etc..) and / or immutable types and / or functions* and if the components genuinely render &lt;em&gt;entirely&lt;/em&gt; according to the props data (no accessing DateTime.Now, for example) then you can derive from the &lt;strong&gt;PureComponent&lt;/strong&gt; base class instead. This automatically implements &quot;shouldComponentUpdate&quot; behind the scenes.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(There are some cases where &quot;props&quot; properties that are callbacks - like &quot;OnChange&quot; on the &lt;strong&gt;TextInput&lt;/strong&gt; - can&#39;t be compared by the &lt;strong&gt;PureComponent&lt;/strong&gt;&#39;s magic, but most of the time they can be and the details of when they can and can&#39;t are outside the scope of this article - so let&#39;s just assume that function / &lt;strong&gt;Action&amp;lt;T&amp;gt;&lt;/strong&gt; / callback property types CAN always be handled).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To illustrate, add the following line to the start of the &lt;strong&gt;MessageHistory&lt;/strong&gt; &quot;Render&quot; method -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Console.WriteLine(&quot;MessageHistory.Render&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, run the application in the browser and bring up the browser console in the dev tools. &lt;em&gt;Every&lt;/em&gt; time that the app re-renders in the Virtual DOM, &quot;MessageHistory.Render&quot; will be written to the console. Every time that a key is pressed to change one of the text input elements, the entire UI will be re-rendered and &quot;MessageHistory.Render&quot; will be displayed in the console.&lt;/p&gt;

&lt;p&gt;Now, change the base class of the &lt;strong&gt;MessageHistory&lt;/strong&gt; from &lt;strong&gt;StatelessComponent&amp;lt;MessageHistory.Props&amp;gt;&lt;/strong&gt; to &lt;strong&gt;PureComponent&amp;lt;MessageHistory.Props&amp;gt;&lt;/strong&gt;. It will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Linq;
using Bridge.Html5;
using Bridge.React;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class MessageHistory : StatelessComponent&amp;lt;MessageHistory.Props&amp;gt;
  {
    public MessageHistory(
      Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; messages,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, messages)) { }

    public override ReactElement Render()
    {
      Bridge.Html5.Console.WriteLine(&quot;MessageHistory.Render&quot;);

      var className = props.ClassName;
      if (!props.Messages.Any())
        className = className.Add(&quot; &quot;, new NonBlankTrimmedString(&quot;zero-messages&quot;));

      // Any time a set of child components is dynamically-created (meaning that the
      // numbers of items may vary from one render to another), each must have a unique
      // &quot;Key&quot; property set (this may be a int or a string). Here, this is simple as
      // each message tuple is a unique ID and the contents of that message.
      var messageElements = props.Messages
        .Select(savedMessage =&amp;gt; DOM.Div(new Attributes { Key = (int)savedMessage.Key },
        DOM.Span(new Attributes { ClassName = &quot;title&quot; }, savedMessage.Value.Title),
        DOM.Span(new Attributes { ClassName = &quot;content&quot; }, savedMessage.Value.Content)
        ));

      // When child components are specified (as they are through the second argument of
      // DOM.Div), the argument is of type Any&amp;lt;ReactElement, string&amp;gt;[] (meaning that each
      // element may be another component or it may be a simple text value)
      // - The React  bindings have an extension method that transforms an IEnumerable set
      //   of components (such as &quot;messageElements&quot;) into an Any&amp;lt;ReactElement, string&amp;gt;[]
      return DOM.FieldSet(
        new FieldSetAttributes { ClassName = className.ToStringIfDefined() },
        DOM.Legend(null, &quot;Message History&quot;),
        DOM.Div(null, messageElements.ToChildComponentArray())
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; messages)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Messages, messages);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public Set&amp;lt;Saved&amp;lt;MessageId, MessageDetails&amp;gt;&amp;gt; Messages { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Re-build the application and refresh it in the browser. Now change the text input values while keeping an eye on the console. The &quot;MessageHistory.Render&quot; message will initially only appear in the console when the &lt;strong&gt;MessageHistory&lt;/strong&gt; component is first rendered, the changes to the text inputs no longer require the &lt;strong&gt;MessageHistory&lt;/strong&gt; component be redrawn by the Virtual DOM. When the message data actually changes (whether due to you saving a new message or due to a new Chuck Norris fact arriving), the &lt;strong&gt;MessageHistory&lt;/strong&gt; component &lt;em&gt;will&lt;/em&gt; update - indicated by another &quot;MessageHistory.Render&quot; message being displayed in the console.&lt;/p&gt;

&lt;p&gt;This is an excellent example of how using immutable structures can result in cleaner &lt;em&gt;and&lt;/em&gt; more efficient code. In a complicated UI (or if your application is very performance-sensitive - if you&#39;re trying to achieve 60fps on mobile, for example) then being able to save the Virtual DOM the work of determining whether entire branches of the component hierarchy should be re-rendered is invaluable. And getting this optimisation &quot;for free&quot; makes it even better - if you&#39;re following my recommendations and the vast majority of your React components are stateless and al of your data types are immutable then you might as well use the &lt;strong&gt;PureComponent&lt;/strong&gt; base class and reap the performance benefits.&lt;/p&gt;

&lt;h3&gt;PureComponent details&lt;/h3&gt;

&lt;p&gt;I want to go into some of the finer point of the &lt;strong&gt;PureComponent&lt;/strong&gt;&#39;s optimisation rules. There&#39;s nothing particularly complicated or surprising, but there are some nuances that it&#39;s worth being aware of.&lt;/p&gt;

&lt;p&gt;When the &lt;strong&gt;PureComponent&lt;/strong&gt; implements &quot;shouldComponentUpdate&quot; behind the scenes, the React library provides it with two separate instances to compare of the &lt;strong&gt;Props&lt;/strong&gt; class for the current component. The first thing that the &lt;strong&gt;PureComponent&lt;/strong&gt; does is ensure that the two props instances are of the same type (while it would be strange, it would not be illegal to create types derived from the component&#39;s &lt;strong&gt;Props&lt;/strong&gt; class - but if different derived types were provided for the old and new props then it doesn&#39;t seem safe to try to compare them, who knows &lt;em&gt;why&lt;/em&gt; they are different or what significance there could be in the differences). If the old and new props references &lt;em&gt;are&lt;/em&gt; of the precise same type, then it enumerates the properties on the type and compares the values on the old and new props instances. Each pair of property values must match - this means that they are either both null or they are both the same value of a primitive type or they are the same reference &lt;em&gt;or&lt;/em&gt; they are both non-null &lt;em&gt;and&lt;/em&gt; the first value has an &quot;Equals&quot; method that returns true when the second value is passed into it.&lt;/p&gt;

&lt;p&gt;On the whole, this means that things largely work completely intuitively. &lt;em&gt;Particularly&lt;/em&gt; due to the way that the &quot;With&quot; extension methods works for &lt;strong&gt;IAmImmutable&lt;/strong&gt;-implementing class. If &quot;With&quot; is called with a property value update where the new value is the same as the old value, then &quot;With&quot; returns the original instance unaltered. This is most easily explained with an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var title = new TextEditState(text: &quot;hello&quot;, validationError: null);
var title2 = title.With(_ =&amp;gt; _.Text, &quot;hello&quot;);
var title3 = title.With(_ =&amp;gt; _.Text, &quot;hell&quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &quot;title2&quot; instance will be the same as the &quot;title&quot; reference - the text value was asked to changed from &quot;hello&quot; to &quot;hello&quot;, which is no change at all. Since the &lt;strong&gt;TextEditState&lt;/strong&gt; type is immutable, there is no pointing copying &quot;title&quot; to create a new &quot;title2&quot; reference with all of the same data. &quot;title3&quot; &lt;em&gt;will&lt;/em&gt; be a new instance, since the text value needs to change from &quot;hello&quot; to &quot;hell&quot;.&lt;/p&gt;

&lt;p&gt;Having &quot;With&quot; return the same reference when no change is required is beneficial for garbage collection - the fewer references that are created means the less work that it has to do. But it&#39;s also very important for the &lt;strong&gt;PureComponent&lt;/strong&gt; since that prefers to use referential equality to determine whether a property value has changed. If a &lt;strong&gt;Props&lt;/strong&gt; class has a &lt;strong&gt;TextEditState&lt;/strong&gt; property on it, when the values on the old and new props are compared then we want the &lt;strong&gt;TextEditState&lt;/strong&gt; references to be the same if the data that they represent hasn&#39;t changed.&lt;/p&gt;

&lt;p&gt;I think that another example is called for. In the example application from this series, the Message Editor form is given information in its props that describes the current state of the form - the &quot;Caption&quot;, the &quot;Title&quot; text-input-value-and-any-validation-message, the &quot;Content&quot; text-input-value-and-any-validation-message (and information about whether the form should be disabled because a save is in progress). This data is all contained within a &lt;strong&gt;MessageEditState&lt;/strong&gt; instance. The &lt;strong&gt;MessageEditor&lt;/strong&gt; component renders each text input by generating child &lt;strong&gt;ValidatedTextInput&lt;/strong&gt; components. These child &lt;strong&gt;ValidatedTextInput&lt;/strong&gt; components raise an &quot;OnChange&quot; event when the user wants to alter the content in the text input element, the event includes a string argument for the new text value. When this happens, the &lt;strong&gt;MessageEditor&lt;/strong&gt; takes this new text value and uses it to create a new &lt;strong&gt;MessageEditState&lt;/strong&gt; instance, using the &quot;With&quot; extension method - this new instance is then passed up on the &lt;strong&gt;MessageEditor&lt;/strong&gt;&#39;s &quot;OnChange&quot; event. This event will result in the UI being re-rendered to display the new data.&lt;/p&gt;

&lt;p&gt;However, React raises change events from text inputs for user interactions &lt;em&gt;even if they don&#39;t actually result in a change&lt;/em&gt;. If, for instance, there is a text input with the value &quot;Hello&quot; in it and you highlight that text and copy it to the clipboard and then paste it into that same text input then the value obviously hasn&#39;t changed, but React still raises a change event from the text input due to the paste action. What we want to happen in this case is for the &quot;new&quot; &lt;strong&gt;MessageEditState&lt;/strong&gt; instance that the &lt;strong&gt;MessageEditor&lt;/strong&gt; creates when it raises its &quot;OnChange&quot; event to be the exact same reference as the &lt;strong&gt;MessageEditState&lt;/strong&gt; given to the &lt;strong&gt;MessageEditor&lt;/strong&gt; when it last rendered. This way, when the &lt;strong&gt;MessageEditor&lt;/strong&gt; is asked to re-render then it will find that the &quot;new&quot; props data is exactly the same as the old props data and the &lt;strong&gt;PureComponent&lt;/strong&gt; logic will tell React that it needn&#39;t bother re-rendering the component at all.&lt;/p&gt;

&lt;p&gt;Maybe it&#39;s worth examining the &lt;strong&gt;MessageEditor&lt;/strong&gt; code again to try to make this seem less abstract:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge.React;
using BridgeReactTutorial.API;
using BridgeReactTutorial.ViewModels;
using ProductiveRage.Immutable;

namespace BridgeReactTutorial.Components
{
  public class MessageEditor : StatelessComponent&amp;lt;MessageEditor.Props&amp;gt;
  {
    public MessageEditor(
      MessageEditState message,
      Action&amp;lt;MessageEditState&amp;gt; onChange,
      Action onSave,
      Optional&amp;lt;NonBlankTrimmedString&amp;gt; className = new Optional&amp;lt;NonBlankTrimmedString&amp;gt;())
      : base(new Props(className, message, onChange, onSave)) { }

    public override ReactElement Render()
    {
      var formIsInvalid =
        props.Message.Title.ValidationError.IsDefined ||
        props.Message.Content.ValidationError.IsDefined;

      return DOM.FieldSet(
        new FieldSetAttributes { ClassName = props.ClassName.ToStringIfDefined() },
        DOM.Legend(null, props.Message.Caption),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Title&quot;),
        new ValidatedTextInput(
          className: new NonBlankTrimmedString(&quot;title&quot;),
          disabled: props.Message.IsSaveInProgress,
          content: props.Message.Title.Text,
          onChange: newTitle =&amp;gt; props.OnChange(
            props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle))
          ),
          validationMessage: props.Message.Title.ValidationError
        ),
        DOM.Span(new Attributes { ClassName = &quot;label&quot; }, &quot;Content&quot;),
        new ValidatedTextInput(
          className: new NonBlankTrimmedString(&quot;content&quot;),
          disabled: props.Message.IsSaveInProgress,
          content: props.Message.Content.Text,
          onChange: newContent =&amp;gt; props.OnChange(
            props.Message.With(_ =&amp;gt; _.Content, new TextEditState(newContent))
          ),
          validationMessage: props.Message.Content.ValidationError
        ),
        DOM.Button(
        new ButtonAttributes
        {
          Disabled = formIsInvalid || props.Message.IsSaveInProgress,
          OnClick = e =&amp;gt; props.OnSave()
        },
        &quot;Save&quot;
        )
      );
    }

    public class Props : IAmImmutable
    {
      public Props(
        Optional&amp;lt;NonBlankTrimmedString&amp;gt; className,
        MessageEditState message,
        Action&amp;lt;MessageEditState&amp;gt; onChange,
        Action onSave)
      {
        this.CtorSet(_ =&amp;gt; _.ClassName, className);
        this.CtorSet(_ =&amp;gt; _.Message, message);
        this.CtorSet(_ =&amp;gt; _.OnChange, onChange);
        this.CtorSet(_ =&amp;gt; _.OnSave, onSave);
      }
      public Optional&amp;lt;NonBlankTrimmedString&amp;gt; ClassName { get; private set; }
      public MessageEditState Message { get; private set; }
      public Action&amp;lt;MessageEditState&amp;gt; OnChange { get; private set; }
      public Action OnSave { get; private set; }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the user attempted this copy-paste-same-value thing in the &quot;Title&quot; input, then the &quot;onChange&quot; event from the &lt;strong&gt;ValidatedTextInput&lt;/strong&gt; that renders the Title value would be raised -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;onChange: newTitle =&amp;gt; props.OnChange(
  props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will result in the &lt;strong&gt;MessageEditor&lt;/strong&gt;&#39;s &quot;OnChange&quot; event being raised, with a new &lt;strong&gt;MessageEditState&lt;/strong&gt; instance. The key thing is that we want the new &lt;strong&gt;MessageEditState&lt;/strong&gt; instance to be the same as the current &lt;strong&gt;MessageEditState&lt;/strong&gt; instance if the new &quot;Title&quot; string is exactly the same as the current &quot;Title&quot; string.&lt;/p&gt;

&lt;p&gt;One way to do this would be to not worry about how &quot;With&quot; does or doesn&#39;t work and to add a condition into the lambda - eg.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;onChange: newTitle =&amp;gt;
{
  if (newTitle != props.Message.Title.text)
    props.OnChange(props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle)));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, this means that more logic has to go in the components (which I want to avoid). Worse, it&#39;s boring and repetitive logic, which is the kind that I find is most likely to be done incorrectly by accident because you almost feel like you can write it on auto-pilot. It would be best if this could be handled automatically.&lt;/p&gt;

&lt;p&gt;Well, it &lt;em&gt;can&lt;/em&gt; be if we always use &quot;With&quot; to update values. In the code above, I&#39;ve actually been a bit naughty. A &lt;strong&gt;TextEditState&lt;/strong&gt; includes two values - &quot;Text&quot; and &quot;ValidationMessage&quot;. The &quot;ValidationMessage&quot; will get set according to the &quot;Text&quot; value when validation is applied (which happens in the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; in this application). The code above creates a &lt;em&gt;new&lt;/em&gt; &lt;strong&gt;TextEditState&lt;/strong&gt; with the &quot;newTitle&quot; string, erasing any &quot;ValidationMessage&quot; value. This is not really correct, since only the validation logic should change the &quot;ValidationMessage&quot; value. In this example, a validation message should only be displayed if the text value is empty - but the components should have no knowledge of this since we want them to be as dumb as possible. So, any time that a component creates a new &lt;strong&gt;TextEditState&lt;/strong&gt; to include in an &quot;OnChange&quot; event, the &quot;ValidationMessage&quot; property should be untouched - again, it is the responsibility of the store (and &lt;em&gt;not&lt;/em&gt; the component) to worry about ensuring that the &quot;ValidationMessage&quot; value is correct for the &quot;Text&quot; value before a re-render is triggered.&lt;/p&gt;

&lt;p&gt;So, this code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;onChange: newTitle =&amp;gt; props.OnChange(
  props.Message.With(_ =&amp;gt; _.Title, new TextEditState(newTitle))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;should really be this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;onChange: newTitle =&amp;gt; props.OnChange(
  props.Message.With(_ =&amp;gt; _.Title, props.Message.Title.With(_ =&amp;gt; _.Text, newContent))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;em&gt;only&lt;/em&gt; changes the &quot;Text&quot; property on the &quot;Title&quot; &lt;strong&gt;TextEditState&lt;/strong&gt; - which means that, in our copy-paste-same-value case, no new &lt;strong&gt;TextEditState&lt;/strong&gt; instance will be created. This still means that the &lt;strong&gt;MessageEditor&lt;/strong&gt;&#39;s &quot;OnChange&quot; event will be raised (which will result in an action being sent through the Dispatcher and received by the &lt;strong&gt;MessageWriterStore&lt;/strong&gt;, which will raise a &quot;Change&quot; event and cause the &lt;strong&gt;AppContainer&lt;/strong&gt; to re-render the UI), but when the &lt;strong&gt;MessageEditor&lt;/strong&gt; is asked to re-render then it will realise that the new data is the same as its current data and it will tell React not to bother re-rendering it. The code still had to do one full pass of the raise-event-up-to-top-level-component-and-send-change-message-through-Dispatcher-to-the-Store, even though the data hadn&#39;t changed, but that sort of work is very cheap (certainly much cheaper than any DOM or even Virtual DOM interactions).&lt;/p&gt;

&lt;p&gt;All of the above came &quot;for free&quot; by using &lt;strong&gt;IAmImmutable&lt;/strong&gt;-implementing classes and &lt;strong&gt;PureComponent&lt;/strong&gt; and by applying updates using the &quot;With&quot; extension method. There are &lt;em&gt;some&lt;/em&gt; cases where you need to do a little work to help the system out, though. If you recall the &quot;ValidateMessage&quot; function that we wrote earlier -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static MessageEditState ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  return message
    .With(_ =&amp;gt; _.Caption, ToNonBlankTrimmedString(message.Title, fallback: _defaultCaption))
    .With(_ =&amp;gt; _.Title, Validate(message.Title, MustHaveValue, _noTitleWarning))
    .With(_ =&amp;gt; _.Content, Validate(message.Content, MustHaveValue, _noContentWarning));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This always set the &quot;Caption&quot; based upon the &quot;Title&quot; value. If there is a &quot;Title&quot; value in the text input of the message editor form of &quot;My New Message&quot; then the &quot;Caption&quot; value will also be &quot;My New Message&quot;. The &quot;ToNonBlankTrimmedString&quot; method is implemented as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static NonBlankTrimmedString ToNonBlankTrimmedString(
  TextEditState textEditState,
  NonBlankTrimmedString fallback)
{
  if (textEditState == null)
    throw new ArgumentNullException(&quot;textEditState&quot;);
  if (fallback == null)
    throw new ArgumentNullException(&quot;fallback&quot;);

  return (textEditState.Text.Trim() == &quot;&quot;)
    ? fallback
    : new NonBlankTrimmedString(textEditState.Text);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Every time that &quot;ValidateMessage&quot; is called and there is a non-blank &quot;Title&quot; value then a new &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instance will be created for the &quot;Caption&quot;. The problem is that if the &quot;Title&quot; input isn&#39;t changing (if the user is currently changing the &quot;Content&quot; text input box, for example) then we will be creating new &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instances for the same &quot;Title&quot; value - and the &lt;strong&gt;PureComponent&lt;/strong&gt; will see each new &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; reference as a new and distinct value.&lt;/p&gt;

&lt;p&gt;We could try to prevent this by changing &quot;ValidateMessage&quot; such that it tries to avoid creating new &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instances for the Caption -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static MessageEditState ValidateMessage(MessageEditState message)
{
  if (message == null)
    throw new ArgumentNullException(&quot;message&quot;);

  if (message.Title.Text.Trim() == &quot;&quot;)
    message = message.With(_ =&amp;gt; _.Caption, _defaultCaption);
  else if (message.Title.Text.Trim() != message.Caption)
    message = message.With(_ =&amp;gt; _.Caption, new NonBlankTrimmedString(message.Title.Text));

  return message
    .With(_ =&amp;gt; _.Title, Validate(message.Title, MustHaveValue, _noTitleWarning))
    .With(_ =&amp;gt; _.Content, Validate(message.Content, MustHaveValue, _noContentWarning));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. but this brings us back round to &quot;ValidateMessage&quot; being very noisy. This will have a tendency to make it prone to error and it definitely moves away from the goal of code clarity that I&#39;m aiming for.&lt;/p&gt;

&lt;p&gt;An alternative is to implement an &quot;Equals&quot; override for the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; class. The &quot;With&quot; extension method, like the &lt;strong&gt;PureComponent&lt;/strong&gt;&#39;s &quot;shouldComponentUpdate&quot; logic&quot;, will consider an &quot;Equals&quot; method if referential equality fails. This means that if we call &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.With(_ =&amp;gt; _.Caption, ToNonBlankTrimmedString(message.Title, fallback: _defaultCaption))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;.. and if the return value from &quot;ToNonBlankTrimmedString&quot; is a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; instance that is equivalent to the current &quot;Caption&quot; value (according to the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; &quot;Equals&quot; implementation below), then &quot;With&quot; will return the same reference.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using Bridge;
using Bridge.React;

namespace BridgeReactTutorial.API
{
  public sealed class NonBlankTrimmedString
  {
    public NonBlankTrimmedString(string value)
    {
      if (string.IsNullOrWhiteSpace(value))
        throw new ArgumentException(&quot;Null, blank or whitespace-only value specified&quot;);

      Value = value.Trim();
    }

    /// &amp;lt;summary&amp;gt;
    /// This will never be null, blank or have any leading or trailing whitespace
    /// &amp;lt;/summary&amp;gt;
    public string Value { get; private set; }

    /// &amp;lt;summary&amp;gt;
    /// It&#39;s convenient to be able to pass a NonBlankTrimmedString instance as any argument
    /// that requires a string
    /// &amp;lt;/summary&amp;gt;
    public static implicit operator string(NonBlankTrimmedString value)
    {
      if (value == null)
        throw new ArgumentNullException(&quot;value&quot;);
      return value.Value;
    }

    /// &amp;lt;summary&amp;gt;
    /// It&#39;s convenient to be able to pass a NonBlankTrimmedString instance as any argument
    /// that requires a ReactElement-or-string, such as for the children array of the React
    /// DOM component factories
    /// &amp;lt;/summary&amp;gt;
    public static implicit operator Any&amp;lt;ReactElement, string&amp;gt;(NonBlankTrimmedString value)
    {
      if (value == null)
        throw new ArgumentNullException(&quot;value&quot;);
      return value.Value;
    }

    public override bool Equals(object o)
    {
      var otherNonBlankTrimmedString = o as NonBlankTrimmedString;
      return
        (otherNonBlankTrimmedString != null) &amp;amp;&amp;amp;
        (otherNonBlankTrimmedString.Value == Value);
    }

    public override int GetHashCode()
    {
      return Value.GetHashCode();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Having an &quot;Equals&quot; implementation on types such as &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; makes a lot of sense because we essentially want them to be treated as &quot;value types&quot; - if two references describe the same data then they should be treated as the same value. Note that a custom &quot;Equals&quot; implementation was not necessary for &lt;strong&gt;MessageId&lt;/strong&gt;, since that is a struct - in C#, structs &lt;a href=&quot;http://csharp.2000things.com/2011/09/14/411-overriding-the-equals-method-for-a-value-type/&quot;&gt;automatically get an &quot;Equals&quot; implementation created for them&lt;/a&gt; that considers two struct instances to be equivalent if all of their properties have the same values and the JavaScript generated by Bridge does the same in order to maintain compatibility.&lt;/p&gt;

&lt;p&gt;One thing that I snuck into the new &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; above is that the class is now sealed. If it is possible to inherit from a given class, it becomes much more difficult to implement a reliable &quot;Equals&quot; method. For the sake of argument, imagine a class &quot;X&quot; that is not sealed and that has a single string &quot;Value&quot; property and that implements its own &quot;Equals&quot; method, exactly the same as the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; &quot;Equals&quot; method above. Then imagine that a class &quot;Y&quot; is derived from &quot;X&quot; and adds a second property, a &quot;Count&quot; int. If &quot;Y&quot; does not override the &quot;Equals&quot; implementation on &quot;X&quot; then it seems likely that the &quot;Equals&quot; implementation that &quot;Y&quot; inherits from &quot;X&quot; will be inaccurate - if an instance of &quot;Y&quot; with a &quot;Value&quot; of &quot;Hello&quot; and &quot;Count&quot; of 1 was compared to another instance of &quot;Y&quot; with a &quot;Value&quot; of &quot;Hello&quot; but a &quot;Count&quot; of 2 then they would be considered to be equivalent, which would almost certainly not be the expected behaviour. There is an implicit assumption that if &quot;X&quot; is derived from and the derived type adds properties then that derived type should have its own &quot;Equals&quot; method. A failure to respect this implicit assumption will not result in any compiler warnings, it will likely result only in unexpected runtime behaviour at some point. I don&#39;t like implicit assumptions, as I&#39;m sure that you&#39;ve been able to tell from the themes in this post. An easy way to avoid this problem is to prevent &quot;X&quot; from being inherited from, by making it sealed. This is precisely what I&#39;ve done with the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This leads me on to another guideline - I believe that 99% of all classes should be abstract or sealed. Any class that may be inherited from requires planning, to try to make it as easy as possible for any derived types to work in non-suprising manners. This is complicated, if not impossible (as the &quot;Equals&quot; conundrum above hopefully illustrates for an extremely simple case). However, if you really think that it should be possible for a class to be inherited from, then I think that you should document any implicit assumptions on that base class and you should carefully think about how it should and shouldn&#39;t be used. I have found that the most common cases for which a base class are suitable are those where some shared functionality is required that can&#39;t easily be provided via composition (which I will talk about in a moment), but where that base class is not fully-functional itself and so must be inherited from in order to be useful. The &lt;strong&gt;Component&lt;/strong&gt;, &lt;strong&gt;StatelessComponent&lt;/strong&gt; and &lt;strong&gt;PureComponent&lt;/strong&gt; base classes in the Bridge / React bindings are excellent examples; they are required in order to define components that the React library can work with, but the classes are not functional on their own - they must be inherited from in order to be useful, therefore they are defined as abstract classes.&lt;/p&gt;

&lt;p&gt;Historically, I think that there have been beliefs that many object models lend themselves well to inheritance hierarchies. In Web Forms (if I remember correctly - it&#39;s been a long time), a &lt;strong&gt;Button&lt;/strong&gt; inherited from a &lt;strong&gt;WebControl&lt;/strong&gt; and that inherited from a &lt;strong&gt;Control&lt;/strong&gt; or a &lt;strong&gt;Component&lt;/strong&gt;.. or something. The idea was that every component as you went up the hierarchy was a specialisation of the one below it. Which arguably made sense. But I find that the waters often get very murky when these &quot;is-a&quot; hierachies are constructed and it&#39;s very easy to confuse a &quot;has-a&quot; characteristic for being an &quot;is-a&quot;. For example, the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; needs to register for events from the Dispatcher, so perhaps it is a specialisation of a &quot;DispatcherMessageReceiver&quot;. But it&#39;s also responsible for saving messages, so perhaps it&#39;s also specialisation of a &quot;MessageRecorder&quot;. Not only is it more complicated to design classes that are intended to be inherited from, but C# only allows one class to inherit from a single base class - so if &lt;strong&gt;MessageWriterStore&lt;/strong&gt; needs to be a specialisation of both a &quot;DispatcherMessageReceiver&quot; &lt;em&gt;and&lt;/em&gt; a &quot;MessageRecorder&quot; then we have a problem; possibly only solved by creating a specialisation of the &quot;DispatcherMessageReceiver&quot; that &lt;em&gt;also&lt;/em&gt; deals with recording messages, so that the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; can inherit from &lt;em&gt;that&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Perhaps that example is a little fatuous, but similar sorts of issues &lt;em&gt;do&lt;/em&gt; genuinely occur when inheritance trees are viewed as &quot;the best way&quot; to build classes. The alternative is to use composition, which is where classes are designed in a &quot;has-a&quot; manner. The current &lt;strong&gt;MessageWriterStore&lt;/strong&gt; is designed in this way as its constructor declares that it requires an &lt;strong&gt;AppDispatcher&lt;/strong&gt; and a &lt;strong&gt;IReadAndWriteMessages&lt;/strong&gt; implementation. Not only does composition avoid the multiple inheritance problem (also known as the &quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Multiple_inheritance#The_diamond_problem&quot;&gt;deadly diamond of death&lt;/a&gt;&quot;) but it makes code easier to fully comprehend. With inheritance, each class is a sum of its behaviour and all of the behaviour of its base class (which is likewise a sum of &lt;em&gt;its&lt;/em&gt; behaviour and all of the behaviour of &lt;em&gt;its&lt;/em&gt; base class, repeated for as many levels as the inheritance tree is deep). With composition, each piece is fully self-contained and communication between one part and another is throughly tightly constrained interfaces.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(A couple of months ago, I read &quot;&lt;a href=&quot;https://tech.scrunch.com/blog/5-reasons-your-team-will-love-you-for-composition/&quot;&gt;5 reasons your team will love you for composition&lt;/a&gt;&quot;, which I think offers a good take on some of the practical benefits positives of preferring composition to inheritance - it&#39;s well worth a quick read).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In summary, I strongly believe that almost all relations between classes may be described better by using composition than inheritance (where &quot;better&quot; means that the code is easier to reason about and, also, easier to test) and so almost no classes should need to be inherited from. In the few cases where inheritance &lt;em&gt;is&lt;/em&gt; necessary, the base classes must be carefully designed for inheritance and the use cases that necessitate inheritance will almost always be ones where the base classes are non-functional in isolation, where they &lt;em&gt;require&lt;/em&gt; a derived type in order to work.&lt;/p&gt;

&lt;p&gt;Therefore, 99% of classes should be written to be abstract or to be sealed. This goes for &lt;em&gt;all&lt;/em&gt; classes that I&#39;ve shown code for in this series - the &lt;strong&gt;MessageEditor&lt;/strong&gt; component class should be sealed, its &lt;strong&gt;Props&lt;/strong&gt; class should be sealed, the &lt;strong&gt;MessageWriterStore&lt;/strong&gt; should be sealed, the &lt;strong&gt;MessageDetails&lt;/strong&gt; should be sealed, the &lt;strong&gt;Saved&lt;/strong&gt; class should be sealed and the &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; should be sealed. They should &lt;em&gt;all&lt;/em&gt; be sealed.&lt;/p&gt;

&lt;p&gt;Now, if we wanted to play devil&#39;s advocate then we could say that any &quot;ClassName&quot; property on a component class shouldn&#39;t be &lt;strong&gt;Optional&amp;lt;NonBlankTrimmedString&amp;gt;&lt;/strong&gt; since I&#39;ve said that everything should be really specific, since richer types have a lot of value in expressing intent. We could say that there should be a more specific &lt;strong&gt;ClassName&lt;/strong&gt; class, which only allows characters that are valid in an html class name (React deals with encoding string &quot;ClassName&quot; properties, so this isn&#39;t really a big concern - but I&#39;m trying to prove another point, so bear with me). We could also say that this &lt;strong&gt;ClassName&lt;/strong&gt; class really &lt;em&gt;is&lt;/em&gt; a specialisation of &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; and so surely we should allow &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; to be inherited from so that &lt;strong&gt;ClassName&lt;/strong&gt; could be derived from it. On the surface, this doesn&#39;t seem too unreasonable. However, the only actual benefit of having &lt;strong&gt;ClassName&lt;/strong&gt; inherit from &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; (other than it just &lt;em&gt;feeling&lt;/em&gt; like something that may possibly be a good idea) would be if there was a point at which you had a method that took an argument of type &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; that you wanted to give a &lt;strong&gt;ClassName&lt;/strong&gt; instance - because it seems like any valid &lt;strong&gt;ClassName&lt;/strong&gt; will also be a valid &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt;. I think that the benefit is just too small to outweight the cost. Inheritance brings with it too much potential complication (and associated mental burden) that any small benefit like this is not enough to bring inheritance into play. On top of which, if you really did want to be able to use a &lt;strong&gt;ClassName&lt;/strong&gt; instance anywhere that a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; is required, you could do this by implementing an implicit operator method on &lt;strong&gt;ClassName&lt;/strong&gt; that allows it be implicitly cast to a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; - then you would have the marginal benefit of being able to use a &lt;strong&gt;ClassName&lt;/strong&gt; anywhere that you need a &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; but still be able to keep &lt;strong&gt;NonBlankTrimmedString&lt;/strong&gt; sealed and less prone to error.&lt;/p&gt;

&lt;p&gt;Writing classes that are sealed by default is another practice that I am still trying to instill into myself. Much like writing methods to be static by default, I think that it makes a huge amount of sense but it&#39;s also a concept that I&#39;ve only cemented in the last year or so and I&#39;m still trying to consistently apply it!&lt;/p&gt;

&lt;h3&gt;In summary&lt;/h3&gt;

&lt;p&gt;This has turned out to be a pretty huge post. But I didn&#39;t want to try to split it up because all of the principles are related, really.&lt;/p&gt;

&lt;p&gt;If you&#39;d stopped reading after &lt;a href=&quot;http://www.productiverage.com/writing-react-apps-using-bridgenet-the-dan-way-part-two&quot;&gt;Part Two&lt;/a&gt; then I think that you would have the tools to construct client-side applications that will scale from something simple up to something massively complex. The combination of C# (which is time-proven as a language that not only enables large applications to be built and maintained over long periods of time, it is a language where it is not exceptional for this to be the case*) and React is very powerful.&lt;/p&gt;

&lt;p&gt;* &lt;em&gt;(Languages such as PHP and JavaScript CAN be used to build and maintain large code bases, but I think that it&#39;s telling that the companies that take this work seriously rely on, and develop, additional tooling to make it manageable, like &lt;a href=&quot;http://hacklang.org/&quot;&gt;Hack&lt;/a&gt; and &lt;a href=&quot;http://flowtype.org/&quot;&gt;Flow&lt;/a&gt;).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;However, the principles behind React that I found most appealing when I first encountered it - that it primarily exists to make complicated interactions in an application simpler and scalable - are what I want to apply to my C#. In the concepts that I&#39;m advocating here for writing C# React applications &lt;em&gt;and&lt;/em&gt; in React itself, performance is not the number one priority; it is not something for which code clarity must be sacrificed in order to attain. Performance is, however, still important - but it is achieved through high-level design decisions and not through micro-optimisations (I still think that the best example of this is how performing particular operations on an immutable structure will almost always be slower than on the corresponding mutable structure, but the algorithms that may be written based upon the safe sharing of immutable types mean that actual application performance will be greater - whether this is in the avoidance of deep-cloning references for safety or in the way that the &lt;strong&gt;PureComponent&lt;/strong&gt; can avoid re-rendering of entire branches of the UI by the Virtual DOM).&lt;/p&gt;

&lt;p&gt;To summarise, I believe that if the guidelines presented here are followed then you will be able to go beyond the C# React applications that you would have written with Part-Two Knowledge and be able to write code that is easier to understand (whether by other Developers or by yourself, when you come back to a piece of code after six months), easier to maintain and extend &lt;em&gt;and&lt;/em&gt; that is more efficient.&lt;/p&gt;

&lt;p&gt;To recap, the guidelines are as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Immutable data types are fantastic for code clarity (the classes themselves will require more lines of code than if they were mutable but this is a trade-off that is well worth making, plus you will often require less code in places that makes use of these classes - which is relevant if lines of code is the most important metric to you)&lt;/li&gt;
&lt;li&gt;Anything that can&#39;t be immutable should have accessibility that is as restricted as possible (Store classes are not immutable, but their public properties are all read-only)&lt;/li&gt;
&lt;li&gt;Implicit assumptions are &quot;silly mistakes&quot; waiting to happen, encoding as much in the type system as possible communicates intent to other Developers and moves various types of error from runtime to compile time (immutable types and strongly-typed IDs are both examples of this)&lt;/li&gt;
&lt;li&gt;Write static methods by default, only make them instance / non-static methods if and when they need to be&lt;/li&gt;
&lt;li&gt;Write sealed classes by default, if they really need to be inheritable then they likely should be abstract (classes should almost never be neither sealed nor abstract)&lt;/li&gt;
&lt;li&gt;Using simple composable abstractions can greatly improve code clarity (as we saw with the &quot;ValidateMessage&quot; method rewrite)&lt;/li&gt;
&lt;li&gt;Code clarity is king!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&#39;m not sure that there&#39;s anything earth-shatteringly original about any one of these suggestions. Combining them can, in my ever-so-humble opinion, result in significantly higher quality code than &lt;em&gt;not&lt;/em&gt; following them. While these posts have been about writing React applications using &lt;a href=&quot;http://bridge.net/&quot;&gt;Bridge.NET&lt;/a&gt;, these rules may be applied just as well to any C# code. The &lt;a href=&quot;https://www.nuget.org/packages/ProductiveRage.Immutable&quot;&gt;ProductiveRage.Immutable&lt;/a&gt; NuGet package only works with Bridge projects, though - but if anyone asked them I would happily consider recreating it for vanilla C#! :)&lt;/p&gt;

&lt;h3&gt;Is this really the end??&lt;/h3&gt;

&lt;p&gt;There are some other things to consider when writing complete Bridge / React applications. I keep saying that it&#39;s important for code to be testable, but I haven&#39;t offered any way to write the actual unit tests. I&#39;ve also not had to offer any URL-routing capabilities, since the example application is so simple. But routing &lt;em&gt;is&lt;/em&gt; something that is almost certainly going to be required in any real browser-based application.&lt;/p&gt;

&lt;p&gt;These are both technologies that I would like to cover in future posts, but probably as shorter follow-up pieces. In terms of &lt;em&gt;how&lt;/em&gt; to write React applications in C#, I am happy with what I&#39;ve covered in these three posts - I wanted to get the example code to where it is now but without jumping straight to the final architecture; I wanted to illustrate &lt;em&gt;why&lt;/em&gt; one-way data binding is so beneficial and then why a Flux-like structure is so helpful and then &lt;em&gt;why&lt;/em&gt; immutable types are such a good idea. Hopefully, by starting from the basics and introducing new concepts and approaches only when there was a way to illustrate the improvements that they yield, you all agree with me that this is the way to do things! &lt;/p&gt;

&lt;p&gt;Of course, if you disagree in general, or on any particular points, or you have any tweaks to what I&#39;ve suggested then I would be very interested to hear. That&#39;s what the comments section is for!&lt;/p&gt;
</description>
			<pubDate>Wed, 30 Mar 2016 21:32:00 GMT</pubDate>
		</item>

	</channel>

</rss>